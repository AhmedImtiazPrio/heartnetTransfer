{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17061, 2500, 1)\n",
      "(17061, 1)\n",
      "(5872, 2500, 1)\n",
      "(5872, 1)\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/100\n",
      " - 16s - loss: 1.5462 - acc: 0.3087 - val_loss: 1.1749 - val_acc: 0.3595\n",
      "Epoch 2/100\n",
      " - 5s - loss: 1.3435 - acc: 0.3856 - val_loss: 1.1470 - val_acc: 0.4191\n",
      "Epoch 3/100\n",
      " - 5s - loss: 1.2768 - acc: 0.4271 - val_loss: 1.1404 - val_acc: 0.4429\n",
      "Epoch 4/100\n",
      " - 5s - loss: 1.2524 - acc: 0.4383 - val_loss: 1.1380 - val_acc: 0.4503\n",
      "Epoch 5/100\n",
      " - 5s - loss: 1.2370 - acc: 0.4513 - val_loss: 1.1370 - val_acc: 0.4540\n",
      "Epoch 6/100\n",
      " - 5s - loss: 1.2325 - acc: 0.4540 - val_loss: 1.1360 - val_acc: 0.4564\n",
      "Epoch 7/100\n",
      " - 5s - loss: 1.2106 - acc: 0.4654 - val_loss: 1.1332 - val_acc: 0.4596\n",
      "Epoch 8/100\n",
      " - 5s - loss: 1.1996 - acc: 0.4684 - val_loss: 1.1323 - val_acc: 0.4595\n",
      "Epoch 9/100\n",
      " - 5s - loss: 1.2061 - acc: 0.4649 - val_loss: 1.1310 - val_acc: 0.4601\n",
      "Epoch 10/100\n",
      " - 5s - loss: 1.1936 - acc: 0.4659 - val_loss: 1.1294 - val_acc: 0.4610\n",
      "Epoch 11/100\n",
      " - 5s - loss: 1.1835 - acc: 0.4695 - val_loss: 1.1280 - val_acc: 0.4630\n",
      "Epoch 12/100\n",
      " - 5s - loss: 1.1782 - acc: 0.4751 - val_loss: 1.1265 - val_acc: 0.4615\n",
      "Epoch 13/100\n",
      " - 5s - loss: 1.1745 - acc: 0.4763 - val_loss: 1.1250 - val_acc: 0.4632\n",
      "Epoch 14/100\n",
      " - 4s - loss: 1.1695 - acc: 0.4791 - val_loss: 1.1243 - val_acc: 0.4624\n",
      "Epoch 15/100\n",
      " - 5s - loss: 1.1658 - acc: 0.4793 - val_loss: 1.1232 - val_acc: 0.4632\n",
      "Epoch 16/100\n",
      " - 5s - loss: 1.1626 - acc: 0.4810 - val_loss: 1.1222 - val_acc: 0.4634\n",
      "Epoch 17/100\n",
      " - 5s - loss: 1.1643 - acc: 0.4775 - val_loss: 1.1218 - val_acc: 0.4649\n",
      "Epoch 18/100\n",
      " - 5s - loss: 1.1534 - acc: 0.4809 - val_loss: 1.1205 - val_acc: 0.4642\n",
      "Epoch 19/100\n",
      " - 5s - loss: 1.1568 - acc: 0.4855 - val_loss: 1.1195 - val_acc: 0.4659\n",
      "Epoch 20/100\n",
      " - 5s - loss: 1.1450 - acc: 0.4862 - val_loss: 1.1198 - val_acc: 0.4653\n",
      "Epoch 21/100\n",
      " - 5s - loss: 1.1557 - acc: 0.4783 - val_loss: 1.1188 - val_acc: 0.4656\n",
      "Epoch 22/100\n",
      " - 5s - loss: 1.1386 - acc: 0.4826 - val_loss: 1.1179 - val_acc: 0.4659\n",
      "Epoch 23/100\n",
      " - 5s - loss: 1.1351 - acc: 0.4848 - val_loss: 1.1171 - val_acc: 0.4656\n",
      "Epoch 24/100\n",
      " - 5s - loss: 1.1242 - acc: 0.4894 - val_loss: 1.1155 - val_acc: 0.4666\n",
      "Epoch 25/100\n",
      " - 5s - loss: 1.1261 - acc: 0.4885 - val_loss: 1.1154 - val_acc: 0.4676\n",
      "Epoch 26/100\n",
      " - 5s - loss: 1.1283 - acc: 0.4886 - val_loss: 1.1145 - val_acc: 0.4678\n",
      "Epoch 27/100\n",
      " - 5s - loss: 1.1212 - acc: 0.4941 - val_loss: 1.1142 - val_acc: 0.4676\n",
      "Epoch 28/100\n",
      " - 5s - loss: 1.1247 - acc: 0.4898 - val_loss: 1.1135 - val_acc: 0.4671\n",
      "Epoch 29/100\n",
      " - 5s - loss: 1.1138 - acc: 0.4918 - val_loss: 1.1131 - val_acc: 0.4676\n",
      "Epoch 30/100\n",
      " - 5s - loss: 1.1137 - acc: 0.4975 - val_loss: 1.1121 - val_acc: 0.4682\n",
      "Epoch 31/100\n",
      " - 5s - loss: 1.1076 - acc: 0.4964 - val_loss: 1.1119 - val_acc: 0.4687\n",
      "Epoch 32/100\n",
      " - 5s - loss: 1.1068 - acc: 0.4941 - val_loss: 1.1109 - val_acc: 0.4682\n",
      "Epoch 33/100\n",
      " - 5s - loss: 1.1039 - acc: 0.4977 - val_loss: 1.1106 - val_acc: 0.4678\n",
      "Epoch 34/100\n",
      " - 5s - loss: 1.1007 - acc: 0.5020 - val_loss: 1.1099 - val_acc: 0.4676\n",
      "Epoch 35/100\n",
      " - 5s - loss: 1.1102 - acc: 0.4984 - val_loss: 1.1096 - val_acc: 0.4673\n",
      "Epoch 36/100\n",
      " - 5s - loss: 1.1028 - acc: 0.4935 - val_loss: 1.1081 - val_acc: 0.4690\n",
      "Epoch 37/100\n",
      " - 5s - loss: 1.1045 - acc: 0.4980 - val_loss: 1.1079 - val_acc: 0.4699\n",
      "Epoch 38/100\n",
      " - 5s - loss: 1.0945 - acc: 0.5013 - val_loss: 1.1074 - val_acc: 0.4704\n",
      "Epoch 39/100\n",
      " - 5s - loss: 1.0873 - acc: 0.5028 - val_loss: 1.1071 - val_acc: 0.4702\n",
      "Epoch 40/100\n",
      " - 5s - loss: 1.0947 - acc: 0.4985 - val_loss: 1.1067 - val_acc: 0.4700\n",
      "Epoch 41/100\n",
      " - 5s - loss: 1.0916 - acc: 0.4975 - val_loss: 1.1059 - val_acc: 0.4707\n",
      "Epoch 42/100\n",
      " - 5s - loss: 1.0825 - acc: 0.5042 - val_loss: 1.1054 - val_acc: 0.4712\n",
      "Epoch 43/100\n",
      " - 4s - loss: 1.0833 - acc: 0.5031 - val_loss: 1.1048 - val_acc: 0.4709\n",
      "Epoch 44/100\n",
      " - 5s - loss: 1.0841 - acc: 0.5022 - val_loss: 1.1033 - val_acc: 0.4709\n",
      "Epoch 45/100\n",
      " - 5s - loss: 1.0796 - acc: 0.5098 - val_loss: 1.1034 - val_acc: 0.4699\n",
      "Epoch 46/100\n",
      " - 5s - loss: 1.0792 - acc: 0.5067 - val_loss: 1.1026 - val_acc: 0.4692\n",
      "Epoch 47/100\n",
      " - 5s - loss: 1.0789 - acc: 0.5055 - val_loss: 1.1021 - val_acc: 0.4687\n",
      "Epoch 48/100\n",
      " - 5s - loss: 1.0719 - acc: 0.5076 - val_loss: 1.1019 - val_acc: 0.4685\n",
      "Epoch 49/100\n",
      " - 5s - loss: 1.0768 - acc: 0.5058 - val_loss: 1.1015 - val_acc: 0.4687\n",
      "Epoch 50/100\n",
      " - 5s - loss: 1.0730 - acc: 0.5064 - val_loss: 1.1012 - val_acc: 0.4676\n",
      "Epoch 51/100\n",
      " - 5s - loss: 1.0697 - acc: 0.5055 - val_loss: 1.1011 - val_acc: 0.4682\n",
      "Epoch 52/100\n",
      " - 5s - loss: 1.0660 - acc: 0.5114 - val_loss: 1.1004 - val_acc: 0.4682\n",
      "Epoch 53/100\n",
      " - 5s - loss: 1.0684 - acc: 0.5084 - val_loss: 1.0996 - val_acc: 0.4690\n",
      "Epoch 54/100\n",
      " - 5s - loss: 1.0645 - acc: 0.5066 - val_loss: 1.0984 - val_acc: 0.4695\n",
      "Epoch 55/100\n",
      " - 5s - loss: 1.0571 - acc: 0.5079 - val_loss: 1.0985 - val_acc: 0.4700\n",
      "Epoch 56/100\n",
      " - 5s - loss: 1.0593 - acc: 0.5065 - val_loss: 1.0980 - val_acc: 0.4699\n",
      "Epoch 57/100\n",
      " - 5s - loss: 1.0514 - acc: 0.5118 - val_loss: 1.0970 - val_acc: 0.4702\n",
      "Epoch 58/100\n",
      " - 5s - loss: 1.0593 - acc: 0.5139 - val_loss: 1.0970 - val_acc: 0.4704\n",
      "Epoch 59/100\n",
      " - 4s - loss: 1.0569 - acc: 0.5092 - val_loss: 1.0965 - val_acc: 0.4705\n",
      "Epoch 60/100\n",
      " - 5s - loss: 1.0485 - acc: 0.5139 - val_loss: 1.0954 - val_acc: 0.4705\n",
      "Epoch 61/100\n",
      " - 5s - loss: 1.0518 - acc: 0.5119 - val_loss: 1.0954 - val_acc: 0.4707\n",
      "Epoch 62/100\n",
      " - 5s - loss: 1.0503 - acc: 0.5142 - val_loss: 1.0946 - val_acc: 0.4704\n",
      "Epoch 63/100\n",
      " - 5s - loss: 1.0515 - acc: 0.5118 - val_loss: 1.0946 - val_acc: 0.4705\n",
      "Epoch 64/100\n",
      " - 5s - loss: 1.0470 - acc: 0.5169 - val_loss: 1.0945 - val_acc: 0.4709\n",
      "Epoch 65/100\n",
      " - 5s - loss: 1.0409 - acc: 0.5164 - val_loss: 1.0935 - val_acc: 0.4709\n",
      "Epoch 66/100\n",
      " - 5s - loss: 1.0537 - acc: 0.5133 - val_loss: 1.0931 - val_acc: 0.4714\n",
      "Epoch 67/100\n",
      " - 5s - loss: 1.0494 - acc: 0.5154 - val_loss: 1.0927 - val_acc: 0.4719\n",
      "Epoch 68/100\n",
      " - 5s - loss: 1.0470 - acc: 0.5161 - val_loss: 1.0923 - val_acc: 0.4719\n",
      "Epoch 69/100\n",
      " - 5s - loss: 1.0437 - acc: 0.5146 - val_loss: 1.0913 - val_acc: 0.4719\n",
      "Epoch 70/100\n",
      " - 5s - loss: 1.0417 - acc: 0.5171 - val_loss: 1.0910 - val_acc: 0.4721\n",
      "Epoch 71/100\n",
      " - 5s - loss: 1.0392 - acc: 0.5173 - val_loss: 1.0907 - val_acc: 0.4728\n",
      "Epoch 72/100\n",
      " - 5s - loss: 1.0384 - acc: 0.5166 - val_loss: 1.0905 - val_acc: 0.4733\n",
      "Epoch 73/100\n",
      " - 5s - loss: 1.0327 - acc: 0.5194 - val_loss: 1.0901 - val_acc: 0.4734\n",
      "Epoch 74/100\n",
      " - 5s - loss: 1.0385 - acc: 0.5142 - val_loss: 1.0896 - val_acc: 0.4736\n",
      "Epoch 75/100\n",
      " - 5s - loss: 1.0302 - acc: 0.5231 - val_loss: 1.0895 - val_acc: 0.4736\n",
      "Epoch 76/100\n",
      " - 5s - loss: 1.0338 - acc: 0.5201 - val_loss: 1.0892 - val_acc: 0.4736\n",
      "Epoch 77/100\n",
      " - 5s - loss: 1.0380 - acc: 0.5178 - val_loss: 1.0886 - val_acc: 0.4736\n",
      "Epoch 78/100\n",
      " - 5s - loss: 1.0312 - acc: 0.5178 - val_loss: 1.0881 - val_acc: 0.4734\n",
      "Epoch 79/100\n",
      " - 5s - loss: 1.0319 - acc: 0.5202 - val_loss: 1.0877 - val_acc: 0.4729\n",
      "Epoch 80/100\n",
      " - 5s - loss: 1.0334 - acc: 0.5229 - val_loss: 1.0876 - val_acc: 0.4731\n",
      "Epoch 81/100\n",
      " - 5s - loss: 1.0321 - acc: 0.5190 - val_loss: 1.0874 - val_acc: 0.4726\n",
      "Epoch 82/100\n",
      " - 5s - loss: 1.0283 - acc: 0.5244 - val_loss: 1.0870 - val_acc: 0.4729\n",
      "Epoch 83/100\n",
      " - 5s - loss: 1.0332 - acc: 0.5207 - val_loss: 1.0868 - val_acc: 0.4726\n",
      "Epoch 84/100\n",
      " - 5s - loss: 1.0231 - acc: 0.5273 - val_loss: 1.0860 - val_acc: 0.4724\n",
      "Epoch 85/100\n",
      " - 5s - loss: 1.0293 - acc: 0.5218 - val_loss: 1.0859 - val_acc: 0.4722\n",
      "Epoch 86/100\n",
      " - 5s - loss: 1.0271 - acc: 0.5252 - val_loss: 1.0859 - val_acc: 0.4722\n",
      "Epoch 87/100\n",
      " - 5s - loss: 1.0285 - acc: 0.5236 - val_loss: 1.0850 - val_acc: 0.4728\n",
      "Epoch 88/100\n",
      " - 5s - loss: 1.0186 - acc: 0.5273 - val_loss: 1.0847 - val_acc: 0.4736\n",
      "Epoch 89/100\n",
      " - 5s - loss: 1.0225 - acc: 0.5242 - val_loss: 1.0849 - val_acc: 0.4733\n",
      "Epoch 90/100\n",
      " - 5s - loss: 1.0284 - acc: 0.5286 - val_loss: 1.0843 - val_acc: 0.4733\n",
      "Epoch 91/100\n",
      " - 5s - loss: 1.0229 - acc: 0.5201 - val_loss: 1.0839 - val_acc: 0.4733\n",
      "Epoch 92/100\n",
      " - 5s - loss: 1.0170 - acc: 0.5265 - val_loss: 1.0835 - val_acc: 0.4736\n",
      "Epoch 93/100\n",
      " - 5s - loss: 1.0186 - acc: 0.5274 - val_loss: 1.0832 - val_acc: 0.4736\n",
      "Epoch 94/100\n",
      " - 5s - loss: 1.0200 - acc: 0.5257 - val_loss: 1.0830 - val_acc: 0.4739\n",
      "Epoch 95/100\n",
      " - 5s - loss: 1.0194 - acc: 0.5284 - val_loss: 1.0824 - val_acc: 0.4743\n",
      "Epoch 96/100\n",
      " - 5s - loss: 1.0196 - acc: 0.5252 - val_loss: 1.0821 - val_acc: 0.4745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 97/100\n",
      " - 5s - loss: 1.0233 - acc: 0.5255 - val_loss: 1.0818 - val_acc: 0.4748\n",
      "Epoch 98/100\n",
      " - 5s - loss: 1.0178 - acc: 0.5257 - val_loss: 1.0816 - val_acc: 0.4756\n",
      "Epoch 99/100\n",
      " - 5s - loss: 1.0134 - acc: 0.5287 - val_loss: 1.0817 - val_acc: 0.4753\n",
      "Epoch 100/100\n",
      " - 5s - loss: 1.0173 - acc: 0.5299 - val_loss: 1.0811 - val_acc: 0.4750\n",
      "0.326258503401\n",
      "[[ 0 30  2]\n",
      " [ 0 92  6]\n",
      " [ 0 48  2]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from heartnet_v1 import heartnet, reshape_folds\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "set_session(tf.Session(config=config))\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, TensorBoard, Callback\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "import tables\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "def heartnet_transfer(load_path='/media/taufiq/Data/heart_sound/interspeech_compare/weights.0148-0.8902.hdf5',lr=0.0012843784,lr_decay=0.0001132885,num_dense=20,trainable=False,dropout_rate=0.):\n",
    "    model = heartnet(load_path=load_path,FIR_train=False,trainable=trainable)\n",
    "    x = model.layers[-4].output\n",
    "    x = Dense(num_dense,activation='relu') (x)\n",
    "    x = Dropout(rate=dropout_rate,seed=1) (x)\n",
    "    output = Dense(3,activation='softmax')(x)\n",
    "    model = Model(inputs=model.input,outputs=output)\n",
    "    sgd = SGD(lr=lr)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "class log_UAR(Callback):\n",
    "\n",
    "    def __init__(self, x_val, y_val, val_parts, res_thresh):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.val_parts = val_parts\n",
    "        self.res_thresh = res_thresh\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if logs is not None:\n",
    "            y_pred = self.model.predict(self.x_val, verbose=0)\n",
    "            y_pred = np.argmax(y_pred, axis=-1)\n",
    "            self.y_val_ = np.transpose(np.argmax(self.y_val, axis=-1))\n",
    "            true = []\n",
    "            pred = []\n",
    "            start_idx = 0\n",
    "            for s in self.val_parts:\n",
    "\n",
    "                if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "                    continue\n",
    "                # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "                temp_ = self.y_val_[start_idx:start_idx + int(s) - 1]\n",
    "                temp = y_pred[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "                if (sum(temp == 0) > sum(temp == 1)) and (sum(temp == 0) > sum(temp == 2)):\n",
    "                    pred.append(0)\n",
    "                elif (sum(temp == 2) > sum(temp == 1)) and (sum(temp == 2) > sum(temp == 0)):\n",
    "                    pred.append(2)\n",
    "                else:\n",
    "                    pred.append(1)\n",
    "\n",
    "                if (sum(temp_ == 0) > sum(temp_ == 1)) and (sum(temp_ == 0) > sum(temp_ == 2)):\n",
    "                    true.append(0)\n",
    "                elif (sum(temp_ == 2) > sum(temp_ == 1)) and (sum(temp_ == 2) > sum(temp_ == 0)):\n",
    "                    true.append(2)\n",
    "                else:\n",
    "                    true.append(1)\n",
    "\n",
    "                start_idx = start_idx + int(s)\n",
    "\n",
    "            score = recall_score(y_pred=pred, y_true=true, average='macro')\n",
    "            logs['UAR'] = np.array(score)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    fold_dir = '/media/taufiq/Data/heart_sound/interspeech_compare/feature/segmented_noFIR/'\n",
    "    foldname = 'comParE'\n",
    "    model_dir = '/media/taufiq/Data/heart_sound/models/'\n",
    "    log_name = foldname + ' ' + str(datetime.now())\n",
    "    checkpoint_name = model_dir + log_name + \"/\" + 'weights.{epoch:04d}-{val_acc:.4f}.hdf5'\n",
    "    if not os.path.exists(model_dir + log_name):\n",
    "        os.makedirs(model_dir + log_name)\n",
    "    log_dir = '/media/taufiq/Data/heart_sound/interspeech_compare/logs/'\n",
    "\n",
    "    ##### Load Model ######\n",
    "\n",
    "    load_path='/media/taufiq/Data/heart_sound/interspeech_compare/weights.0148-0.8902.hdf5'\n",
    "    lr = 0.00005\n",
    "    num_dense = 34\n",
    "    epochs = 1000\n",
    "    batch_size = 128\n",
    "    dropout_rate = 0.\n",
    "    trainable = True\n",
    "    res_thresh = .5\n",
    "    model = heartnet_transfer(load_path=load_path,lr=lr,num_dense=num_dense,trainable=trainable,dropout_rate=dropout_rate)\n",
    "    plot_model(model,\"model.png\",show_layer_names=True,show_shapes=True)\n",
    "\n",
    "    ###### Load Data ######\n",
    "\n",
    "    feat = tables.open_file(fold_dir + foldname + '.mat')\n",
    "    x_train = feat.root.trainX[:]\n",
    "    y_train = feat.root.trainY[0, :]\n",
    "    x_val = feat.root.valX[:]\n",
    "    y_val = feat.root.valY[0, :]\n",
    "    train_parts = feat.root.train_parts[:]\n",
    "    val_parts = feat.root.val_parts[0, :]\n",
    "\n",
    "    ############### Reshaping ############\n",
    "\n",
    "    x_train, y_train, x_val, y_val = reshape_folds(x_train, x_val, y_train, y_val)\n",
    "    y_train = to_categorical(y_train,num_classes=3)\n",
    "    y_val = to_categorical(y_val,num_classes=3)\n",
    "\n",
    "    ### Callbacks ###\n",
    "    csv_logger = CSVLogger(log_dir + log_name + '/training.csv')\n",
    "    modelcheckpnt = ModelCheckpoint(filepath=checkpoint_name,\n",
    "                                    monitor='val_acc', save_best_only=True, mode='max')\n",
    "    tensbd = TensorBoard(log_dir=log_dir + log_name,\n",
    "                         batch_size=batch_size,\n",
    "                         histogram_freq=100,\n",
    "                         # embeddings_freq=99,\n",
    "                         # embeddings_layer_names=embedding_layer_names,\n",
    "                         # embeddings_data=x_val,\n",
    "                         # embeddings_metadata=metadata_file,\n",
    "                         write_images=False)\n",
    "\n",
    "    ### Train ###\n",
    "    model.fit(x_train,y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              verbose=2,\n",
    "              shuffle=True,\n",
    "              callbacks=[modelcheckpnt,\n",
    "                         log_UAR(x_val, y_val, val_parts, res_thresh),\n",
    "                         tensbd, csv_logger],\n",
    "              validation_data=(x_val,y_val))\n",
    "\n",
    "    ###### Results #####\n",
    "\n",
    "    y_pred = model.predict(x_val, verbose=0)\n",
    "    y_pred = np.argmax(y_pred,axis=-1)\n",
    "    y_val = np.transpose(np.argmax(y_val,axis=-1))\n",
    "    true = []\n",
    "    pred = []\n",
    "    start_idx = 0\n",
    "    for s in val_parts:\n",
    "\n",
    "        if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "            continue\n",
    "        # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "        temp_ = y_val[start_idx:start_idx + int(s) - 1]\n",
    "        temp = y_pred[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "        if (sum(temp==0) > sum(temp==1)) and  (sum(temp==0) > sum(temp==2)):\n",
    "            pred.append(0)\n",
    "        elif (sum(temp==2) > sum(temp==1)) and  (sum(temp==2) > sum(temp==0)):\n",
    "            pred.append(2)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "\n",
    "        if (sum(temp_ == 0) > sum(temp_ == 1)) and (sum(temp_ == 0) > sum(temp_ == 2)):\n",
    "            true.append(0)\n",
    "        elif (sum(temp_ == 2) > sum(temp_ == 1)) and (sum(temp_ == 2) > sum(temp_ == 0)):\n",
    "            true.append(2)\n",
    "        else:\n",
    "            true.append(1)\n",
    "\n",
    "        start_idx = start_idx + int(s)\n",
    "    score = recall_score(y_pred=pred, y_true=true, average='macro')\n",
    "    print(score)\n",
    "    print(confusion_matrix(y_true=true,y_pred=pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "    y_pred = model.predict(x_val, verbose=0)\n",
    "    print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(y_pred[:,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.argmax(y_pred)\n",
    "sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
