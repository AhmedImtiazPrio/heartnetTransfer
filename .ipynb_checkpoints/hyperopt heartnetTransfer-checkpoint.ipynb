{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "from custom_layers import Conv1D_linearphase\n",
    "from heartnet_v1 import heartnet, reshape_folds, branch\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "set_session(tf.Session(config=config))\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, TensorBoard, Callback\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dense, Dropout, Concatenate, initializers, Input\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "import tables\n",
    "from datetime import datetime\n",
    "from hyperopt import hp, fmin, Trials, tpe, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(Y, classes):\n",
    "    num_samples = (len(Y))\n",
    "    n_classes = (len(classes))\n",
    "    num_bin = np.sum(Y,axis=-2)\n",
    "    class_weights = {i: (num_samples / (n_classes * num_bin[i])) for i in range(n_classes)}\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heartnet_transfer(load_path='/media/taufiq/Data1/heart_sound/weights.0148-0.8902.hdf5',\n",
    "                      lr=0.0012843784,lr_decay=0.0001132885,\n",
    "                      num_dense1=20,num_dense2=20,trainable=False,dropout_rate=0.):\n",
    "    model = heartnet(load_path=load_path,FIR_train=False,trainable=trainable)\n",
    "    plot_model(model,'before.png',show_shapes=True,show_layer_names=True)\n",
    "    x = model.layers[-4].output\n",
    "    x = Dense(num_dense1,activation='relu',kernel_initializer=initializers.he_uniform(seed=1)) (x)\n",
    "    x = Dropout(rate=dropout_rate,seed=1) (x)\n",
    "    x = Dense(num_dense2, activation='relu',kernel_initializer=initializers.he_normal(seed=1))(x)\n",
    "    x = Dropout(rate=dropout_rate, seed=1)(x)\n",
    "    output = Dense(3,activation='softmax')(x)\n",
    "    model = Model(inputs=model.input,outputs=output)\n",
    "    plot_model(model, 'after.png',show_shapes=True,show_layer_names=True)\n",
    "    if load_path:\n",
    "        model.load_weights(load_path,by_name=True)\n",
    "    sgd = Adam(lr=lr)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class log_recall(Callback):\n",
    "\n",
    "    def __init__(self, x_val, y_val, val_parts):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.val_parts = val_parts\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if logs is not None:\n",
    "            y_pred = self.model.predict(self.x_val, verbose=0)\n",
    "            y_pred = np.argmax(y_pred, axis=-1)\n",
    "            self.y_val_ = np.transpose(np.argmax(self.y_val, axis=-1))\n",
    "            true = []\n",
    "            pred = []\n",
    "            start_idx = 0\n",
    "            for s in self.val_parts:\n",
    "\n",
    "                if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "                    continue\n",
    "                # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "                temp_ = self.y_val_[start_idx:start_idx + int(s) - 1]\n",
    "                temp = y_pred[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "                if (sum(temp == 0) > sum(temp == 1)) and (sum(temp == 0) > sum(temp == 2)):\n",
    "                    pred.append(0)\n",
    "                elif (sum(temp == 2) > sum(temp == 1)) and (sum(temp == 2) > sum(temp == 0)):\n",
    "                    pred.append(2)\n",
    "                else:\n",
    "                    pred.append(1)\n",
    "\n",
    "                if (sum(temp_ == 0) > sum(temp_ == 1)) and (sum(temp_ == 0) > sum(temp_ == 2)):\n",
    "                    true.append(0)\n",
    "                elif (sum(temp_ == 2) > sum(temp_ == 1)) and (sum(temp_ == 2) > sum(temp_ == 0)):\n",
    "                    true.append(2)\n",
    "                else:\n",
    "                    true.append(1)\n",
    "\n",
    "                start_idx = start_idx + int(s)\n",
    "\n",
    "            confmat = confusion_matrix(y_pred=pred, y_true=true)\n",
    "            \n",
    "            logs['recall0'] = confmat[0,0]/np.sum(confmat[0,:])\n",
    "            logs['recall1'] = confmat[1,1]/np.sum(confmat[1,:])\n",
    "            logs['recall2'] = confmat[2,2]/np.sum(confmat[2,:])\n",
    "            logs['UAR'] = np.mean([logs['recall0'],logs['recall1'],logs['recall2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dir = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/'\n",
    "foldname = 'comParE'\n",
    "model_dir = '/media/taufiq/Data1/heart_sound/models/'\n",
    "log_dir = '/media/taufiq/Data1/heart_sound/logs/'\n",
    "\n",
    "##### Load Model ######\n",
    "load_path='/media/taufiq/Data1/heart_sound/weights.0169-0.8798.hdf5'\n",
    "# lr = 0.00001\n",
    "lr = 1e-6\n",
    "num_dense1 = 239 #34,120,167,239,1239,650,788,422,598\n",
    "# num_dense2 = 137 #121,\n",
    "epochs = 40\n",
    "batch_size = 256\n",
    "dropout_rate = 0.\n",
    "trainable = False\n",
    "addweights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17061, 2500, 1)\n",
      "(17061, 1)\n",
      "(5872, 2500, 1)\n",
      "(5872, 1)\n"
     ]
    }
   ],
   "source": [
    "feat = tables.open_file(fold_dir + foldname + '.mat')\n",
    "x_train = feat.root.trainX[:]\n",
    "y_train = feat.root.trainY[0, :]\n",
    "x_val = feat.root.valX[:]\n",
    "y_val = feat.root.valY[0, :]\n",
    "train_parts = feat.root.train_parts[:]\n",
    "val_parts = feat.root.val_parts[0, :]\n",
    "############### Reshaping ############\n",
    "x_train, y_train, x_val, y_val = reshape_folds(x_train, x_val, y_train, y_val)\n",
    "y_train = to_categorical(y_train,num_classes=3)\n",
    "y_val = to_categorical(y_val,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    #### Parse arguments and print #####\n",
    "    \n",
    "    print(\"args %s\" % args)\n",
    "    \n",
    "#     lr = args['lr']\n",
    "#     num_dense1 = args['num_dense1']\n",
    "    num_dense2 = args['num_dense2']\n",
    "    \n",
    "    ##### Load model ######\n",
    "    model = heartnet_transfer(load_path=load_path,lr=lr,num_dense1=num_dense1,\n",
    "                              num_dense2=num_dense2,trainable=trainable,\n",
    "                              dropout_rate=dropout_rate)\n",
    "    \n",
    "    #### Log params #####\n",
    "    log_name = foldname + ' ' + str(datetime.now()) + str(args.values())\n",
    "    checkpoint_name = model_dir + log_name + \"/\" + 'weights.{epoch:04d}-{val_acc:.4f}.hdf5'\n",
    "    if not os.path.exists(model_dir + log_name):\n",
    "        os.makedirs(model_dir + log_name)\n",
    "    plot_model(model,\"model.png\",show_layer_names=True,show_shapes=True)\n",
    "    \n",
    "    ### Callbacks ###\n",
    "    \n",
    "    csv_logger = CSVLogger(log_dir + log_name + '/training.csv')\n",
    "    modelcheckpnt = ModelCheckpoint(filepath=checkpoint_name,\n",
    "                                    monitor='val_acc', save_best_only=False, mode='max')\n",
    "    tensbd = TensorBoard(log_dir=log_dir + log_name,\n",
    "                         batch_size=batch_size,\n",
    "                         # histogram_freq=100,\n",
    "                         # embeddings_freq=99,\n",
    "                         # embeddings_layer_names=embedding_layer_names,\n",
    "                         # embeddings_data=x_val,\n",
    "                         # embeddings_metadata=metadata_file,\n",
    "                         write_images=False)\n",
    "    class_weights=compute_weight(y_train,range(3))\n",
    "    print(\"Class weights %s\" % class_weights)\n",
    "\n",
    "    #### Train ####\n",
    "    \n",
    "    history = model.fit(x_train,y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=2,\n",
    "                        shuffle=True,\n",
    "                        class_weight=class_weights,\n",
    "                        callbacks=[modelcheckpnt,\n",
    "                        log_recall(x_val, y_val, val_parts),\n",
    "                        tensbd, csv_logger],\n",
    "                        validation_data=(x_val,y_val))\n",
    "#     print(\"History : %s\" % history.history)\n",
    "    loss = history.history['val_loss']\n",
    "    print(loss)\n",
    "    K.clear_session()\n",
    "#     return (1.- np.float32(np.max(loss)))\n",
    "    return {'loss': np.min(loss), 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "#     'lr' : 10 ** hp.uniform('lr',-8,-3),\n",
    "#     'num_dense1' : 200 + hp.randint('num_dense1',1800),\n",
    "    'num_dense2' : 40 + hp.randint('num_dense2',360)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args {'num_dense2': 89}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 1.2428 - acc: 0.3390 - val_loss: 1.1510 - val_acc: 0.3442\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.2202 - acc: 0.3444 - val_loss: 1.1484 - val_acc: 0.3360\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2046 - acc: 0.3426 - val_loss: 1.1463 - val_acc: 0.3399\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.1864 - acc: 0.3595 - val_loss: 1.1439 - val_acc: 0.3408\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.1795 - acc: 0.3653 - val_loss: 1.1423 - val_acc: 0.3394\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.1674 - acc: 0.3720 - val_loss: 1.1429 - val_acc: 0.3374\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.1539 - acc: 0.3764 - val_loss: 1.1410 - val_acc: 0.3377\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1493 - acc: 0.3775 - val_loss: 1.1421 - val_acc: 0.3338\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1350 - acc: 0.3887 - val_loss: 1.1406 - val_acc: 0.3374\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1342 - acc: 0.3859 - val_loss: 1.1411 - val_acc: 0.3362\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1255 - acc: 0.3905 - val_loss: 1.1405 - val_acc: 0.3370\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1145 - acc: 0.3984 - val_loss: 1.1394 - val_acc: 0.3406\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1171 - acc: 0.4033 - val_loss: 1.1395 - val_acc: 0.3392\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1053 - acc: 0.4056 - val_loss: 1.1391 - val_acc: 0.3382\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1069 - acc: 0.4089 - val_loss: 1.1401 - val_acc: 0.3334\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.0988 - acc: 0.4118 - val_loss: 1.1379 - val_acc: 0.3353\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.0917 - acc: 0.4194 - val_loss: 1.1390 - val_acc: 0.3351\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.0871 - acc: 0.4232 - val_loss: 1.1409 - val_acc: 0.3324\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.0896 - acc: 0.4296 - val_loss: 1.1395 - val_acc: 0.3340\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.0769 - acc: 0.4295 - val_loss: 1.1383 - val_acc: 0.3391\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0764 - acc: 0.4290 - val_loss: 1.1379 - val_acc: 0.3401\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0791 - acc: 0.4317 - val_loss: 1.1399 - val_acc: 0.3362\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0683 - acc: 0.4361 - val_loss: 1.1388 - val_acc: 0.3397\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0664 - acc: 0.4364 - val_loss: 1.1387 - val_acc: 0.3411\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0657 - acc: 0.4445 - val_loss: 1.1390 - val_acc: 0.3426\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0583 - acc: 0.4451 - val_loss: 1.1375 - val_acc: 0.3437\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0612 - acc: 0.4470 - val_loss: 1.1395 - val_acc: 0.3432\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0560 - acc: 0.4450 - val_loss: 1.1393 - val_acc: 0.3443\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0460 - acc: 0.4567 - val_loss: 1.1389 - val_acc: 0.3442\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0497 - acc: 0.4562 - val_loss: 1.1401 - val_acc: 0.3442\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0468 - acc: 0.4545 - val_loss: 1.1407 - val_acc: 0.3428\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0417 - acc: 0.4612 - val_loss: 1.1410 - val_acc: 0.3437\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0415 - acc: 0.4586 - val_loss: 1.1428 - val_acc: 0.3416\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0376 - acc: 0.4599 - val_loss: 1.1411 - val_acc: 0.3445\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0369 - acc: 0.4629 - val_loss: 1.1418 - val_acc: 0.3471\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0297 - acc: 0.4673 - val_loss: 1.1420 - val_acc: 0.3476\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0313 - acc: 0.4655 - val_loss: 1.1440 - val_acc: 0.3443\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0318 - acc: 0.4640 - val_loss: 1.1436 - val_acc: 0.3484\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0291 - acc: 0.4686 - val_loss: 1.1448 - val_acc: 0.3452\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0234 - acc: 0.4721 - val_loss: 1.1436 - val_acc: 0.3515\n",
      "[1.1510249142425912, 1.1484084743245095, 1.1462839666439337, 1.1439054025291422, 1.1422652334218455, 1.1428651575821298, 1.1409935649149425, 1.1421159859898955, 1.1406490166115826, 1.1411008360600277, 1.140519400058715, 1.139388303665764, 1.1395345975007933, 1.1391345681546494, 1.1400686622640417, 1.137946776538194, 1.1389717246920925, 1.1409102522384893, 1.1395261670977932, 1.1382934098672477, 1.1378522984663213, 1.1398889446778258, 1.13878983925084, 1.1387482501505506, 1.1389983236302472, 1.1375380345196424, 1.139520861147535, 1.1392583408537613, 1.1389330294216686, 1.1401270079028054, 1.14072147896894, 1.1410336111157078, 1.1428024996204011, 1.1410767986599042, 1.1418093764489614, 1.1420404472532975, 1.1439593650339734, 1.1436253792583455, 1.1447597371784803, 1.143590560401168]\n",
      "args {'num_dense2': 375}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.5886 - acc: 0.3794 - val_loss: 1.1296 - val_acc: 0.3878\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3883 - acc: 0.3856 - val_loss: 1.1259 - val_acc: 0.3694\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.3165 - acc: 0.3643 - val_loss: 1.1391 - val_acc: 0.3375\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2875 - acc: 0.3601 - val_loss: 1.1448 - val_acc: 0.3215\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2661 - acc: 0.3592 - val_loss: 1.1459 - val_acc: 0.3193\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2448 - acc: 0.3643 - val_loss: 1.1457 - val_acc: 0.3176\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2286 - acc: 0.3640 - val_loss: 1.1429 - val_acc: 0.3212\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.2233 - acc: 0.3672 - val_loss: 1.1416 - val_acc: 0.3229\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.2133 - acc: 0.3762 - val_loss: 1.1416 - val_acc: 0.3224\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1962 - acc: 0.3762 - val_loss: 1.1419 - val_acc: 0.3222\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1880 - acc: 0.3824 - val_loss: 1.1406 - val_acc: 0.3270\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1741 - acc: 0.3893 - val_loss: 1.1400 - val_acc: 0.3290\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1677 - acc: 0.3936 - val_loss: 1.1427 - val_acc: 0.3282\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1647 - acc: 0.3958 - val_loss: 1.1423 - val_acc: 0.3295\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1467 - acc: 0.3960 - val_loss: 1.1433 - val_acc: 0.3304\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1459 - acc: 0.4009 - val_loss: 1.1426 - val_acc: 0.3348\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1382 - acc: 0.4062 - val_loss: 1.1434 - val_acc: 0.3357\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1335 - acc: 0.4091 - val_loss: 1.1414 - val_acc: 0.3411\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1200 - acc: 0.4178 - val_loss: 1.1431 - val_acc: 0.3404\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1178 - acc: 0.4190 - val_loss: 1.1447 - val_acc: 0.3386\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1144 - acc: 0.4168 - val_loss: 1.1459 - val_acc: 0.3386\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.1115 - acc: 0.4237 - val_loss: 1.1453 - val_acc: 0.3403\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0952 - acc: 0.4304 - val_loss: 1.1454 - val_acc: 0.3426\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0982 - acc: 0.4250 - val_loss: 1.1484 - val_acc: 0.3423\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0947 - acc: 0.4301 - val_loss: 1.1477 - val_acc: 0.3437\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0850 - acc: 0.4333 - val_loss: 1.1469 - val_acc: 0.3462\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0827 - acc: 0.4391 - val_loss: 1.1476 - val_acc: 0.3443\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0747 - acc: 0.4442 - val_loss: 1.1479 - val_acc: 0.3462\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0711 - acc: 0.4428 - val_loss: 1.1489 - val_acc: 0.3466\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0715 - acc: 0.4391 - val_loss: 1.1513 - val_acc: 0.3467\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0713 - acc: 0.4445 - val_loss: 1.1519 - val_acc: 0.3481\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0619 - acc: 0.4501 - val_loss: 1.1514 - val_acc: 0.3493\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0574 - acc: 0.4538 - val_loss: 1.1512 - val_acc: 0.3529\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0578 - acc: 0.4530 - val_loss: 1.1521 - val_acc: 0.3508\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0462 - acc: 0.4569 - val_loss: 1.1524 - val_acc: 0.3527\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0498 - acc: 0.4568 - val_loss: 1.1540 - val_acc: 0.3517\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0447 - acc: 0.4633 - val_loss: 1.1547 - val_acc: 0.3503\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0369 - acc: 0.4620 - val_loss: 1.1564 - val_acc: 0.3489\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0425 - acc: 0.4639 - val_loss: 1.1569 - val_acc: 0.3484\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0366 - acc: 0.4655 - val_loss: 1.1559 - val_acc: 0.3484\n",
      "[1.1296056021786516, 1.1259279303069984, 1.1391331558331481, 1.1447810012573116, 1.1458506528947918, 1.1456985044869155, 1.142943645692976, 1.1415830174973616, 1.1416189394464935, 1.1418649932669034, 1.1406315350727425, 1.1399624000128348, 1.1426590499176317, 1.142276132464084, 1.1433112829192782, 1.1426033382519714, 1.1433527492372477, 1.1414256021177411, 1.1431337442320115, 1.1447369850948657, 1.1459098362467919, 1.1453121075513253, 1.1453657913597792, 1.1483731874003398, 1.147658314302117, 1.1468529756452472, 1.1475707094415981, 1.1478572463469545, 1.1488912836407446, 1.1513187729370367, 1.151924196316046, 1.1513749045961885, 1.1512186952767645, 1.1521034805911115, 1.1523620185800079, 1.1539544757120617, 1.1547260492309237, 1.1564290617727129, 1.1568690522165324, 1.1558702121963293]\n",
      "args {'num_dense2': 149}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.3729 - acc: 0.3352 - val_loss: 1.1903 - val_acc: 0.2815\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3121 - acc: 0.3320 - val_loss: 1.1896 - val_acc: 0.2679\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2826 - acc: 0.3389 - val_loss: 1.1802 - val_acc: 0.2778\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2723 - acc: 0.3369 - val_loss: 1.1766 - val_acc: 0.2822\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2425 - acc: 0.3523 - val_loss: 1.1711 - val_acc: 0.2885\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2321 - acc: 0.3577 - val_loss: 1.1676 - val_acc: 0.2927\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2228 - acc: 0.3706 - val_loss: 1.1659 - val_acc: 0.2924\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.2016 - acc: 0.3713 - val_loss: 1.1642 - val_acc: 0.2950\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1983 - acc: 0.3724 - val_loss: 1.1614 - val_acc: 0.3026\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1803 - acc: 0.3855 - val_loss: 1.1622 - val_acc: 0.3016\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1726 - acc: 0.3843 - val_loss: 1.1612 - val_acc: 0.3043\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1618 - acc: 0.3874 - val_loss: 1.1600 - val_acc: 0.3072\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1526 - acc: 0.3925 - val_loss: 1.1612 - val_acc: 0.3060\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1464 - acc: 0.3994 - val_loss: 1.1609 - val_acc: 0.3050\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1336 - acc: 0.3960 - val_loss: 1.1608 - val_acc: 0.3053\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1408 - acc: 0.3970 - val_loss: 1.1616 - val_acc: 0.3081\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1255 - acc: 0.4014 - val_loss: 1.1609 - val_acc: 0.3134\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1184 - acc: 0.4045 - val_loss: 1.1598 - val_acc: 0.3176\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1178 - acc: 0.4121 - val_loss: 1.1599 - val_acc: 0.3169\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1073 - acc: 0.4207 - val_loss: 1.1594 - val_acc: 0.3186\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1066 - acc: 0.4155 - val_loss: 1.1601 - val_acc: 0.3193\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.1013 - acc: 0.4238 - val_loss: 1.1597 - val_acc: 0.3208\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0936 - acc: 0.4203 - val_loss: 1.1590 - val_acc: 0.3225\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0940 - acc: 0.4211 - val_loss: 1.1588 - val_acc: 0.3244\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0893 - acc: 0.4306 - val_loss: 1.1609 - val_acc: 0.3224\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0842 - acc: 0.4221 - val_loss: 1.1608 - val_acc: 0.3231\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0794 - acc: 0.4296 - val_loss: 1.1625 - val_acc: 0.3237\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0770 - acc: 0.4320 - val_loss: 1.1621 - val_acc: 0.3224\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0677 - acc: 0.4358 - val_loss: 1.1616 - val_acc: 0.3254\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0620 - acc: 0.4398 - val_loss: 1.1622 - val_acc: 0.3244\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0604 - acc: 0.4386 - val_loss: 1.1638 - val_acc: 0.3214\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0595 - acc: 0.4444 - val_loss: 1.1635 - val_acc: 0.3215\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0498 - acc: 0.4493 - val_loss: 1.1634 - val_acc: 0.3243\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0548 - acc: 0.4487 - val_loss: 1.1635 - val_acc: 0.3234\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0424 - acc: 0.4524 - val_loss: 1.1632 - val_acc: 0.3234\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0396 - acc: 0.4580 - val_loss: 1.1639 - val_acc: 0.3229\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0441 - acc: 0.4581 - val_loss: 1.1655 - val_acc: 0.3231\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0371 - acc: 0.4595 - val_loss: 1.1646 - val_acc: 0.3246\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0417 - acc: 0.4615 - val_loss: 1.1646 - val_acc: 0.3248\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0275 - acc: 0.4622 - val_loss: 1.1636 - val_acc: 0.3246\n",
      "[1.1903033867194153, 1.1896417972502331, 1.180213819732458, 1.1765557176735486, 1.171116098720956, 1.1675701722786926, 1.1659096960150903, 1.164183381467814, 1.1613979579967115, 1.1622456701964707, 1.1612230042345841, 1.1599744415413131, 1.1612079003851161, 1.1609438079579324, 1.1607714780994591, 1.1615526309130302, 1.1608715560845524, 1.1597832054793022, 1.1599296721190782, 1.1594024058583647, 1.1601134343757942, 1.1596603338335125, 1.1590134993560957, 1.1588064711490185, 1.1609088072010216, 1.1608048066781067, 1.162484979109803, 1.162120598863191, 1.1616360368130967, 1.1622364267666268, 1.163763104082778, 1.163476032522134, 1.1633988456440232, 1.1635353610690997, 1.1632178557341366, 1.163892497808472, 1.1654663735579405, 1.1646169021279025, 1.1646401268260032, 1.1635656187904628]\n",
      "args {'num_dense2': 101}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.7696 - acc: 0.1913 - val_loss: 1.3468 - val_acc: 0.2134\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.4415 - acc: 0.2479 - val_loss: 1.2163 - val_acc: 0.3016\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.3366 - acc: 0.3071 - val_loss: 1.1682 - val_acc: 0.3520\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2960 - acc: 0.3433 - val_loss: 1.1496 - val_acc: 0.3709\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2897 - acc: 0.3559 - val_loss: 1.1405 - val_acc: 0.3787\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2619 - acc: 0.3672 - val_loss: 1.1354 - val_acc: 0.3786\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2438 - acc: 0.3751 - val_loss: 1.1316 - val_acc: 0.3789\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.2321 - acc: 0.3760 - val_loss: 1.1288 - val_acc: 0.3782\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.2185 - acc: 0.3805 - val_loss: 1.1252 - val_acc: 0.3798\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.2132 - acc: 0.3843 - val_loss: 1.1234 - val_acc: 0.3793\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1969 - acc: 0.3830 - val_loss: 1.1223 - val_acc: 0.3776\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1841 - acc: 0.3933 - val_loss: 1.1217 - val_acc: 0.3774\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1660 - acc: 0.3971 - val_loss: 1.1192 - val_acc: 0.3798\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1616 - acc: 0.4026 - val_loss: 1.1197 - val_acc: 0.3753\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1483 - acc: 0.4107 - val_loss: 1.1183 - val_acc: 0.3738\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1503 - acc: 0.4015 - val_loss: 1.1186 - val_acc: 0.3760\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1384 - acc: 0.4072 - val_loss: 1.1187 - val_acc: 0.3748\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1263 - acc: 0.4134 - val_loss: 1.1186 - val_acc: 0.3743\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1249 - acc: 0.4169 - val_loss: 1.1187 - val_acc: 0.3767\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1174 - acc: 0.4205 - val_loss: 1.1181 - val_acc: 0.3740\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1060 - acc: 0.4281 - val_loss: 1.1186 - val_acc: 0.3741\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.1060 - acc: 0.4265 - val_loss: 1.1185 - val_acc: 0.3718\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.1064 - acc: 0.4220 - val_loss: 1.1191 - val_acc: 0.3706\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0994 - acc: 0.4270 - val_loss: 1.1193 - val_acc: 0.3697\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0949 - acc: 0.4283 - val_loss: 1.1196 - val_acc: 0.3690\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0870 - acc: 0.4354 - val_loss: 1.1193 - val_acc: 0.3704\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0856 - acc: 0.4375 - val_loss: 1.1208 - val_acc: 0.3687\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0766 - acc: 0.4382 - val_loss: 1.1214 - val_acc: 0.3684\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0775 - acc: 0.4419 - val_loss: 1.1222 - val_acc: 0.3704\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0737 - acc: 0.4402 - val_loss: 1.1229 - val_acc: 0.3680\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0671 - acc: 0.4449 - val_loss: 1.1225 - val_acc: 0.3697\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0634 - acc: 0.4506 - val_loss: 1.1220 - val_acc: 0.3697\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0567 - acc: 0.4473 - val_loss: 1.1235 - val_acc: 0.3678\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0483 - acc: 0.4605 - val_loss: 1.1243 - val_acc: 0.3685\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0534 - acc: 0.4542 - val_loss: 1.1240 - val_acc: 0.3680\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0554 - acc: 0.4506 - val_loss: 1.1242 - val_acc: 0.3699\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0517 - acc: 0.4598 - val_loss: 1.1261 - val_acc: 0.3675\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0441 - acc: 0.4585 - val_loss: 1.1260 - val_acc: 0.3689\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0398 - acc: 0.4584 - val_loss: 1.1258 - val_acc: 0.3702\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0413 - acc: 0.4626 - val_loss: 1.1265 - val_acc: 0.3706\n",
      "[1.346757898538574, 1.2163061228370147, 1.168228589546453, 1.1496100094402844, 1.1404951339846412, 1.135407306842648, 1.1315686520828538, 1.1288332156329455, 1.1251823976838946, 1.1233812372431118, 1.122298378385705, 1.1216901556997274, 1.1191656053553485, 1.1197362452826642, 1.1182848728320254, 1.1186276654781373, 1.1187166459553899, 1.1185780770122518, 1.1187111129552856, 1.118107222731172, 1.1185645319785344, 1.1185401898963574, 1.119144300673898, 1.1193051994334124, 1.119563547077231, 1.1192836433405446, 1.120757133174657, 1.121382194253989, 1.1222460282920816, 1.1229231110710538, 1.1224825798003486, 1.121992737785672, 1.1234826651840835, 1.1243079816288128, 1.1240482599923656, 1.124246222121839, 1.1260688691438057, 1.1260178404218169, 1.1258260346238556, 1.126508028045987]\n",
      "args {'num_dense2': 292}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.3332 - acc: 0.3295 - val_loss: 1.1653 - val_acc: 0.3261\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.2918 - acc: 0.3303 - val_loss: 1.1609 - val_acc: 0.3372\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2730 - acc: 0.3421 - val_loss: 1.1578 - val_acc: 0.3421\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2470 - acc: 0.3568 - val_loss: 1.1549 - val_acc: 0.3472\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2276 - acc: 0.3656 - val_loss: 1.1574 - val_acc: 0.3478\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2160 - acc: 0.3704 - val_loss: 1.1515 - val_acc: 0.3583\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2025 - acc: 0.3802 - val_loss: 1.1528 - val_acc: 0.3575\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1902 - acc: 0.3848 - val_loss: 1.1523 - val_acc: 0.3622\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1777 - acc: 0.3860 - val_loss: 1.1514 - val_acc: 0.3617\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1800 - acc: 0.3891 - val_loss: 1.1482 - val_acc: 0.3650\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1570 - acc: 0.4013 - val_loss: 1.1519 - val_acc: 0.3658\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1459 - acc: 0.4090 - val_loss: 1.1525 - val_acc: 0.3646\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1449 - acc: 0.4054 - val_loss: 1.1510 - val_acc: 0.3638\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1451 - acc: 0.4149 - val_loss: 1.1519 - val_acc: 0.3634\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1244 - acc: 0.4181 - val_loss: 1.1515 - val_acc: 0.3612\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1203 - acc: 0.4225 - val_loss: 1.1530 - val_acc: 0.3612\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1154 - acc: 0.4246 - val_loss: 1.1536 - val_acc: 0.3595\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1071 - acc: 0.4285 - val_loss: 1.1539 - val_acc: 0.3592\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1024 - acc: 0.4259 - val_loss: 1.1553 - val_acc: 0.3571\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.0960 - acc: 0.4355 - val_loss: 1.1548 - val_acc: 0.3580\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0938 - acc: 0.4368 - val_loss: 1.1551 - val_acc: 0.3578\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0858 - acc: 0.4393 - val_loss: 1.1540 - val_acc: 0.3569\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0835 - acc: 0.4403 - val_loss: 1.1565 - val_acc: 0.3549\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0766 - acc: 0.4422 - val_loss: 1.1569 - val_acc: 0.3542\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0752 - acc: 0.4454 - val_loss: 1.1562 - val_acc: 0.3524\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0721 - acc: 0.4497 - val_loss: 1.1570 - val_acc: 0.3527\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0647 - acc: 0.4569 - val_loss: 1.1581 - val_acc: 0.3524\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0577 - acc: 0.4565 - val_loss: 1.1575 - val_acc: 0.3539\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0627 - acc: 0.4560 - val_loss: 1.1573 - val_acc: 0.3524\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0568 - acc: 0.4620 - val_loss: 1.1588 - val_acc: 0.3495\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0533 - acc: 0.4578 - val_loss: 1.1599 - val_acc: 0.3478\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0500 - acc: 0.4613 - val_loss: 1.1599 - val_acc: 0.3489\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0427 - acc: 0.4662 - val_loss: 1.1622 - val_acc: 0.3472\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0449 - acc: 0.4633 - val_loss: 1.1614 - val_acc: 0.3471\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0434 - acc: 0.4639 - val_loss: 1.1609 - val_acc: 0.3479\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0327 - acc: 0.4764 - val_loss: 1.1614 - val_acc: 0.3476\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0327 - acc: 0.4750 - val_loss: 1.1623 - val_acc: 0.3466\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0306 - acc: 0.4722 - val_loss: 1.1630 - val_acc: 0.3457\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0306 - acc: 0.4741 - val_loss: 1.1638 - val_acc: 0.3466\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0271 - acc: 0.4731 - val_loss: 1.1630 - val_acc: 0.3481\n",
      "[1.1652893214524604, 1.160945669831632, 1.1578100149897854, 1.15489801853814, 1.15738353774723, 1.1514873764495435, 1.152771283560293, 1.1523222117722847, 1.1514051054738847, 1.1482299907330922, 1.1519372157894623, 1.1525244699836752, 1.1509541321840209, 1.1518929271022371, 1.1515035304451509, 1.1529819923135824, 1.1536492661494324, 1.1538970717292392, 1.155349837336943, 1.1547591530334722, 1.1551375077271007, 1.1539746915936795, 1.1565473833266007, 1.1569215465306586, 1.1561547417081994, 1.1570149796535274, 1.1580741866732813, 1.1574893709099585, 1.1573129096537909, 1.158841890600137, 1.159862114558103, 1.1599291241461314, 1.1622391058898427, 1.1613520627450553, 1.1609183799993115, 1.1614428073249006, 1.1623133375469281, 1.1629738294461118, 1.1637944239686555, 1.1630019833021659]\n",
      "args {'num_dense2': 57}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.3439 - acc: 0.2796 - val_loss: 1.1512 - val_acc: 0.3355\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.2635 - acc: 0.3169 - val_loss: 1.1394 - val_acc: 0.3479\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2237 - acc: 0.3354 - val_loss: 1.1343 - val_acc: 0.3495\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.1990 - acc: 0.3568 - val_loss: 1.1333 - val_acc: 0.3476\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.1839 - acc: 0.3604 - val_loss: 1.1324 - val_acc: 0.3484\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.1743 - acc: 0.3664 - val_loss: 1.1332 - val_acc: 0.3489\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.1564 - acc: 0.3787 - val_loss: 1.1321 - val_acc: 0.3496\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1558 - acc: 0.3845 - val_loss: 1.1321 - val_acc: 0.3520\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1478 - acc: 0.3877 - val_loss: 1.1335 - val_acc: 0.3476\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1357 - acc: 0.3940 - val_loss: 1.1344 - val_acc: 0.3479\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1265 - acc: 0.3972 - val_loss: 1.1337 - val_acc: 0.3515\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1206 - acc: 0.4036 - val_loss: 1.1346 - val_acc: 0.3488\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1173 - acc: 0.4040 - val_loss: 1.1341 - val_acc: 0.3503\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1141 - acc: 0.4048 - val_loss: 1.1337 - val_acc: 0.3486\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1034 - acc: 0.4144 - val_loss: 1.1336 - val_acc: 0.3498\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.0997 - acc: 0.4112 - val_loss: 1.1341 - val_acc: 0.3505\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.0973 - acc: 0.4182 - val_loss: 1.1347 - val_acc: 0.3481\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.0947 - acc: 0.4174 - val_loss: 1.1344 - val_acc: 0.3491\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.0861 - acc: 0.4191 - val_loss: 1.1349 - val_acc: 0.3503\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.0851 - acc: 0.4241 - val_loss: 1.1349 - val_acc: 0.3512\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0824 - acc: 0.4231 - val_loss: 1.1355 - val_acc: 0.3479\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0797 - acc: 0.4268 - val_loss: 1.1341 - val_acc: 0.3462\n",
      "Epoch 23/40\n",
      " - 5s - loss: 1.0764 - acc: 0.4336 - val_loss: 1.1353 - val_acc: 0.3462\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0726 - acc: 0.4323 - val_loss: 1.1356 - val_acc: 0.3455\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0684 - acc: 0.4322 - val_loss: 1.1363 - val_acc: 0.3421\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0649 - acc: 0.4333 - val_loss: 1.1356 - val_acc: 0.3443\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0657 - acc: 0.4350 - val_loss: 1.1373 - val_acc: 0.3404\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0632 - acc: 0.4348 - val_loss: 1.1361 - val_acc: 0.3408\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0579 - acc: 0.4413 - val_loss: 1.1365 - val_acc: 0.3415\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0546 - acc: 0.4459 - val_loss: 1.1376 - val_acc: 0.3418\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0555 - acc: 0.4389 - val_loss: 1.1365 - val_acc: 0.3413\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0518 - acc: 0.4479 - val_loss: 1.1362 - val_acc: 0.3399\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0447 - acc: 0.4518 - val_loss: 1.1371 - val_acc: 0.3384\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0472 - acc: 0.4507 - val_loss: 1.1370 - val_acc: 0.3391\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0396 - acc: 0.4592 - val_loss: 1.1376 - val_acc: 0.3396\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0408 - acc: 0.4511 - val_loss: 1.1380 - val_acc: 0.3409\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0367 - acc: 0.4622 - val_loss: 1.1379 - val_acc: 0.3418\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0376 - acc: 0.4665 - val_loss: 1.1386 - val_acc: 0.3403\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0323 - acc: 0.4606 - val_loss: 1.1389 - val_acc: 0.3396\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0262 - acc: 0.4664 - val_loss: 1.1394 - val_acc: 0.3379\n",
      "[1.1512080580402135, 1.1394386931401184, 1.1343265369087863, 1.133314498114001, 1.1324216055935021, 1.133157635254821, 1.1321218933006723, 1.1321264963383895, 1.1335035520288534, 1.1343662485439705, 1.1337349466796791, 1.1345887664878076, 1.1340715602568125, 1.1337082330797283, 1.133567016196186, 1.1340853079788042, 1.1346755934021453, 1.134439024028726, 1.1348985735661976, 1.1348637764720242, 1.1355377425939575, 1.1341392204612089, 1.1352693147815216, 1.1356168939891889, 1.1363236520855564, 1.135625493948726, 1.1372956316867382, 1.136136694889952, 1.1364677381125718, 1.137556497017759, 1.1364541661187153, 1.1362233321088537, 1.1370574310624957, 1.1370180634127, 1.1376464262970136, 1.1380267786394997, 1.1379187412417877, 1.1385815559356025, 1.138884391057069, 1.139373833866795]\n",
      "args {'num_dense2': 130}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.3184 - acc: 0.2633 - val_loss: 1.1358 - val_acc: 0.3466\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.2625 - acc: 0.3150 - val_loss: 1.1140 - val_acc: 0.3902\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2468 - acc: 0.3349 - val_loss: 1.1078 - val_acc: 0.3976\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2210 - acc: 0.3466 - val_loss: 1.1050 - val_acc: 0.4009\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2081 - acc: 0.3490 - val_loss: 1.1027 - val_acc: 0.4065\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.1975 - acc: 0.3594 - val_loss: 1.1031 - val_acc: 0.4063\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.1814 - acc: 0.3709 - val_loss: 1.1026 - val_acc: 0.4070\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1692 - acc: 0.3757 - val_loss: 1.1039 - val_acc: 0.4028\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1686 - acc: 0.3803 - val_loss: 1.1040 - val_acc: 0.4036\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1539 - acc: 0.3882 - val_loss: 1.1054 - val_acc: 0.4004\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1481 - acc: 0.3925 - val_loss: 1.1068 - val_acc: 0.3990\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1406 - acc: 0.3904 - val_loss: 1.1068 - val_acc: 0.3976\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1309 - acc: 0.3982 - val_loss: 1.1070 - val_acc: 0.3961\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1271 - acc: 0.4099 - val_loss: 1.1093 - val_acc: 0.3903\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1186 - acc: 0.4104 - val_loss: 1.1103 - val_acc: 0.3856\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1181 - acc: 0.4111 - val_loss: 1.1102 - val_acc: 0.3830\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1034 - acc: 0.4183 - val_loss: 1.1119 - val_acc: 0.3804\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.0970 - acc: 0.4201 - val_loss: 1.1147 - val_acc: 0.3772\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.0975 - acc: 0.4232 - val_loss: 1.1157 - val_acc: 0.3779\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.0911 - acc: 0.4257 - val_loss: 1.1182 - val_acc: 0.3769\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0883 - acc: 0.4265 - val_loss: 1.1195 - val_acc: 0.3762\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0796 - acc: 0.4354 - val_loss: 1.1188 - val_acc: 0.3745\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0804 - acc: 0.4322 - val_loss: 1.1200 - val_acc: 0.3719\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0703 - acc: 0.4429 - val_loss: 1.1220 - val_acc: 0.3667\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0721 - acc: 0.4387 - val_loss: 1.1223 - val_acc: 0.3653\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0705 - acc: 0.4378 - val_loss: 1.1236 - val_acc: 0.3651\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0666 - acc: 0.4466 - val_loss: 1.1241 - val_acc: 0.3661\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0653 - acc: 0.4435 - val_loss: 1.1260 - val_acc: 0.3621\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0527 - acc: 0.4463 - val_loss: 1.1258 - val_acc: 0.3612\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0552 - acc: 0.4493 - val_loss: 1.1272 - val_acc: 0.3576\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0489 - acc: 0.4531 - val_loss: 1.1288 - val_acc: 0.3547\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0394 - acc: 0.4585 - val_loss: 1.1286 - val_acc: 0.3556\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0423 - acc: 0.4561 - val_loss: 1.1297 - val_acc: 0.3539\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0401 - acc: 0.4612 - val_loss: 1.1313 - val_acc: 0.3513\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0361 - acc: 0.4602 - val_loss: 1.1319 - val_acc: 0.3537\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0356 - acc: 0.4647 - val_loss: 1.1329 - val_acc: 0.3489\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0340 - acc: 0.4620 - val_loss: 1.1324 - val_acc: 0.3515\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0265 - acc: 0.4698 - val_loss: 1.1336 - val_acc: 0.3489\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0262 - acc: 0.4722 - val_loss: 1.1360 - val_acc: 0.3478\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0240 - acc: 0.4771 - val_loss: 1.1362 - val_acc: 0.3469\n",
      "[1.1358201552476805, 1.113968035505643, 1.1078111852547128, 1.1050483819899182, 1.1027250721928858, 1.1031293706608079, 1.102595881805108, 1.1038881985303166, 1.103976653122447, 1.1053659279275005, 1.1067883240754337, 1.1067670099741755, 1.1070268553674059, 1.1093375744546792, 1.110349473251634, 1.1102428400548991, 1.1119351854766097, 1.1146648112044997, 1.1156523068529383, 1.1181517027379382, 1.1195484146435188, 1.1188487590820977, 1.119975112764322, 1.122005847884134, 1.1223384684372988, 1.1236067565325496, 1.1240510066783396, 1.1260242121096202, 1.1258264555918098, 1.1271992424853166, 1.1287557650002211, 1.1286290383793678, 1.129713356982135, 1.1313177415395628, 1.1318744966704448, 1.1328899126286727, 1.1324311757932242, 1.13362223803185, 1.1359984793520104, 1.1361741551911149]\n",
      "args {'num_dense2': 177}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.4190 - acc: 0.2913 - val_loss: 1.2132 - val_acc: 0.3115\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3244 - acc: 0.3214 - val_loss: 1.1817 - val_acc: 0.3432\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.3114 - acc: 0.3288 - val_loss: 1.1742 - val_acc: 0.3450\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2800 - acc: 0.3465 - val_loss: 1.1678 - val_acc: 0.3486\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2674 - acc: 0.3509 - val_loss: 1.1611 - val_acc: 0.3515\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2594 - acc: 0.3527 - val_loss: 1.1565 - val_acc: 0.3522\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2411 - acc: 0.3629 - val_loss: 1.1524 - val_acc: 0.3537\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.2291 - acc: 0.3622 - val_loss: 1.1492 - val_acc: 0.3583\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.2117 - acc: 0.3692 - val_loss: 1.1487 - val_acc: 0.3532\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.2023 - acc: 0.3725 - val_loss: 1.1473 - val_acc: 0.3503\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1890 - acc: 0.3831 - val_loss: 1.1460 - val_acc: 0.3512\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1791 - acc: 0.3802 - val_loss: 1.1438 - val_acc: 0.3506\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1790 - acc: 0.3918 - val_loss: 1.1428 - val_acc: 0.3493\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1646 - acc: 0.3904 - val_loss: 1.1445 - val_acc: 0.3471\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1523 - acc: 0.3997 - val_loss: 1.1450 - val_acc: 0.3471\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1401 - acc: 0.3992 - val_loss: 1.1448 - val_acc: 0.3495\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1394 - acc: 0.4113 - val_loss: 1.1435 - val_acc: 0.3495\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1335 - acc: 0.4081 - val_loss: 1.1457 - val_acc: 0.3435\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1326 - acc: 0.4057 - val_loss: 1.1442 - val_acc: 0.3469\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1184 - acc: 0.4114 - val_loss: 1.1434 - val_acc: 0.3474\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1087 - acc: 0.4194 - val_loss: 1.1452 - val_acc: 0.3464\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.1151 - acc: 0.4194 - val_loss: 1.1463 - val_acc: 0.3442\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.1034 - acc: 0.4224 - val_loss: 1.1468 - val_acc: 0.3432\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0987 - acc: 0.4249 - val_loss: 1.1477 - val_acc: 0.3420\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0919 - acc: 0.4291 - val_loss: 1.1497 - val_acc: 0.3404\n",
      "Epoch 26/40\n",
      " - 5s - loss: 1.0896 - acc: 0.4317 - val_loss: 1.1494 - val_acc: 0.3425\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0840 - acc: 0.4300 - val_loss: 1.1499 - val_acc: 0.3391\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0777 - acc: 0.4366 - val_loss: 1.1509 - val_acc: 0.3375\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0759 - acc: 0.4398 - val_loss: 1.1515 - val_acc: 0.3357\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0713 - acc: 0.4460 - val_loss: 1.1522 - val_acc: 0.3358\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0709 - acc: 0.4395 - val_loss: 1.1528 - val_acc: 0.3338\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0677 - acc: 0.4447 - val_loss: 1.1519 - val_acc: 0.3350\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0633 - acc: 0.4489 - val_loss: 1.1516 - val_acc: 0.3343\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0566 - acc: 0.4453 - val_loss: 1.1543 - val_acc: 0.3290\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0628 - acc: 0.4492 - val_loss: 1.1557 - val_acc: 0.3290\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0485 - acc: 0.4531 - val_loss: 1.1533 - val_acc: 0.3351\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0518 - acc: 0.4558 - val_loss: 1.1536 - val_acc: 0.3345\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0448 - acc: 0.4596 - val_loss: 1.1548 - val_acc: 0.3348\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0359 - acc: 0.4615 - val_loss: 1.1561 - val_acc: 0.3340\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0359 - acc: 0.4630 - val_loss: 1.1572 - val_acc: 0.3295\n",
      "[1.2131719862083, 1.181703279063877, 1.174209619412955, 1.1678425031396933, 1.1611488349431218, 1.156499531028706, 1.1523788488528384, 1.1492282814810646, 1.1487384979341595, 1.1472836924508742, 1.1459566858224064, 1.1438294022219708, 1.1428131407548037, 1.1444720698962094, 1.1450018424753923, 1.1447786648202007, 1.1434535866537276, 1.145700920180339, 1.1442413411283363, 1.143417634821068, 1.1452117930965788, 1.1462930262251185, 1.1467862561223292, 1.1476844201620657, 1.14970585598283, 1.1493974492075658, 1.14994849268682, 1.1509177275509535, 1.1515182389875198, 1.1522147957570545, 1.1527816102680133, 1.1518946411824031, 1.151594302959598, 1.1542859343806795, 1.1557039370004099, 1.1532958044343165, 1.153563530633495, 1.1547565063923517, 1.1561154474679392, 1.1571909660214623]\n",
      "args {'num_dense2': 281}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.4384 - acc: 0.3766 - val_loss: 1.1710 - val_acc: 0.3406\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3104 - acc: 0.3668 - val_loss: 1.1803 - val_acc: 0.3106\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2751 - acc: 0.3517 - val_loss: 1.1841 - val_acc: 0.2997\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2543 - acc: 0.3589 - val_loss: 1.1871 - val_acc: 0.2951\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2556 - acc: 0.3523 - val_loss: 1.1818 - val_acc: 0.2980\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2306 - acc: 0.3645 - val_loss: 1.1770 - val_acc: 0.3042\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2183 - acc: 0.3692 - val_loss: 1.1781 - val_acc: 0.3007\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1958 - acc: 0.3738 - val_loss: 1.1757 - val_acc: 0.3050\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1935 - acc: 0.3821 - val_loss: 1.1715 - val_acc: 0.3099\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1845 - acc: 0.3879 - val_loss: 1.1724 - val_acc: 0.3077\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1638 - acc: 0.3899 - val_loss: 1.1707 - val_acc: 0.3140\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1627 - acc: 0.3990 - val_loss: 1.1726 - val_acc: 0.3098\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1507 - acc: 0.3999 - val_loss: 1.1700 - val_acc: 0.3135\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1403 - acc: 0.3999 - val_loss: 1.1689 - val_acc: 0.3152\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1357 - acc: 0.4056 - val_loss: 1.1670 - val_acc: 0.3178\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1278 - acc: 0.4145 - val_loss: 1.1646 - val_acc: 0.3214\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1215 - acc: 0.4175 - val_loss: 1.1670 - val_acc: 0.3195\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1140 - acc: 0.4166 - val_loss: 1.1668 - val_acc: 0.3195\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1026 - acc: 0.4258 - val_loss: 1.1652 - val_acc: 0.3214\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1027 - acc: 0.4281 - val_loss: 1.1633 - val_acc: 0.3306\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1000 - acc: 0.4276 - val_loss: 1.1641 - val_acc: 0.3299\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0880 - acc: 0.4357 - val_loss: 1.1627 - val_acc: 0.3309\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0849 - acc: 0.4326 - val_loss: 1.1635 - val_acc: 0.3297\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0873 - acc: 0.4392 - val_loss: 1.1652 - val_acc: 0.3251\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0852 - acc: 0.4363 - val_loss: 1.1632 - val_acc: 0.3285\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0753 - acc: 0.4405 - val_loss: 1.1636 - val_acc: 0.3266\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0762 - acc: 0.4396 - val_loss: 1.1614 - val_acc: 0.3312\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0674 - acc: 0.4464 - val_loss: 1.1617 - val_acc: 0.3314\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0663 - acc: 0.4471 - val_loss: 1.1632 - val_acc: 0.3292\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0591 - acc: 0.4564 - val_loss: 1.1626 - val_acc: 0.3312\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0597 - acc: 0.4517 - val_loss: 1.1627 - val_acc: 0.3300\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0584 - acc: 0.4586 - val_loss: 1.1631 - val_acc: 0.3321\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0510 - acc: 0.4538 - val_loss: 1.1631 - val_acc: 0.3340\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0472 - acc: 0.4636 - val_loss: 1.1630 - val_acc: 0.3333\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0446 - acc: 0.4689 - val_loss: 1.1625 - val_acc: 0.3357\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0379 - acc: 0.4632 - val_loss: 1.1640 - val_acc: 0.3357\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0396 - acc: 0.4701 - val_loss: 1.1638 - val_acc: 0.3353\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0294 - acc: 0.4687 - val_loss: 1.1633 - val_acc: 0.3382\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0285 - acc: 0.4733 - val_loss: 1.1641 - val_acc: 0.3358\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0256 - acc: 0.4758 - val_loss: 1.1646 - val_acc: 0.3365\n",
      "[1.1710057736092758, 1.1803249598199081, 1.1840512362747817, 1.1871222959227392, 1.1817955187945666, 1.1770452839152366, 1.178129683398421, 1.1756840158223456, 1.1715392069205925, 1.1723653594544539, 1.1706925779987096, 1.1725967329919176, 1.170000906211479, 1.1689058876817169, 1.1669729064530832, 1.164598666354811, 1.1670015098613356, 1.1667820458840934, 1.1652017373804826, 1.1633248001093435, 1.1640676484120964, 1.1627007839790158, 1.163457135413583, 1.165150296785526, 1.1632110117566683, 1.1636475399339556, 1.1614304504862274, 1.1616924640593151, 1.1631648930281968, 1.162582530637528, 1.162672211753575, 1.1631380816571395, 1.1630954245455583, 1.1629524266687337, 1.1624712625706228, 1.1639717508726615, 1.1638169327613768, 1.1632663339620066, 1.164147767448945, 1.164590459428626]\n",
      "args {'num_dense2': 206}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.7570 - acc: 0.2604 - val_loss: 1.3738 - val_acc: 0.2585\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.4392 - acc: 0.2669 - val_loss: 1.2117 - val_acc: 0.2994\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.3127 - acc: 0.3114 - val_loss: 1.1515 - val_acc: 0.3770\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2741 - acc: 0.3427 - val_loss: 1.1337 - val_acc: 0.4009\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2619 - acc: 0.3645 - val_loss: 1.1283 - val_acc: 0.4045\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2485 - acc: 0.3661 - val_loss: 1.1254 - val_acc: 0.4038\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2348 - acc: 0.3703 - val_loss: 1.1230 - val_acc: 0.4057\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.2161 - acc: 0.3805 - val_loss: 1.1215 - val_acc: 0.4050\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.2100 - acc: 0.3843 - val_loss: 1.1218 - val_acc: 0.4004\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1872 - acc: 0.3889 - val_loss: 1.1192 - val_acc: 0.4057\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1903 - acc: 0.3878 - val_loss: 1.1186 - val_acc: 0.4033\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1717 - acc: 0.3969 - val_loss: 1.1184 - val_acc: 0.3994\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1594 - acc: 0.4104 - val_loss: 1.1192 - val_acc: 0.3915\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1633 - acc: 0.4041 - val_loss: 1.1203 - val_acc: 0.3869\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1475 - acc: 0.4070 - val_loss: 1.1223 - val_acc: 0.3840\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1354 - acc: 0.4121 - val_loss: 1.1221 - val_acc: 0.3830\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1340 - acc: 0.4108 - val_loss: 1.1208 - val_acc: 0.3842\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1308 - acc: 0.4197 - val_loss: 1.1235 - val_acc: 0.3818\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1215 - acc: 0.4220 - val_loss: 1.1252 - val_acc: 0.3786\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1201 - acc: 0.4228 - val_loss: 1.1264 - val_acc: 0.3776\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1098 - acc: 0.4241 - val_loss: 1.1273 - val_acc: 0.3765\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.1030 - acc: 0.4294 - val_loss: 1.1266 - val_acc: 0.3762\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.1038 - acc: 0.4336 - val_loss: 1.1288 - val_acc: 0.3748\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.1002 - acc: 0.4279 - val_loss: 1.1295 - val_acc: 0.3724\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0922 - acc: 0.4390 - val_loss: 1.1314 - val_acc: 0.3713\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0845 - acc: 0.4382 - val_loss: 1.1331 - val_acc: 0.3694\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0815 - acc: 0.4484 - val_loss: 1.1340 - val_acc: 0.3668\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0783 - acc: 0.4405 - val_loss: 1.1356 - val_acc: 0.3661\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0703 - acc: 0.4418 - val_loss: 1.1364 - val_acc: 0.3694\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0743 - acc: 0.4475 - val_loss: 1.1378 - val_acc: 0.3684\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0680 - acc: 0.4477 - val_loss: 1.1394 - val_acc: 0.3648\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0603 - acc: 0.4518 - val_loss: 1.1401 - val_acc: 0.3656\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0577 - acc: 0.4578 - val_loss: 1.1405 - val_acc: 0.3655\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0562 - acc: 0.4533 - val_loss: 1.1422 - val_acc: 0.3629\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0498 - acc: 0.4598 - val_loss: 1.1432 - val_acc: 0.3595\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0438 - acc: 0.4615 - val_loss: 1.1446 - val_acc: 0.3566\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0406 - acc: 0.4718 - val_loss: 1.1434 - val_acc: 0.3578\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0465 - acc: 0.4644 - val_loss: 1.1458 - val_acc: 0.3546\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0374 - acc: 0.4671 - val_loss: 1.1473 - val_acc: 0.3546\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0381 - acc: 0.4667 - val_loss: 1.1478 - val_acc: 0.3517\n",
      "[1.3737733484288976, 1.2117219552681946, 1.1515130473742368, 1.1336847017506488, 1.1282782697547684, 1.1253642876726404, 1.12302613323326, 1.121483565351294, 1.1217904311759594, 1.1191733805944875, 1.1185603222989906, 1.1184153612043293, 1.1191685716202864, 1.1203286287245373, 1.122277063634805, 1.122050083300723, 1.120822589468891, 1.1234707026780464, 1.1252172610415425, 1.1264422703179091, 1.1272808277639446, 1.1266095056845642, 1.1287801603530343, 1.1295300078976707, 1.13142897614991, 1.1330916904298747, 1.1340231216570986, 1.1355544923111918, 1.1364050093398756, 1.1377717620345487, 1.1393758464574164, 1.1400563327103286, 1.1404708659616414, 1.1421983284261636, 1.1432065564215346, 1.1445577472691966, 1.1433792757403298, 1.1458085460299043, 1.1473491253579995, 1.1478215797070912]\n",
      "args {'num_dense2': 79}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.3214 - acc: 0.2963 - val_loss: 1.1791 - val_acc: 0.2868\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.2805 - acc: 0.3353 - val_loss: 1.1639 - val_acc: 0.3001\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2487 - acc: 0.3500 - val_loss: 1.1540 - val_acc: 0.3094\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2265 - acc: 0.3680 - val_loss: 1.1468 - val_acc: 0.3162\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2112 - acc: 0.3736 - val_loss: 1.1431 - val_acc: 0.3181\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.1946 - acc: 0.3750 - val_loss: 1.1407 - val_acc: 0.3232\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.1848 - acc: 0.3792 - val_loss: 1.1365 - val_acc: 0.3270\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1714 - acc: 0.3871 - val_loss: 1.1351 - val_acc: 0.3336\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1640 - acc: 0.3923 - val_loss: 1.1322 - val_acc: 0.3369\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1507 - acc: 0.3955 - val_loss: 1.1299 - val_acc: 0.3443\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1413 - acc: 0.4060 - val_loss: 1.1293 - val_acc: 0.3460\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1360 - acc: 0.4077 - val_loss: 1.1286 - val_acc: 0.3498\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1275 - acc: 0.4136 - val_loss: 1.1286 - val_acc: 0.3515\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1155 - acc: 0.4245 - val_loss: 1.1289 - val_acc: 0.3508\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1142 - acc: 0.4174 - val_loss: 1.1286 - val_acc: 0.3481\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1068 - acc: 0.4200 - val_loss: 1.1284 - val_acc: 0.3515\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1054 - acc: 0.4218 - val_loss: 1.1272 - val_acc: 0.3541\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.0970 - acc: 0.4277 - val_loss: 1.1281 - val_acc: 0.3500\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.0888 - acc: 0.4283 - val_loss: 1.1285 - val_acc: 0.3512\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.0911 - acc: 0.4289 - val_loss: 1.1272 - val_acc: 0.3535\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0931 - acc: 0.4313 - val_loss: 1.1287 - val_acc: 0.3529\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0846 - acc: 0.4363 - val_loss: 1.1288 - val_acc: 0.3529\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0781 - acc: 0.4364 - val_loss: 1.1293 - val_acc: 0.3505\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0725 - acc: 0.4412 - val_loss: 1.1295 - val_acc: 0.3527\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0728 - acc: 0.4480 - val_loss: 1.1304 - val_acc: 0.3532\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0656 - acc: 0.4467 - val_loss: 1.1310 - val_acc: 0.3522\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0591 - acc: 0.4547 - val_loss: 1.1325 - val_acc: 0.3508\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0640 - acc: 0.4471 - val_loss: 1.1335 - val_acc: 0.3524\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0605 - acc: 0.4483 - val_loss: 1.1334 - val_acc: 0.3489\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0539 - acc: 0.4569 - val_loss: 1.1329 - val_acc: 0.3518\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0533 - acc: 0.4568 - val_loss: 1.1347 - val_acc: 0.3503\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0512 - acc: 0.4598 - val_loss: 1.1351 - val_acc: 0.3505\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0522 - acc: 0.4564 - val_loss: 1.1373 - val_acc: 0.3466\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0465 - acc: 0.4546 - val_loss: 1.1369 - val_acc: 0.3471\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0412 - acc: 0.4632 - val_loss: 1.1363 - val_acc: 0.3500\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0396 - acc: 0.4660 - val_loss: 1.1357 - val_acc: 0.3513\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0328 - acc: 0.4696 - val_loss: 1.1377 - val_acc: 0.3478\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0388 - acc: 0.4628 - val_loss: 1.1381 - val_acc: 0.3464\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0357 - acc: 0.4671 - val_loss: 1.1382 - val_acc: 0.3467\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0270 - acc: 0.4787 - val_loss: 1.1394 - val_acc: 0.3443\n",
      "[1.179117886831715, 1.163862472009269, 1.1539742703009042, 1.146778756006537, 1.1431192071951053, 1.1406864674929378, 1.1364792244310924, 1.1351037808270155, 1.1322420491184786, 1.1299093276343488, 1.1292958480460766, 1.1285578792036717, 1.1286240179467266, 1.1288564247396402, 1.128572468536751, 1.1283504914198, 1.1271957740471863, 1.1281250848432327, 1.1284657076853821, 1.127196583176179, 1.1286950163360512, 1.1288040207257388, 1.1292693705909584, 1.1294567195206313, 1.130350407202822, 1.1310326604817154, 1.1324658663461253, 1.133465222182001, 1.1333777440016537, 1.1329232717404898, 1.1347239751581926, 1.1351343328361616, 1.1373395669687671, 1.1369127018899943, 1.1362738245514499, 1.1356531810370714, 1.1377140644135852, 1.1380584464086174, 1.1382228808441994, 1.1394096999467231]\n",
      "args {'num_dense2': 63}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.2923 - acc: 0.2921 - val_loss: 1.1555 - val_acc: 0.3212\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.2390 - acc: 0.3414 - val_loss: 1.1257 - val_acc: 0.3636\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2192 - acc: 0.3601 - val_loss: 1.1150 - val_acc: 0.3781\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2081 - acc: 0.3638 - val_loss: 1.1107 - val_acc: 0.3796\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.1878 - acc: 0.3777 - val_loss: 1.1064 - val_acc: 0.3871\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.1784 - acc: 0.3829 - val_loss: 1.1051 - val_acc: 0.3886\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.1659 - acc: 0.3826 - val_loss: 1.1022 - val_acc: 0.3937\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1564 - acc: 0.3883 - val_loss: 1.1002 - val_acc: 0.3961\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1419 - acc: 0.4014 - val_loss: 1.1000 - val_acc: 0.3941\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1438 - acc: 0.4004 - val_loss: 1.0995 - val_acc: 0.3963\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1257 - acc: 0.4004 - val_loss: 1.0993 - val_acc: 0.3961\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1217 - acc: 0.4027 - val_loss: 1.0979 - val_acc: 0.3980\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1114 - acc: 0.4119 - val_loss: 1.0980 - val_acc: 0.3961\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1137 - acc: 0.4130 - val_loss: 1.0986 - val_acc: 0.3944\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1028 - acc: 0.4196 - val_loss: 1.0987 - val_acc: 0.3915\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.0966 - acc: 0.4237 - val_loss: 1.0995 - val_acc: 0.3888\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.0915 - acc: 0.4246 - val_loss: 1.1008 - val_acc: 0.3893\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.0891 - acc: 0.4330 - val_loss: 1.1008 - val_acc: 0.3890\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.0850 - acc: 0.4338 - val_loss: 1.1013 - val_acc: 0.3837\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.0836 - acc: 0.4329 - val_loss: 1.1013 - val_acc: 0.3825\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0777 - acc: 0.4384 - val_loss: 1.1027 - val_acc: 0.3813\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0732 - acc: 0.4359 - val_loss: 1.1040 - val_acc: 0.3806\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0731 - acc: 0.4343 - val_loss: 1.1037 - val_acc: 0.3808\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0633 - acc: 0.4493 - val_loss: 1.1043 - val_acc: 0.3796\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0674 - acc: 0.4451 - val_loss: 1.1054 - val_acc: 0.3787\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0564 - acc: 0.4517 - val_loss: 1.1071 - val_acc: 0.3762\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0551 - acc: 0.4509 - val_loss: 1.1069 - val_acc: 0.3776\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0517 - acc: 0.4551 - val_loss: 1.1084 - val_acc: 0.3772\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0464 - acc: 0.4568 - val_loss: 1.1084 - val_acc: 0.3770\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0485 - acc: 0.4539 - val_loss: 1.1092 - val_acc: 0.3736\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0429 - acc: 0.4570 - val_loss: 1.1107 - val_acc: 0.3721\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0449 - acc: 0.4588 - val_loss: 1.1115 - val_acc: 0.3711\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0414 - acc: 0.4689 - val_loss: 1.1118 - val_acc: 0.3714\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0409 - acc: 0.4657 - val_loss: 1.1121 - val_acc: 0.3706\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0397 - acc: 0.4635 - val_loss: 1.1128 - val_acc: 0.3689\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0331 - acc: 0.4701 - val_loss: 1.1133 - val_acc: 0.3697\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0303 - acc: 0.4717 - val_loss: 1.1136 - val_acc: 0.3719\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0275 - acc: 0.4721 - val_loss: 1.1141 - val_acc: 0.3702\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0254 - acc: 0.4746 - val_loss: 1.1145 - val_acc: 0.3673\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0206 - acc: 0.4790 - val_loss: 1.1161 - val_acc: 0.3646\n",
      "[1.1554866464001605, 1.1256537976641745, 1.1149800444169005, 1.1107341528588486, 1.1063912197419667, 1.1050631814821539, 1.1021675608788264, 1.1002410647005085, 1.099969477679489, 1.0995339246147011, 1.099302982439462, 1.0979480944797193, 1.0980382469109684, 1.0986292378454183, 1.0987345064693317, 1.099515179522356, 1.1007695945147273, 1.1007558623841414, 1.1013427066543122, 1.1013171286284111, 1.1027228819252035, 1.1040310382193375, 1.1036816598284147, 1.1042753834815375, 1.1054005840493808, 1.1071002668515864, 1.1069150464736148, 1.1083658478890193, 1.1084119978003022, 1.109159866860517, 1.1107320535410328, 1.1114777355817749, 1.1118466071276965, 1.1121469398285453, 1.1128026870680765, 1.1133094347140444, 1.113609392896335, 1.114087085957748, 1.1145351771113008, 1.116140023888944]\n",
      "args {'num_dense2': 331}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.4760 - acc: 0.4445 - val_loss: 1.1077 - val_acc: 0.4091\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3078 - acc: 0.3937 - val_loss: 1.1465 - val_acc: 0.3421\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2692 - acc: 0.3661 - val_loss: 1.1650 - val_acc: 0.3147\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2489 - acc: 0.3476 - val_loss: 1.1696 - val_acc: 0.3106\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2308 - acc: 0.3607 - val_loss: 1.1663 - val_acc: 0.3132\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2171 - acc: 0.3673 - val_loss: 1.1693 - val_acc: 0.3082\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2131 - acc: 0.3645 - val_loss: 1.1676 - val_acc: 0.3101\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.2038 - acc: 0.3724 - val_loss: 1.1685 - val_acc: 0.3128\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1929 - acc: 0.3737 - val_loss: 1.1669 - val_acc: 0.3123\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1797 - acc: 0.3758 - val_loss: 1.1669 - val_acc: 0.3132\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1652 - acc: 0.3780 - val_loss: 1.1665 - val_acc: 0.3128\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1624 - acc: 0.3911 - val_loss: 1.1652 - val_acc: 0.3111\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1481 - acc: 0.3968 - val_loss: 1.1634 - val_acc: 0.3142\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1406 - acc: 0.4010 - val_loss: 1.1661 - val_acc: 0.3110\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1388 - acc: 0.3987 - val_loss: 1.1652 - val_acc: 0.3132\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1360 - acc: 0.4028 - val_loss: 1.1650 - val_acc: 0.3122\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1193 - acc: 0.4101 - val_loss: 1.1643 - val_acc: 0.3157\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1187 - acc: 0.4143 - val_loss: 1.1639 - val_acc: 0.3171\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1161 - acc: 0.4134 - val_loss: 1.1648 - val_acc: 0.3151\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1090 - acc: 0.4185 - val_loss: 1.1654 - val_acc: 0.3173\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1059 - acc: 0.4182 - val_loss: 1.1668 - val_acc: 0.3152\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0991 - acc: 0.4172 - val_loss: 1.1662 - val_acc: 0.3185\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0875 - acc: 0.4240 - val_loss: 1.1651 - val_acc: 0.3198\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0842 - acc: 0.4315 - val_loss: 1.1653 - val_acc: 0.3176\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0815 - acc: 0.4339 - val_loss: 1.1679 - val_acc: 0.3144\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0715 - acc: 0.4360 - val_loss: 1.1677 - val_acc: 0.3154\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0753 - acc: 0.4367 - val_loss: 1.1682 - val_acc: 0.3152\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0678 - acc: 0.4424 - val_loss: 1.1685 - val_acc: 0.3140\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0652 - acc: 0.4449 - val_loss: 1.1673 - val_acc: 0.3145\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0610 - acc: 0.4404 - val_loss: 1.1680 - val_acc: 0.3134\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0544 - acc: 0.4472 - val_loss: 1.1690 - val_acc: 0.3154\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0562 - acc: 0.4513 - val_loss: 1.1686 - val_acc: 0.3166\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0473 - acc: 0.4509 - val_loss: 1.1685 - val_acc: 0.3178\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0480 - acc: 0.4542 - val_loss: 1.1692 - val_acc: 0.3161\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0479 - acc: 0.4543 - val_loss: 1.1713 - val_acc: 0.3135\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0404 - acc: 0.4565 - val_loss: 1.1704 - val_acc: 0.3145\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0340 - acc: 0.4645 - val_loss: 1.1693 - val_acc: 0.3171\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0415 - acc: 0.4572 - val_loss: 1.1717 - val_acc: 0.3132\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0305 - acc: 0.4625 - val_loss: 1.1715 - val_acc: 0.3147\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0278 - acc: 0.4739 - val_loss: 1.1708 - val_acc: 0.3171\n",
      "[1.1076975394984356, 1.1465111035417146, 1.16504502036591, 1.169614458928641, 1.1663054533160675, 1.169349849711322, 1.167551513588721, 1.168476400323395, 1.1669115260121607, 1.1668603394271893, 1.1665413782447172, 1.1651903407125448, 1.1634411811828613, 1.166066829125303, 1.165178929427664, 1.1650168145385036, 1.1642904642167469, 1.1639333684048145, 1.1648394762657643, 1.1654371211574253, 1.166840712445958, 1.16622003157717, 1.1651485794571506, 1.165329222783081, 1.1678625013912731, 1.1676728946311596, 1.1681601075450472, 1.1685175859960613, 1.1672873243648934, 1.1680472588993873, 1.1690293950021104, 1.168642999040983, 1.1684587284394765, 1.1691950527133994, 1.1713379972312365, 1.1704379654710235, 1.1692781126791514, 1.1717042016723176, 1.1714681633811557, 1.1707677617060066]\n",
      "args {'num_dense2': 230}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.4919 - acc: 0.3474 - val_loss: 1.1632 - val_acc: 0.3495\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3130 - acc: 0.3642 - val_loss: 1.1547 - val_acc: 0.3171\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2571 - acc: 0.3597 - val_loss: 1.1568 - val_acc: 0.2987\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2498 - acc: 0.3534 - val_loss: 1.1593 - val_acc: 0.2873\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2271 - acc: 0.3601 - val_loss: 1.1573 - val_acc: 0.2866\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2151 - acc: 0.3633 - val_loss: 1.1544 - val_acc: 0.2912\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2025 - acc: 0.3715 - val_loss: 1.1504 - val_acc: 0.2934\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1872 - acc: 0.3822 - val_loss: 1.1488 - val_acc: 0.2968\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1716 - acc: 0.3870 - val_loss: 1.1453 - val_acc: 0.3033\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1726 - acc: 0.3887 - val_loss: 1.1449 - val_acc: 0.3043\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1545 - acc: 0.4044 - val_loss: 1.1451 - val_acc: 0.3081\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1496 - acc: 0.4021 - val_loss: 1.1434 - val_acc: 0.3140\n",
      "Epoch 13/40\n",
      " - 5s - loss: 1.1464 - acc: 0.4040 - val_loss: 1.1440 - val_acc: 0.3168\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1280 - acc: 0.4136 - val_loss: 1.1424 - val_acc: 0.3227\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1316 - acc: 0.4051 - val_loss: 1.1416 - val_acc: 0.3285\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1227 - acc: 0.4163 - val_loss: 1.1425 - val_acc: 0.3271\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1193 - acc: 0.4253 - val_loss: 1.1437 - val_acc: 0.3300\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1108 - acc: 0.4232 - val_loss: 1.1411 - val_acc: 0.3362\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.0984 - acc: 0.4302 - val_loss: 1.1406 - val_acc: 0.3375\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1050 - acc: 0.4222 - val_loss: 1.1416 - val_acc: 0.3389\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0977 - acc: 0.4292 - val_loss: 1.1410 - val_acc: 0.3396\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0950 - acc: 0.4354 - val_loss: 1.1425 - val_acc: 0.3415\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0864 - acc: 0.4385 - val_loss: 1.1424 - val_acc: 0.3420\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0808 - acc: 0.4401 - val_loss: 1.1422 - val_acc: 0.3433\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0826 - acc: 0.4438 - val_loss: 1.1433 - val_acc: 0.3408\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0698 - acc: 0.4473 - val_loss: 1.1423 - val_acc: 0.3443\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0675 - acc: 0.4493 - val_loss: 1.1430 - val_acc: 0.3445\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0679 - acc: 0.4496 - val_loss: 1.1434 - val_acc: 0.3455\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0637 - acc: 0.4515 - val_loss: 1.1412 - val_acc: 0.3500\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0647 - acc: 0.4510 - val_loss: 1.1438 - val_acc: 0.3455\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0595 - acc: 0.4594 - val_loss: 1.1432 - val_acc: 0.3495\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0544 - acc: 0.4560 - val_loss: 1.1447 - val_acc: 0.3501\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0497 - acc: 0.4594 - val_loss: 1.1437 - val_acc: 0.3506\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0484 - acc: 0.4580 - val_loss: 1.1442 - val_acc: 0.3495\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0470 - acc: 0.4656 - val_loss: 1.1455 - val_acc: 0.3486\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0438 - acc: 0.4651 - val_loss: 1.1457 - val_acc: 0.3481\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0343 - acc: 0.4720 - val_loss: 1.1452 - val_acc: 0.3481\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0335 - acc: 0.4747 - val_loss: 1.1453 - val_acc: 0.3472\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0315 - acc: 0.4732 - val_loss: 1.1436 - val_acc: 0.3506\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0292 - acc: 0.4757 - val_loss: 1.1453 - val_acc: 0.3476\n",
      "[1.1631641397684083, 1.154683335925318, 1.15677205743192, 1.1593121030350146, 1.1572749367851651, 1.1544496032132765, 1.1504433986601452, 1.14883080620207, 1.1452605990687899, 1.1449244642777403, 1.145071630257027, 1.1433996998321783, 1.143973106584367, 1.142427812155326, 1.1416325549663575, 1.142465564795346, 1.1436807323216742, 1.141134350111439, 1.1405663854094876, 1.1416171630007044, 1.1409579141913058, 1.1425096891231692, 1.142402956856044, 1.1421686596051874, 1.1433302017908331, 1.1422726276460071, 1.143012189735184, 1.1433927083859976, 1.1411796441195121, 1.1437938508935455, 1.143179690155736, 1.144657602751937, 1.1437221794752075, 1.1441806405376673, 1.1454556816605197, 1.145656643186668, 1.1451779412313767, 1.145287740457935, 1.143610701249146, 1.145261800256672]\n",
      "args {'num_dense2': 98}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.4062 - acc: 0.2966 - val_loss: 1.1801 - val_acc: 0.3035\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3113 - acc: 0.3471 - val_loss: 1.1593 - val_acc: 0.3333\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2850 - acc: 0.3578 - val_loss: 1.1508 - val_acc: 0.3452\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2689 - acc: 0.3606 - val_loss: 1.1465 - val_acc: 0.3445\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2415 - acc: 0.3709 - val_loss: 1.1399 - val_acc: 0.3491\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2300 - acc: 0.3725 - val_loss: 1.1358 - val_acc: 0.3532\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2147 - acc: 0.3796 - val_loss: 1.1346 - val_acc: 0.3530\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1933 - acc: 0.3868 - val_loss: 1.1311 - val_acc: 0.3587\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1835 - acc: 0.3948 - val_loss: 1.1292 - val_acc: 0.3622\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1730 - acc: 0.4020 - val_loss: 1.1290 - val_acc: 0.3583\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1624 - acc: 0.3992 - val_loss: 1.1285 - val_acc: 0.3585\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1501 - acc: 0.4057 - val_loss: 1.1270 - val_acc: 0.3592\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1414 - acc: 0.4098 - val_loss: 1.1246 - val_acc: 0.3624\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1401 - acc: 0.4102 - val_loss: 1.1247 - val_acc: 0.3667\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1319 - acc: 0.4193 - val_loss: 1.1242 - val_acc: 0.3672\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1231 - acc: 0.4224 - val_loss: 1.1249 - val_acc: 0.3677\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1189 - acc: 0.4231 - val_loss: 1.1243 - val_acc: 0.3678\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1146 - acc: 0.4275 - val_loss: 1.1263 - val_acc: 0.3638\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1052 - acc: 0.4304 - val_loss: 1.1269 - val_acc: 0.3626\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1058 - acc: 0.4247 - val_loss: 1.1268 - val_acc: 0.3639\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0958 - acc: 0.4325 - val_loss: 1.1252 - val_acc: 0.3660\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0919 - acc: 0.4410 - val_loss: 1.1259 - val_acc: 0.3653\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0916 - acc: 0.4380 - val_loss: 1.1275 - val_acc: 0.3626\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0839 - acc: 0.4402 - val_loss: 1.1278 - val_acc: 0.3632\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0784 - acc: 0.4449 - val_loss: 1.1271 - val_acc: 0.3629\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0722 - acc: 0.4493 - val_loss: 1.1279 - val_acc: 0.3610\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0760 - acc: 0.4476 - val_loss: 1.1291 - val_acc: 0.3575\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0698 - acc: 0.4493 - val_loss: 1.1292 - val_acc: 0.3573\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0634 - acc: 0.4510 - val_loss: 1.1279 - val_acc: 0.3573\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0603 - acc: 0.4553 - val_loss: 1.1298 - val_acc: 0.3549\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0583 - acc: 0.4587 - val_loss: 1.1312 - val_acc: 0.3539\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0525 - acc: 0.4526 - val_loss: 1.1323 - val_acc: 0.3556\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0520 - acc: 0.4601 - val_loss: 1.1325 - val_acc: 0.3546\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0463 - acc: 0.4633 - val_loss: 1.1321 - val_acc: 0.3552\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0479 - acc: 0.4611 - val_loss: 1.1325 - val_acc: 0.3551\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0403 - acc: 0.4643 - val_loss: 1.1337 - val_acc: 0.3530\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0388 - acc: 0.4649 - val_loss: 1.1359 - val_acc: 0.3495\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0370 - acc: 0.4684 - val_loss: 1.1340 - val_acc: 0.3522\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0311 - acc: 0.4690 - val_loss: 1.1364 - val_acc: 0.3496\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0303 - acc: 0.4754 - val_loss: 1.1377 - val_acc: 0.3471\n",
      "[1.180075640574463, 1.1593270675362943, 1.1508115354610724, 1.1465231089241172, 1.139918715817402, 1.1358025626200745, 1.1345521773564393, 1.1311023852480855, 1.1291713337807305, 1.1290283833277648, 1.1284968511934825, 1.1269708521034802, 1.124604549654823, 1.124663911333526, 1.1242034038990656, 1.1248771280293894, 1.1242569291948947, 1.1263229781990156, 1.126863641375092, 1.1267915450909483, 1.125212940273233, 1.1258929220792058, 1.1274894589624223, 1.1277649610503817, 1.1270644245745376, 1.1279396975072917, 1.1290674359012365, 1.1291968107873154, 1.1279199779520892, 1.129809090486989, 1.1311722948375775, 1.1323129685763118, 1.1324647138813861, 1.1321410340249376, 1.132499721459537, 1.1337079238501817, 1.1359042293044461, 1.134025728670063, 1.136398003601573, 1.1377046822851944]\n",
      "args {'num_dense2': 255}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.3479 - acc: 0.3218 - val_loss: 1.1654 - val_acc: 0.3149\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3168 - acc: 0.3102 - val_loss: 1.1600 - val_acc: 0.3231\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2868 - acc: 0.3235 - val_loss: 1.1560 - val_acc: 0.3217\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2679 - acc: 0.3225 - val_loss: 1.1509 - val_acc: 0.3266\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2461 - acc: 0.3372 - val_loss: 1.1465 - val_acc: 0.3328\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2344 - acc: 0.3380 - val_loss: 1.1449 - val_acc: 0.3351\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2158 - acc: 0.3551 - val_loss: 1.1435 - val_acc: 0.3380\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1953 - acc: 0.3551 - val_loss: 1.1435 - val_acc: 0.3365\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1945 - acc: 0.3663 - val_loss: 1.1425 - val_acc: 0.3394\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1712 - acc: 0.3752 - val_loss: 1.1430 - val_acc: 0.3435\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1686 - acc: 0.3706 - val_loss: 1.1428 - val_acc: 0.3449\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1541 - acc: 0.3836 - val_loss: 1.1419 - val_acc: 0.3459\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1451 - acc: 0.3895 - val_loss: 1.1433 - val_acc: 0.3469\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1411 - acc: 0.3873 - val_loss: 1.1423 - val_acc: 0.3495\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1359 - acc: 0.3900 - val_loss: 1.1439 - val_acc: 0.3501\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1298 - acc: 0.3925 - val_loss: 1.1434 - val_acc: 0.3522\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1235 - acc: 0.4046 - val_loss: 1.1445 - val_acc: 0.3500\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1149 - acc: 0.4003 - val_loss: 1.1463 - val_acc: 0.3464\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1040 - acc: 0.4056 - val_loss: 1.1458 - val_acc: 0.3488\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1034 - acc: 0.4150 - val_loss: 1.1466 - val_acc: 0.3498\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0998 - acc: 0.4142 - val_loss: 1.1474 - val_acc: 0.3503\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0929 - acc: 0.4157 - val_loss: 1.1482 - val_acc: 0.3495\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0936 - acc: 0.4239 - val_loss: 1.1484 - val_acc: 0.3503\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0894 - acc: 0.4234 - val_loss: 1.1488 - val_acc: 0.3493\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0773 - acc: 0.4300 - val_loss: 1.1494 - val_acc: 0.3488\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0741 - acc: 0.4338 - val_loss: 1.1489 - val_acc: 0.3512\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0759 - acc: 0.4333 - val_loss: 1.1497 - val_acc: 0.3488\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0648 - acc: 0.4404 - val_loss: 1.1494 - val_acc: 0.3500\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0657 - acc: 0.4311 - val_loss: 1.1498 - val_acc: 0.3501\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0580 - acc: 0.4451 - val_loss: 1.1506 - val_acc: 0.3503\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0620 - acc: 0.4427 - val_loss: 1.1511 - val_acc: 0.3493\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0538 - acc: 0.4463 - val_loss: 1.1534 - val_acc: 0.3464\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0515 - acc: 0.4465 - val_loss: 1.1546 - val_acc: 0.3466\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0460 - acc: 0.4503 - val_loss: 1.1543 - val_acc: 0.3464\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0501 - acc: 0.4489 - val_loss: 1.1534 - val_acc: 0.3476\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0506 - acc: 0.4569 - val_loss: 1.1558 - val_acc: 0.3438\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0429 - acc: 0.4589 - val_loss: 1.1563 - val_acc: 0.3442\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0361 - acc: 0.4595 - val_loss: 1.1546 - val_acc: 0.3457\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0348 - acc: 0.4642 - val_loss: 1.1563 - val_acc: 0.3443\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0337 - acc: 0.4611 - val_loss: 1.1561 - val_acc: 0.3442\n",
      "[1.1653987133535442, 1.1599705326459713, 1.1559744284003568, 1.1508619843776609, 1.1464753323095047, 1.1449409456928679, 1.1434618725114039, 1.1434959631200057, 1.1424761078338208, 1.1430255980192803, 1.1428119814688242, 1.141903049614514, 1.1433088896385006, 1.1423283987539017, 1.143910855948113, 1.1433790077630441, 1.1445188506097819, 1.14630387849314, 1.1457940346538533, 1.146628463950404, 1.1473937797936171, 1.1481659045336357, 1.148434581808563, 1.1487810780631749, 1.149355193574682, 1.1488680560192555, 1.1497135695059877, 1.1494006097154332, 1.1497616761386882, 1.150554156108513, 1.1511218151539484, 1.1533774699437196, 1.1546042608630105, 1.1542671201014714, 1.1534484114893775, 1.1558203671218914, 1.1563410089841006, 1.1545763899260062, 1.1562686424489241, 1.1560987867516457]\n",
      "args {'num_dense2': 121}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.4316 - acc: 0.2363 - val_loss: 1.2137 - val_acc: 0.3212\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3159 - acc: 0.3041 - val_loss: 1.1449 - val_acc: 0.3716\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2731 - acc: 0.3412 - val_loss: 1.1246 - val_acc: 0.3924\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2479 - acc: 0.3636 - val_loss: 1.1199 - val_acc: 0.3988\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2361 - acc: 0.3718 - val_loss: 1.1183 - val_acc: 0.4007\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2179 - acc: 0.3771 - val_loss: 1.1181 - val_acc: 0.4007\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2084 - acc: 0.3821 - val_loss: 1.1180 - val_acc: 0.4017\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1991 - acc: 0.3879 - val_loss: 1.1187 - val_acc: 0.3975\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1859 - acc: 0.3829 - val_loss: 1.1194 - val_acc: 0.3973\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1801 - acc: 0.3923 - val_loss: 1.1222 - val_acc: 0.3937\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1681 - acc: 0.3959 - val_loss: 1.1240 - val_acc: 0.3922\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1548 - acc: 0.3972 - val_loss: 1.1244 - val_acc: 0.3907\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1457 - acc: 0.4058 - val_loss: 1.1252 - val_acc: 0.3922\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1412 - acc: 0.4074 - val_loss: 1.1274 - val_acc: 0.3908\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1310 - acc: 0.4138 - val_loss: 1.1290 - val_acc: 0.3868\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1290 - acc: 0.4174 - val_loss: 1.1298 - val_acc: 0.3833\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1282 - acc: 0.4172 - val_loss: 1.1309 - val_acc: 0.3798\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1128 - acc: 0.4224 - val_loss: 1.1343 - val_acc: 0.3711\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1140 - acc: 0.4180 - val_loss: 1.1338 - val_acc: 0.3718\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1052 - acc: 0.4268 - val_loss: 1.1344 - val_acc: 0.3709\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1080 - acc: 0.4194 - val_loss: 1.1366 - val_acc: 0.3667\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0949 - acc: 0.4323 - val_loss: 1.1373 - val_acc: 0.3672\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0892 - acc: 0.4358 - val_loss: 1.1394 - val_acc: 0.3656\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0881 - acc: 0.4315 - val_loss: 1.1391 - val_acc: 0.3665\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0805 - acc: 0.4375 - val_loss: 1.1402 - val_acc: 0.3643\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0788 - acc: 0.4415 - val_loss: 1.1417 - val_acc: 0.3604\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0768 - acc: 0.4422 - val_loss: 1.1439 - val_acc: 0.3568\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0721 - acc: 0.4455 - val_loss: 1.1442 - val_acc: 0.3564\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0626 - acc: 0.4518 - val_loss: 1.1454 - val_acc: 0.3569\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0599 - acc: 0.4511 - val_loss: 1.1457 - val_acc: 0.3580\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0593 - acc: 0.4480 - val_loss: 1.1471 - val_acc: 0.3534\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0602 - acc: 0.4453 - val_loss: 1.1488 - val_acc: 0.3549\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0522 - acc: 0.4584 - val_loss: 1.1491 - val_acc: 0.3512\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0511 - acc: 0.4558 - val_loss: 1.1500 - val_acc: 0.3506\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0474 - acc: 0.4627 - val_loss: 1.1505 - val_acc: 0.3484\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0452 - acc: 0.4602 - val_loss: 1.1525 - val_acc: 0.3467\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0433 - acc: 0.4635 - val_loss: 1.1524 - val_acc: 0.3469\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0430 - acc: 0.4590 - val_loss: 1.1521 - val_acc: 0.3506\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0357 - acc: 0.4690 - val_loss: 1.1533 - val_acc: 0.3484\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0328 - acc: 0.4684 - val_loss: 1.1560 - val_acc: 0.3449\n",
      "[1.213729773295348, 1.1448575956620053, 1.12463889784644, 1.1198633909225464, 1.1183164541987698, 1.1180651977211642, 1.1180462570866057, 1.1186964180553967, 1.1194219738651037, 1.1221570897167321, 1.124024776411966, 1.124357266387108, 1.1252066247794543, 1.1273946047478867, 1.1290372733524126, 1.1298336385056498, 1.1309266321015943, 1.1343219247760825, 1.1338403718672916, 1.1343648391458578, 1.1365725081363232, 1.137317098778665, 1.1393927212307173, 1.1391223844455438, 1.1401586935370756, 1.1416607965240686, 1.143934248578646, 1.1442166336225879, 1.1453583256750082, 1.1457354034974725, 1.1470533472965458, 1.1488386405586222, 1.1491488858204773, 1.149994969367981, 1.1504870688882771, 1.152461051291276, 1.1523900798620905, 1.1521173488216765, 1.1532674228787747, 1.1560297600255025]\n",
      "args {'num_dense2': 120}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 4s - loss: 1.2948 - acc: 0.3472 - val_loss: 1.1859 - val_acc: 0.3333\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.2834 - acc: 0.3432 - val_loss: 1.1825 - val_acc: 0.3287\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2504 - acc: 0.3501 - val_loss: 1.1760 - val_acc: 0.3265\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2365 - acc: 0.3568 - val_loss: 1.1731 - val_acc: 0.3210\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2116 - acc: 0.3614 - val_loss: 1.1719 - val_acc: 0.3174\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.1990 - acc: 0.3684 - val_loss: 1.1669 - val_acc: 0.3224\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.1954 - acc: 0.3690 - val_loss: 1.1669 - val_acc: 0.3166\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.1759 - acc: 0.3758 - val_loss: 1.1641 - val_acc: 0.3169\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1620 - acc: 0.3782 - val_loss: 1.1638 - val_acc: 0.3144\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1472 - acc: 0.3878 - val_loss: 1.1633 - val_acc: 0.3093\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1438 - acc: 0.3956 - val_loss: 1.1619 - val_acc: 0.3084\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1379 - acc: 0.3926 - val_loss: 1.1603 - val_acc: 0.3134\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1320 - acc: 0.4052 - val_loss: 1.1599 - val_acc: 0.3093\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1197 - acc: 0.4019 - val_loss: 1.1599 - val_acc: 0.3082\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1144 - acc: 0.4155 - val_loss: 1.1582 - val_acc: 0.3110\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1130 - acc: 0.4122 - val_loss: 1.1588 - val_acc: 0.3106\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1057 - acc: 0.4104 - val_loss: 1.1586 - val_acc: 0.3098\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.0966 - acc: 0.4231 - val_loss: 1.1583 - val_acc: 0.3113\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.0956 - acc: 0.4205 - val_loss: 1.1587 - val_acc: 0.3116\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.0863 - acc: 0.4237 - val_loss: 1.1577 - val_acc: 0.3149\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0829 - acc: 0.4302 - val_loss: 1.1578 - val_acc: 0.3156\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0826 - acc: 0.4282 - val_loss: 1.1573 - val_acc: 0.3137\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.0751 - acc: 0.4347 - val_loss: 1.1562 - val_acc: 0.3162\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0725 - acc: 0.4339 - val_loss: 1.1556 - val_acc: 0.3169\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0746 - acc: 0.4384 - val_loss: 1.1574 - val_acc: 0.3134\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0677 - acc: 0.4341 - val_loss: 1.1554 - val_acc: 0.3168\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0659 - acc: 0.4471 - val_loss: 1.1557 - val_acc: 0.3178\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0542 - acc: 0.4476 - val_loss: 1.1557 - val_acc: 0.3168\n",
      "Epoch 29/40\n",
      " - 5s - loss: 1.0538 - acc: 0.4479 - val_loss: 1.1561 - val_acc: 0.3188\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0482 - acc: 0.4582 - val_loss: 1.1555 - val_acc: 0.3215\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0500 - acc: 0.4529 - val_loss: 1.1563 - val_acc: 0.3215\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0490 - acc: 0.4528 - val_loss: 1.1564 - val_acc: 0.3186\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0448 - acc: 0.4528 - val_loss: 1.1581 - val_acc: 0.3181\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0405 - acc: 0.4613 - val_loss: 1.1568 - val_acc: 0.3210\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0370 - acc: 0.4656 - val_loss: 1.1561 - val_acc: 0.3214\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0377 - acc: 0.4619 - val_loss: 1.1573 - val_acc: 0.3222\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0329 - acc: 0.4557 - val_loss: 1.1585 - val_acc: 0.3251\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0270 - acc: 0.4646 - val_loss: 1.1578 - val_acc: 0.3236\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0306 - acc: 0.4693 - val_loss: 1.1580 - val_acc: 0.3254\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0271 - acc: 0.4698 - val_loss: 1.1596 - val_acc: 0.3236\n",
      "[1.1858922541953563, 1.182498676250676, 1.1759789230388258, 1.1730528936723923, 1.1719360838793929, 1.1669107984132272, 1.1668790705522334, 1.1641229696429718, 1.1637625658544597, 1.1633016722078868, 1.1618992895781182, 1.1603022573429491, 1.1598878169904288, 1.1599074608623494, 1.158179302306526, 1.1588289003606063, 1.1586312127048377, 1.1582848889301518, 1.1586596270672957, 1.15769164308865, 1.157761641679083, 1.1572748799414985, 1.1561523926030712, 1.1555945944721107, 1.1573893731556406, 1.1554274286171395, 1.155715714358504, 1.155682067455323, 1.156089536500562, 1.1554695286607872, 1.1563445274446575, 1.1563748322650587, 1.1580770681599506, 1.1568263119507876, 1.1561467007655213, 1.1573162488131823, 1.1584568277041984, 1.1577909177915278, 1.1580012919792362, 1.15963403567956]\n",
      "args {'num_dense2': 332}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 1.4941 - acc: 0.3985 - val_loss: 1.1678 - val_acc: 0.3581\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3370 - acc: 0.3881 - val_loss: 1.1748 - val_acc: 0.3219\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.2821 - acc: 0.3676 - val_loss: 1.1796 - val_acc: 0.3050\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.2680 - acc: 0.3581 - val_loss: 1.1818 - val_acc: 0.2967\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2471 - acc: 0.3546 - val_loss: 1.1771 - val_acc: 0.2965\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2342 - acc: 0.3662 - val_loss: 1.1739 - val_acc: 0.2955\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2163 - acc: 0.3695 - val_loss: 1.1708 - val_acc: 0.2965\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.2062 - acc: 0.3765 - val_loss: 1.1697 - val_acc: 0.2973\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.1912 - acc: 0.3836 - val_loss: 1.1710 - val_acc: 0.2921\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.1792 - acc: 0.3842 - val_loss: 1.1644 - val_acc: 0.3013\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1610 - acc: 0.3960 - val_loss: 1.1649 - val_acc: 0.3007\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1665 - acc: 0.3932 - val_loss: 1.1630 - val_acc: 0.3067\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1457 - acc: 0.3994 - val_loss: 1.1636 - val_acc: 0.3038\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1446 - acc: 0.4077 - val_loss: 1.1621 - val_acc: 0.3076\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1333 - acc: 0.4066 - val_loss: 1.1596 - val_acc: 0.3099\n",
      "Epoch 16/40\n",
      " - 4s - loss: 1.1290 - acc: 0.4125 - val_loss: 1.1611 - val_acc: 0.3099\n",
      "Epoch 17/40\n",
      " - 5s - loss: 1.1201 - acc: 0.4160 - val_loss: 1.1588 - val_acc: 0.3128\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1187 - acc: 0.4169 - val_loss: 1.1558 - val_acc: 0.3162\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1118 - acc: 0.4283 - val_loss: 1.1608 - val_acc: 0.3127\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1042 - acc: 0.4221 - val_loss: 1.1579 - val_acc: 0.3156\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.0955 - acc: 0.4293 - val_loss: 1.1591 - val_acc: 0.3190\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.0953 - acc: 0.4337 - val_loss: 1.1594 - val_acc: 0.3181\n",
      "Epoch 23/40\n",
      " - 5s - loss: 1.0871 - acc: 0.4323 - val_loss: 1.1587 - val_acc: 0.3183\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0812 - acc: 0.4393 - val_loss: 1.1602 - val_acc: 0.3162\n",
      "Epoch 25/40\n",
      " - 5s - loss: 1.0851 - acc: 0.4350 - val_loss: 1.1591 - val_acc: 0.3188\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0793 - acc: 0.4338 - val_loss: 1.1579 - val_acc: 0.3210\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0745 - acc: 0.4399 - val_loss: 1.1589 - val_acc: 0.3224\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0688 - acc: 0.4468 - val_loss: 1.1594 - val_acc: 0.3203\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0580 - acc: 0.4560 - val_loss: 1.1600 - val_acc: 0.3227\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0628 - acc: 0.4479 - val_loss: 1.1591 - val_acc: 0.3265\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0587 - acc: 0.4512 - val_loss: 1.1590 - val_acc: 0.3260\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0496 - acc: 0.4626 - val_loss: 1.1610 - val_acc: 0.3241\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0500 - acc: 0.4595 - val_loss: 1.1613 - val_acc: 0.3248\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0452 - acc: 0.4615 - val_loss: 1.1610 - val_acc: 0.3237\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0489 - acc: 0.4599 - val_loss: 1.1606 - val_acc: 0.3234\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0355 - acc: 0.4669 - val_loss: 1.1618 - val_acc: 0.3237\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0316 - acc: 0.4657 - val_loss: 1.1618 - val_acc: 0.3251\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0365 - acc: 0.4659 - val_loss: 1.1613 - val_acc: 0.3263\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0241 - acc: 0.4725 - val_loss: 1.1621 - val_acc: 0.3251\n",
      "Epoch 40/40\n",
      " - 5s - loss: 1.0240 - acc: 0.4728 - val_loss: 1.1605 - val_acc: 0.3251\n",
      "[1.1677727348473157, 1.1747964843092562, 1.1796461847237736, 1.1818232088063003, 1.1771153646853705, 1.1738657909128256, 1.1707957024795157, 1.1696800691880063, 1.1709536223060752, 1.1643869301928487, 1.1649335824176466, 1.1630288001951794, 1.1636096638619737, 1.162073917869651, 1.1595717821199172, 1.1610701629836162, 1.1588140680614545, 1.1557838965501708, 1.1608389765430212, 1.157880775285352, 1.1591304089133032, 1.159432428734179, 1.158722914856851, 1.1601647596593123, 1.15912926879176, 1.1579249259236724, 1.158883406940533, 1.1594049553780206, 1.1599803568556784, 1.1590612967592493, 1.1590169112753803, 1.161013481077771, 1.1613167400905806, 1.1609662306731015, 1.1605670676244377, 1.1617600222699325, 1.1618321269994212, 1.161307645103912, 1.1621387842890352, 1.1605236955819402]\n",
      "args {'num_dense2': 237}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/40\n",
      " - 5s - loss: 1.6065 - acc: 0.2109 - val_loss: 1.3075 - val_acc: 0.2778\n",
      "Epoch 2/40\n",
      " - 4s - loss: 1.3959 - acc: 0.2573 - val_loss: 1.1884 - val_acc: 0.3425\n",
      "Epoch 3/40\n",
      " - 4s - loss: 1.3292 - acc: 0.3063 - val_loss: 1.1493 - val_acc: 0.3917\n",
      "Epoch 4/40\n",
      " - 4s - loss: 1.3082 - acc: 0.3363 - val_loss: 1.1385 - val_acc: 0.4004\n",
      "Epoch 5/40\n",
      " - 4s - loss: 1.2872 - acc: 0.3424 - val_loss: 1.1346 - val_acc: 0.4024\n",
      "Epoch 6/40\n",
      " - 4s - loss: 1.2734 - acc: 0.3518 - val_loss: 1.1310 - val_acc: 0.4011\n",
      "Epoch 7/40\n",
      " - 4s - loss: 1.2531 - acc: 0.3556 - val_loss: 1.1278 - val_acc: 0.3980\n",
      "Epoch 8/40\n",
      " - 4s - loss: 1.2352 - acc: 0.3626 - val_loss: 1.1282 - val_acc: 0.3941\n",
      "Epoch 9/40\n",
      " - 4s - loss: 1.2187 - acc: 0.3679 - val_loss: 1.1260 - val_acc: 0.3931\n",
      "Epoch 10/40\n",
      " - 4s - loss: 1.2144 - acc: 0.3695 - val_loss: 1.1275 - val_acc: 0.3895\n",
      "Epoch 11/40\n",
      " - 4s - loss: 1.1913 - acc: 0.3769 - val_loss: 1.1278 - val_acc: 0.3886\n",
      "Epoch 12/40\n",
      " - 4s - loss: 1.1845 - acc: 0.3822 - val_loss: 1.1283 - val_acc: 0.3861\n",
      "Epoch 13/40\n",
      " - 4s - loss: 1.1772 - acc: 0.3834 - val_loss: 1.1299 - val_acc: 0.3811\n",
      "Epoch 14/40\n",
      " - 4s - loss: 1.1633 - acc: 0.3879 - val_loss: 1.1309 - val_acc: 0.3793\n",
      "Epoch 15/40\n",
      " - 4s - loss: 1.1609 - acc: 0.3891 - val_loss: 1.1321 - val_acc: 0.3731\n",
      "Epoch 16/40\n",
      " - 5s - loss: 1.1516 - acc: 0.3925 - val_loss: 1.1328 - val_acc: 0.3697\n",
      "Epoch 17/40\n",
      " - 4s - loss: 1.1442 - acc: 0.3976 - val_loss: 1.1337 - val_acc: 0.3667\n",
      "Epoch 18/40\n",
      " - 4s - loss: 1.1314 - acc: 0.3967 - val_loss: 1.1338 - val_acc: 0.3660\n",
      "Epoch 19/40\n",
      " - 4s - loss: 1.1308 - acc: 0.4058 - val_loss: 1.1344 - val_acc: 0.3632\n",
      "Epoch 20/40\n",
      " - 4s - loss: 1.1231 - acc: 0.4068 - val_loss: 1.1361 - val_acc: 0.3610\n",
      "Epoch 21/40\n",
      " - 4s - loss: 1.1159 - acc: 0.4077 - val_loss: 1.1376 - val_acc: 0.3595\n",
      "Epoch 22/40\n",
      " - 4s - loss: 1.1110 - acc: 0.4167 - val_loss: 1.1396 - val_acc: 0.3541\n",
      "Epoch 23/40\n",
      " - 4s - loss: 1.1044 - acc: 0.4147 - val_loss: 1.1389 - val_acc: 0.3537\n",
      "Epoch 24/40\n",
      " - 4s - loss: 1.0983 - acc: 0.4221 - val_loss: 1.1415 - val_acc: 0.3498\n",
      "Epoch 25/40\n",
      " - 4s - loss: 1.0986 - acc: 0.4188 - val_loss: 1.1416 - val_acc: 0.3498\n",
      "Epoch 26/40\n",
      " - 4s - loss: 1.0910 - acc: 0.4271 - val_loss: 1.1429 - val_acc: 0.3471\n",
      "Epoch 27/40\n",
      " - 4s - loss: 1.0848 - acc: 0.4273 - val_loss: 1.1434 - val_acc: 0.3466\n",
      "Epoch 28/40\n",
      " - 4s - loss: 1.0809 - acc: 0.4282 - val_loss: 1.1432 - val_acc: 0.3469\n",
      "Epoch 29/40\n",
      " - 4s - loss: 1.0724 - acc: 0.4371 - val_loss: 1.1435 - val_acc: 0.3452\n",
      "Epoch 30/40\n",
      " - 4s - loss: 1.0699 - acc: 0.4351 - val_loss: 1.1446 - val_acc: 0.3438\n",
      "Epoch 31/40\n",
      " - 4s - loss: 1.0691 - acc: 0.4409 - val_loss: 1.1446 - val_acc: 0.3438\n",
      "Epoch 32/40\n",
      " - 4s - loss: 1.0666 - acc: 0.4392 - val_loss: 1.1465 - val_acc: 0.3425\n",
      "Epoch 33/40\n",
      " - 4s - loss: 1.0653 - acc: 0.4377 - val_loss: 1.1485 - val_acc: 0.3408\n",
      "Epoch 34/40\n",
      " - 4s - loss: 1.0554 - acc: 0.4468 - val_loss: 1.1475 - val_acc: 0.3391\n",
      "Epoch 35/40\n",
      " - 4s - loss: 1.0551 - acc: 0.4468 - val_loss: 1.1472 - val_acc: 0.3411\n",
      "Epoch 36/40\n",
      " - 4s - loss: 1.0548 - acc: 0.4509 - val_loss: 1.1495 - val_acc: 0.3353\n",
      "Epoch 37/40\n",
      " - 4s - loss: 1.0532 - acc: 0.4484 - val_loss: 1.1526 - val_acc: 0.3328\n",
      "Epoch 38/40\n",
      " - 4s - loss: 1.0452 - acc: 0.4481 - val_loss: 1.1514 - val_acc: 0.3340\n",
      "Epoch 39/40\n",
      " - 4s - loss: 1.0407 - acc: 0.4494 - val_loss: 1.1511 - val_acc: 0.3348\n",
      "Epoch 40/40\n",
      " - 4s - loss: 1.0358 - acc: 0.4626 - val_loss: 1.1531 - val_acc: 0.3312\n",
      "[1.3074930623701548, 1.1883898827295538, 1.1493378591797332, 1.138489117739311, 1.1346075749202384, 1.1310053180284005, 1.1278321275269303, 1.1282387747751594, 1.1260415097998013, 1.1275284667106025, 1.127755381430852, 1.1282637781927956, 1.129946567057264, 1.130898083263262, 1.1321176683545437, 1.1327617350326247, 1.1337440871412812, 1.1337816270235774, 1.1344258684553308, 1.136075441778843, 1.1375655751137383, 1.1396173086088426, 1.1388741682920533, 1.141451085620745, 1.1415956205503168, 1.1428925766931892, 1.1434494815665306, 1.143211405023892, 1.1434742147331343, 1.1445528989916602, 1.1446102022799873, 1.1464512910115296, 1.14852166078396, 1.147489131633852, 1.1472105083413604, 1.149474851117147, 1.1526400747351166, 1.1513778822298595, 1.1510961107726967, 1.1530857141401203]\n",
      "best: {'num_dense2': 23}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            trials=trials,\n",
    "            max_evals=20)\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=0\n",
    "loss = np.zeros(len(trials))\n",
    "params = np.zeros((len(trials),3))\n",
    "for objects in trials.trials:\n",
    "                  loss[it] = objects['result']['loss'] \n",
    "#                   params[it,0] = 10 ** objects['misc']['vals']['lr'][0]\n",
    "#                   params[it,1] = objects['misc']['vals']['num_dense1'][0]\n",
    "                  params[it,2] = objects['misc']['vals']['num_dense2'][0]\n",
    "                  it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAl0AAAJVCAYAAADk0UBGAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n4wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6dc77b1a10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.stem(params[:,2],loss[:])\n",
    "# plt.scatter(params[:,0][mask]+200,params[:,2][mask]+20,c=loss[:][mask],s=loss[:][mask]*200)\n",
    "plt.yscale('log')\n",
    "# plt.ylim([1,2])\n",
    "plt.xscale('log',nonposy='clip')\n",
    "# plt.xlim([10**-8,10**-3])\n",
    "# plt.colorbar()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = loss>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
