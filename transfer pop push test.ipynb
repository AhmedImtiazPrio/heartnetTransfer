{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17061, 2500, 1)\n",
      "(17061, 1)\n",
      "(5872, 2500, 1)\n",
      "(5872, 1)\n",
      "0.280824829932\n",
      "[[25  7  0]\n",
      " [90  6  2]\n",
      " [46  4  0]]\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from heartnet_v1 import heartnet, reshape_folds\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "set_session(tf.Session(config=config))\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, TensorBoard, Callback\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dense, Dropout\n",
    "from keras.models import Model\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "import tables\n",
    "from datetime import datetime\n",
    "import argparse\n",
    "\n",
    "def heartnet_transfer(load_path='/media/taufiq/Data/heart_sound/interspeech_compare/weights.0148-0.8902.hdf5',lr=0.0012843784,lr_decay=0.0001132885,num_dense=20,trainable=False,dropout_rate=0.):\n",
    "    model = heartnet(load_path=load_path,FIR_train=False,trainable=trainable)\n",
    "    x = model.layers[-4].output\n",
    "    x = Dense(num_dense,activation='relu') (x)\n",
    "    x = Dropout(rate=dropout_rate,seed=1) (x)\n",
    "    output = Dense(3,activation='softmax')(x)\n",
    "    model = Model(inputs=model.input,outputs=output)\n",
    "    sgd = SGD(lr=lr)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "class log_UAR(Callback):\n",
    "\n",
    "    def __init__(self, x_val, y_val, val_parts, res_thresh):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.val_parts = val_parts\n",
    "        self.res_thresh = res_thresh\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if logs is not None:\n",
    "            y_pred = self.model.predict(self.x_val, verbose=0)\n",
    "            y_pred = np.argmax(y_pred, axis=-1)\n",
    "            self.y_val_ = np.transpose(np.argmax(self.y_val, axis=-1))\n",
    "            true = []\n",
    "            pred = []\n",
    "            start_idx = 0\n",
    "            for s in self.val_parts:\n",
    "\n",
    "                if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "                    continue\n",
    "                # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "                temp_ = self.y_val_[start_idx:start_idx + int(s) - 1]\n",
    "                temp = y_pred[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "                if (sum(temp == 0) > sum(temp == 1)) and (sum(temp == 0) > sum(temp == 2)):\n",
    "                    pred.append(0)\n",
    "                elif (sum(temp == 2) > sum(temp == 1)) and (sum(temp == 2) > sum(temp == 0)):\n",
    "                    pred.append(2)\n",
    "                else:\n",
    "                    pred.append(1)\n",
    "\n",
    "                if (sum(temp_ == 0) > sum(temp_ == 1)) and (sum(temp_ == 0) > sum(temp_ == 2)):\n",
    "                    true.append(0)\n",
    "                elif (sum(temp_ == 2) > sum(temp_ == 1)) and (sum(temp_ == 2) > sum(temp_ == 0)):\n",
    "                    true.append(2)\n",
    "                else:\n",
    "                    true.append(1)\n",
    "\n",
    "                start_idx = start_idx + int(s)\n",
    "\n",
    "            score = recall_score(y_pred=pred, y_true=true, average='macro')\n",
    "            logs['UAR'] = np.array(score)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "\n",
    "    fold_dir = '/media/taufiq/Data/heart_sound/interspeech_compare/feature/segmented_noFIR/'\n",
    "    foldname = 'comParE'\n",
    "    model_dir = '/media/taufiq/Data/heart_sound/models/'\n",
    "    log_name = foldname + ' ' + str(datetime.now())\n",
    "    checkpoint_name = model_dir + log_name + \"/\" + 'weights.{epoch:04d}-{val_acc:.4f}.hdf5'\n",
    "    if not os.path.exists(model_dir + log_name):\n",
    "        os.makedirs(model_dir + log_name)\n",
    "    log_dir = '/media/taufiq/Data/heart_sound/interspeech_compare/logs/'\n",
    "\n",
    "    ##### Load Model ######\n",
    "\n",
    "    load_path='/media/taufiq/Data/heart_sound/interspeech_compare/weights.0148-0.8902.hdf5'\n",
    "    lr = 0.00005\n",
    "    num_dense = 34\n",
    "    epochs = 1000\n",
    "    batch_size = 128\n",
    "    dropout_rate = 0.\n",
    "    trainable = False\n",
    "    res_thresh = .5\n",
    "    model = heartnet_transfer(load_path=load_path,lr=lr,num_dense=num_dense,trainable=trainable,dropout_rate=dropout_rate)\n",
    "    plot_model(model,\"model.png\",show_layer_names=True,show_shapes=True)\n",
    "\n",
    "    ###### Load Data ######\n",
    "\n",
    "    feat = tables.open_file(fold_dir + foldname + '.mat')\n",
    "    x_train = feat.root.trainX[:]\n",
    "    y_train = feat.root.trainY[0, :]\n",
    "    x_val = feat.root.valX[:]\n",
    "    y_val = feat.root.valY[0, :]\n",
    "    train_parts = feat.root.train_parts[:]\n",
    "    val_parts = feat.root.val_parts[0, :]\n",
    "\n",
    "    ############### Reshaping ############\n",
    "\n",
    "    x_train, y_train, x_val, y_val = reshape_folds(x_train, x_val, y_train, y_val)\n",
    "    y_train = to_categorical(y_train,num_classes=3)\n",
    "    y_val = to_categorical(y_val,num_classes=3)\n",
    "\n",
    "    ### Callbacks ###\n",
    "    csv_logger = CSVLogger(log_dir + log_name + '/training.csv')\n",
    "    modelcheckpnt = ModelCheckpoint(filepath=checkpoint_name,\n",
    "                                    monitor='val_acc', save_best_only=True, mode='max')\n",
    "    tensbd = TensorBoard(log_dir=log_dir + log_name,\n",
    "                         batch_size=batch_size,\n",
    "                         histogram_freq=100,\n",
    "                         # embeddings_freq=99,\n",
    "                         # embeddings_layer_names=embedding_layer_names,\n",
    "                         # embeddings_data=x_val,\n",
    "                         # embeddings_metadata=metadata_file,\n",
    "                         write_images=False)\n",
    "\n",
    "    ### Train ###\n",
    "#     model.fit(x_train,y_train,\n",
    "#               batch_size=batch_size,\n",
    "#               epochs=epochs,\n",
    "#               verbose=2,\n",
    "#               shuffle=True,\n",
    "#               callbacks=[modelcheckpnt,\n",
    "#                          log_UAR(x_val, y_val, val_parts, res_thresh),\n",
    "#                          tensbd, csv_logger],\n",
    "#               validation_data=(x_val,y_val))\n",
    "\n",
    "    ###### Results #####\n",
    "\n",
    "    y_pred = model.predict(x_val, verbose=0)\n",
    "    y_pred = np.argmax(y_pred,axis=-1)\n",
    "    y_val = np.transpose(np.argmax(y_val,axis=-1))\n",
    "    true = []\n",
    "    pred = []\n",
    "    start_idx = 0\n",
    "    for s in val_parts:\n",
    "\n",
    "        if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "            continue\n",
    "        # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "        temp_ = y_val[start_idx:start_idx + int(s) - 1]\n",
    "        temp = y_pred[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "        if (sum(temp==0) > sum(temp==1)) and  (sum(temp==0) > sum(temp==2)):\n",
    "            pred.append(0)\n",
    "        elif (sum(temp==2) > sum(temp==1)) and  (sum(temp==2) > sum(temp==0)):\n",
    "            pred.append(2)\n",
    "        else:\n",
    "            pred.append(1)\n",
    "\n",
    "        if (sum(temp_ == 0) > sum(temp_ == 1)) and (sum(temp_ == 0) > sum(temp_ == 2)):\n",
    "            true.append(0)\n",
    "        elif (sum(temp_ == 2) > sum(temp_ == 1)) and (sum(temp_ == 2) > sum(temp_ == 0)):\n",
    "            true.append(2)\n",
    "        else:\n",
    "            true.append(1)\n",
    "\n",
    "        start_idx = start_idx + int(s)\n",
    "    score = recall_score(y_pred=pred, y_true=true, average='macro')\n",
    "    print(score)\n",
    "    print(confusion_matrix(y_true=true,y_pred=pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = model.layers[-4].output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_ = Model(inputs=model.input,outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_model(model_,'model_.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_feat=np.zeros((x_val.shape[0],9952))\n",
    "val_label= np.zeros(y_val.shape)\n",
    "val_feat.shape\n",
    "for i in range(x_val.shape[0]):\n",
    "    val_feat[i] = model_.predict(x_val[i:i+1,:,:])\n",
    "    val_label[i] = y_val[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import savemat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5872, 9952)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_feat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5872, 2500, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5872,)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_label.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_feat=np.zeros((x_train.shape[0],9952))\n",
    "train_label= np.zeros(y_train.shape)\n",
    "for i in range(x_train.shape[0]):\n",
    "    train_feat[i] = model_.predict(x_train[i:i+1,:,:])\n",
    "    train_label[i] = y_train[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=np.argmax(y_train,axis=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2886"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(train_label==0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "matfile={\"train_X\":train_feat,\"train_Y\":train_label,\"val_X\":val_feat,\"val_Y\":val_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "savemat('features.mat',matfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
