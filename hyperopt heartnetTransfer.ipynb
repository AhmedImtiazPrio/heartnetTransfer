{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function, division\n",
    "from keras.constraints import max_norm\n",
    "from keras.regularizers import l2\n",
    "from custom_layers import Conv1D_linearphase\n",
    "from heartnet_v1 import heartnet, reshape_folds, branch\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.4\n",
    "set_session(tf.Session(config=config))\n",
    "import numpy as np\n",
    "np.random.seed(1)\n",
    "from tensorflow import set_random_seed\n",
    "set_random_seed(1)\n",
    "from keras.utils import to_categorical\n",
    "from keras.optimizers import Adam, SGD\n",
    "from keras.callbacks import CSVLogger, ModelCheckpoint, TensorBoard, Callback\n",
    "from keras.utils import plot_model\n",
    "from keras.layers import Dense, Dropout, Concatenate, initializers, Input\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "from sklearn.metrics import recall_score, confusion_matrix\n",
    "import pandas as pd\n",
    "import os\n",
    "import tables\n",
    "from datetime import datetime\n",
    "from hyperopt import hp, fmin, Trials, tpe, STATUS_OK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_weight(Y, classes):\n",
    "    num_samples = (len(Y))\n",
    "    n_classes = (len(classes))\n",
    "    num_bin = np.sum(Y,axis=-2)\n",
    "    class_weights = {i: (num_samples / (n_classes * num_bin[i])) for i in range(n_classes)}\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heartnet_transfer(load_path='/media/taufiq/Data1/heart_sound/weights.0148-0.8902.hdf5',\n",
    "                      lr=0.0012843784,lr_decay=0.0001132885,\n",
    "                      num_dense1=20,num_dense2=20,trainable=False,dropout_rate=0.):\n",
    "    model = heartnet(load_path=load_path,FIR_train=False,trainable=trainable)\n",
    "    plot_model(model,'before.png',show_shapes=True,show_layer_names=True)\n",
    "    x = model.layers[-4].output\n",
    "    x = Dense(num_dense1,activation='relu',kernel_initializer=initializers.he_uniform(seed=1)) (x)\n",
    "    x = Dropout(rate=dropout_rate,seed=1) (x)\n",
    "    x = Dense(num_dense2, activation='relu',kernel_initializer=initializers.he_normal(seed=1))(x)\n",
    "    x = Dropout(rate=dropout_rate, seed=1)(x)\n",
    "    output = Dense(3,activation='softmax')(x)\n",
    "    model = Model(inputs=model.input,outputs=output)\n",
    "    plot_model(model, 'after.png',show_shapes=True,show_layer_names=True)\n",
    "    if load_path:\n",
    "        model.load_weights(load_path,by_name=True)\n",
    "    sgd = Adam(lr=lr)\n",
    "    model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class log_recall(Callback):\n",
    "\n",
    "    def __init__(self, x_val, y_val, val_parts):\n",
    "        self.x_val = x_val\n",
    "        self.y_val = y_val\n",
    "        self.val_parts = val_parts\n",
    "\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs):\n",
    "        if logs is not None:\n",
    "            y_pred = self.model.predict(self.x_val, verbose=0)\n",
    "            y_pred = np.argmax(y_pred, axis=-1)\n",
    "            self.y_val_ = np.transpose(np.argmax(self.y_val, axis=-1))\n",
    "            true = []\n",
    "            pred = []\n",
    "            start_idx = 0\n",
    "            for s in self.val_parts:\n",
    "\n",
    "                if not s:  ## for e00032 in validation0 there was no cardiac cycle\n",
    "                    continue\n",
    "                # ~ print \"part {} start {} stop {}\".format(s,start_idx,start_idx+int(s)-1)\n",
    "\n",
    "                temp_ = self.y_val_[start_idx:start_idx + int(s) - 1]\n",
    "                temp = y_pred[start_idx:start_idx + int(s) - 1]\n",
    "\n",
    "                if (sum(temp == 0) > sum(temp == 1)) and (sum(temp == 0) > sum(temp == 2)):\n",
    "                    pred.append(0)\n",
    "                elif (sum(temp == 2) > sum(temp == 1)) and (sum(temp == 2) > sum(temp == 0)):\n",
    "                    pred.append(2)\n",
    "                else:\n",
    "                    pred.append(1)\n",
    "\n",
    "                if (sum(temp_ == 0) > sum(temp_ == 1)) and (sum(temp_ == 0) > sum(temp_ == 2)):\n",
    "                    true.append(0)\n",
    "                elif (sum(temp_ == 2) > sum(temp_ == 1)) and (sum(temp_ == 2) > sum(temp_ == 0)):\n",
    "                    true.append(2)\n",
    "                else:\n",
    "                    true.append(1)\n",
    "\n",
    "                start_idx = start_idx + int(s)\n",
    "\n",
    "            confmat = confusion_matrix(y_pred=pred, y_true=true)\n",
    "            \n",
    "            logs['recall0'] = confmat[0,0]/np.sum(confmat[0,:])\n",
    "            logs['recall1'] = confmat[1,1]/np.sum(confmat[1,:])\n",
    "            logs['recall2'] = confmat[2,2]/np.sum(confmat[2,:])\n",
    "            logs['UAR'] = np.mean([logs['recall0'],logs['recall1'],logs['recall2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_dir = '/media/taufiq/Data1/heart_sound/feature/segmented_noFIR/'\n",
    "foldname = 'comParE'\n",
    "model_dir = '/media/taufiq/Data1/heart_sound/models/'\n",
    "log_dir = '/media/taufiq/Data1/heart_sound/logs/'\n",
    "\n",
    "##### Load Model ######\n",
    "load_path='/media/taufiq/Data1/heart_sound/weights.0148-0.8902.hdf5'\n",
    "# lr = 0.00001\n",
    "# lr = 0.1\n",
    "num_dense1 = 792 #34,120,167,239,1239,650,788,422,598\n",
    "num_dense2 = 137 #121,\n",
    "epochs = 20\n",
    "batch_size = 256\n",
    "dropout_rate = 0.\n",
    "trainable = False\n",
    "addweights = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17061, 2500, 1)\n",
      "(17061, 1)\n",
      "(5872, 2500, 1)\n",
      "(5872, 1)\n"
     ]
    }
   ],
   "source": [
    "feat = tables.open_file(fold_dir + foldname + '.mat')\n",
    "x_train = feat.root.trainX[:]\n",
    "y_train = feat.root.trainY[0, :]\n",
    "x_val = feat.root.valX[:]\n",
    "y_val = feat.root.valY[0, :]\n",
    "train_parts = feat.root.train_parts[:]\n",
    "val_parts = feat.root.val_parts[0, :]\n",
    "############### Reshaping ############\n",
    "x_train, y_train, x_val, y_val = reshape_folds(x_train, x_val, y_train, y_val)\n",
    "y_train = to_categorical(y_train,num_classes=3)\n",
    "y_val = to_categorical(y_val,num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(args):\n",
    "    #### Parse arguments and print #####\n",
    "    \n",
    "    print(\"args %s\" % args)\n",
    "    \n",
    "    lr = args['lr']\n",
    "#     lr = 0.01\n",
    "#     num_dense1 = args['num_dense1']\n",
    "#     num_dense2 = args['num_dense2']\n",
    "    \n",
    "    ##### Load model ######\n",
    "    model = heartnet_transfer(load_path=load_path,lr=lr,num_dense1=num_dense1,\n",
    "                              num_dense2=num_dense2,trainable=trainable,\n",
    "                              dropout_rate=dropout_rate)\n",
    "    \n",
    "    #### Log params #####\n",
    "    log_name = foldname + ' ' + str(datetime.now()) + str(args.values())\n",
    "    checkpoint_name = model_dir + log_name + \"/\" + 'weights.{epoch:04d}-{val_acc:.4f}.hdf5'\n",
    "    if not os.path.exists(model_dir + log_name):\n",
    "        os.makedirs(model_dir + log_name)\n",
    "    plot_model(model,\"model.png\",show_layer_names=True,show_shapes=True)\n",
    "    \n",
    "    ### Callbacks ###\n",
    "    \n",
    "    csv_logger = CSVLogger(log_dir + log_name + '/training.csv')\n",
    "    modelcheckpnt = ModelCheckpoint(filepath=checkpoint_name,\n",
    "                                    monitor='val_acc', save_best_only=False, mode='max')\n",
    "    tensbd = TensorBoard(log_dir=log_dir + log_name,\n",
    "                         batch_size=batch_size,\n",
    "                         # histogram_freq=100,\n",
    "                         # embeddings_freq=99,\n",
    "                         # embeddings_layer_names=embedding_layer_names,\n",
    "                         # embeddings_data=x_val,\n",
    "                         # embeddings_metadata=metadata_file,\n",
    "                         write_images=False)\n",
    "    class_weights=compute_weight(y_train,range(3))\n",
    "    print(\"Class weights %s\" % class_weights)\n",
    "\n",
    "    #### Train ####\n",
    "    \n",
    "    history = model.fit(x_train,y_train,\n",
    "                        batch_size=batch_size,\n",
    "                        epochs=epochs,\n",
    "                        verbose=2,\n",
    "                        shuffle=True,\n",
    "                        class_weight=class_weights,\n",
    "                        callbacks=[modelcheckpnt,\n",
    "                        log_recall(x_val, y_val, val_parts),\n",
    "                        tensbd, csv_logger],\n",
    "                        validation_data=(x_val,y_val))\n",
    "#     print(\"History : %s\" % history.history)\n",
    "    loss = history.history['val_loss']\n",
    "    print(loss)\n",
    "    K.clear_session()\n",
    "#     return (1.- np.float32(np.max(loss)))\n",
    "    return {'loss': loss[-1], 'status': STATUS_OK}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "space = {\n",
    "    'lr' : 10 ** hp.uniform('lr',-8,-3),\n",
    "#     'num_dense1' : 200 + hp.randint('num_dense1',1800),\n",
    "#     'num_dense2' : 20 + hp.randint('num_dense2',480)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args {'lr': 4.836166490062578e-06}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.2954 - acc: 0.3410 - val_loss: 1.1756 - val_acc: 0.3057\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.1530 - acc: 0.4014 - val_loss: 1.1745 - val_acc: 0.3202\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.1081 - acc: 0.4259 - val_loss: 1.1669 - val_acc: 0.3350\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.0716 - acc: 0.4496 - val_loss: 1.1694 - val_acc: 0.3333\n",
      "Epoch 5/20\n",
      " - 4s - loss: 1.0457 - acc: 0.4591 - val_loss: 1.1725 - val_acc: 0.3288\n",
      "Epoch 6/20\n",
      " - 4s - loss: 1.0221 - acc: 0.4697 - val_loss: 1.1773 - val_acc: 0.3287\n",
      "Epoch 7/20\n",
      " - 4s - loss: 1.0014 - acc: 0.4970 - val_loss: 1.1962 - val_acc: 0.3086\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.9836 - acc: 0.4950 - val_loss: 1.1872 - val_acc: 0.3193\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.9717 - acc: 0.5069 - val_loss: 1.1928 - val_acc: 0.3241\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.9533 - acc: 0.5180 - val_loss: 1.1921 - val_acc: 0.3239\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.9404 - acc: 0.5304 - val_loss: 1.2033 - val_acc: 0.3190\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.9285 - acc: 0.5347 - val_loss: 1.1976 - val_acc: 0.3283\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.9159 - acc: 0.5485 - val_loss: 1.2043 - val_acc: 0.3193\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.9090 - acc: 0.5462 - val_loss: 1.2091 - val_acc: 0.3225\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.8962 - acc: 0.5566 - val_loss: 1.2040 - val_acc: 0.3324\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.8905 - acc: 0.5637 - val_loss: 1.2281 - val_acc: 0.3186\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.8742 - acc: 0.5734 - val_loss: 1.2233 - val_acc: 0.3300\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.8702 - acc: 0.5709 - val_loss: 1.2173 - val_acc: 0.3387\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.8544 - acc: 0.5916 - val_loss: 1.2290 - val_acc: 0.3292\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.8489 - acc: 0.5897 - val_loss: 1.2253 - val_acc: 0.3369\n",
      "[1.1756109431264186, 1.174494203494745, 1.16690368191098, 1.1693814353007386, 1.1725034223265478, 1.17729444919555, 1.1962193864567727, 1.187227255317106, 1.1927681722822892, 1.192122240482299, 1.2033238384964031, 1.1976486028702447, 1.2042516395246625, 1.2090848820735713, 1.2039820930288663, 1.2280915686480032, 1.2232519657800243, 1.2172761057638017, 1.22898686809176, 1.225321035619003]\n",
      "args {'lr': 1.0217076114053917e-06}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.5376 - acc: 0.2509 - val_loss: 1.1766 - val_acc: 0.3314\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.3750 - acc: 0.3394 - val_loss: 1.1382 - val_acc: 0.3804\n",
      "Epoch 3/20\n",
      " - 5s - loss: 1.3236 - acc: 0.3538 - val_loss: 1.1264 - val_acc: 0.3881\n",
      "Epoch 4/20\n",
      " - 5s - loss: 1.2798 - acc: 0.3720 - val_loss: 1.1206 - val_acc: 0.3939\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.2629 - acc: 0.3775 - val_loss: 1.1172 - val_acc: 0.3987\n",
      "Epoch 6/20\n",
      " - 5s - loss: 1.2288 - acc: 0.3939 - val_loss: 1.1201 - val_acc: 0.3898\n",
      "Epoch 7/20\n",
      " - 5s - loss: 1.2100 - acc: 0.3927 - val_loss: 1.1176 - val_acc: 0.3927\n",
      "Epoch 8/20\n",
      " - 5s - loss: 1.1920 - acc: 0.4031 - val_loss: 1.1190 - val_acc: 0.3888\n",
      "Epoch 9/20\n",
      " - 4s - loss: 1.1744 - acc: 0.3997 - val_loss: 1.1212 - val_acc: 0.3876\n",
      "Epoch 10/20\n",
      " - 5s - loss: 1.1584 - acc: 0.4132 - val_loss: 1.1221 - val_acc: 0.3840\n",
      "Epoch 11/20\n",
      " - 5s - loss: 1.1454 - acc: 0.4181 - val_loss: 1.1259 - val_acc: 0.3804\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.1355 - acc: 0.4195 - val_loss: 1.1275 - val_acc: 0.3789\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.1203 - acc: 0.4263 - val_loss: 1.1287 - val_acc: 0.3818\n",
      "Epoch 14/20\n",
      " - 4s - loss: 1.1150 - acc: 0.4300 - val_loss: 1.1313 - val_acc: 0.3774\n",
      "Epoch 15/20\n",
      " - 4s - loss: 1.1041 - acc: 0.4352 - val_loss: 1.1365 - val_acc: 0.3696\n",
      "Epoch 16/20\n",
      " - 5s - loss: 1.0944 - acc: 0.4371 - val_loss: 1.1355 - val_acc: 0.3721\n",
      "Epoch 17/20\n",
      " - 4s - loss: 1.0834 - acc: 0.4439 - val_loss: 1.1350 - val_acc: 0.3733\n",
      "Epoch 18/20\n",
      " - 5s - loss: 1.0772 - acc: 0.4454 - val_loss: 1.1374 - val_acc: 0.3718\n",
      "Epoch 19/20\n",
      " - 4s - loss: 1.0742 - acc: 0.4521 - val_loss: 1.1403 - val_acc: 0.3692\n",
      "Epoch 20/20\n",
      " - 5s - loss: 1.0685 - acc: 0.4529 - val_loss: 1.1426 - val_acc: 0.3685\n",
      "[1.17660883109641, 1.1382357483014098, 1.1264312254310629, 1.1205519717135937, 1.1172115588383065, 1.1201179979282763, 1.1176113621090673, 1.1190316982425201, 1.1211945026382113, 1.1220835034788792, 1.1259134666796276, 1.1275426370246533, 1.1287068021394902, 1.131335939308603, 1.1365417352489295, 1.1354658454250575, 1.135025580507533, 1.1374384616311304, 1.1403203816115044, 1.1426092698073842]\n",
      "args {'lr': 1.4577805402328605e-08}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 3.2562 - acc: 0.2813 - val_loss: 1.8013 - val_acc: 0.2926\n",
      "Epoch 2/20\n",
      " - 5s - loss: 3.2425 - acc: 0.2817 - val_loss: 1.7886 - val_acc: 0.2927\n",
      "Epoch 3/20\n",
      " - 5s - loss: 3.2195 - acc: 0.2813 - val_loss: 1.7782 - val_acc: 0.2931\n",
      "Epoch 4/20\n",
      " - 5s - loss: 3.1920 - acc: 0.2819 - val_loss: 1.7662 - val_acc: 0.2931\n",
      "Epoch 5/20\n",
      " - 4s - loss: 3.1562 - acc: 0.2817 - val_loss: 1.7552 - val_acc: 0.2933\n",
      "Epoch 6/20\n",
      " - 5s - loss: 3.1389 - acc: 0.2814 - val_loss: 1.7437 - val_acc: 0.2934\n",
      "Epoch 7/20\n",
      " - 5s - loss: 3.1109 - acc: 0.2819 - val_loss: 1.7313 - val_acc: 0.2934\n",
      "Epoch 8/20\n",
      " - 5s - loss: 3.0868 - acc: 0.2820 - val_loss: 1.7202 - val_acc: 0.2938\n",
      "Epoch 9/20\n",
      " - 5s - loss: 3.0790 - acc: 0.2820 - val_loss: 1.7074 - val_acc: 0.2939\n",
      "Epoch 10/20\n",
      " - 5s - loss: 3.0408 - acc: 0.2820 - val_loss: 1.6973 - val_acc: 0.2939\n",
      "Epoch 11/20\n",
      " - 5s - loss: 3.0161 - acc: 0.2820 - val_loss: 1.6865 - val_acc: 0.2941\n",
      "Epoch 12/20\n",
      " - 5s - loss: 3.0112 - acc: 0.2817 - val_loss: 1.6742 - val_acc: 0.2938\n",
      "Epoch 13/20\n",
      " - 5s - loss: 2.9887 - acc: 0.2826 - val_loss: 1.6630 - val_acc: 0.2938\n",
      "Epoch 14/20\n",
      " - 5s - loss: 2.9659 - acc: 0.2829 - val_loss: 1.6517 - val_acc: 0.2939\n",
      "Epoch 15/20\n",
      " - 5s - loss: 2.9335 - acc: 0.2840 - val_loss: 1.6425 - val_acc: 0.2938\n",
      "Epoch 16/20\n",
      " - 5s - loss: 2.9207 - acc: 0.2834 - val_loss: 1.6319 - val_acc: 0.2939\n",
      "Epoch 17/20\n",
      " - 5s - loss: 2.8994 - acc: 0.2836 - val_loss: 1.6204 - val_acc: 0.2934\n",
      "Epoch 18/20\n",
      " - 5s - loss: 2.8799 - acc: 0.2846 - val_loss: 1.6096 - val_acc: 0.2936\n",
      "Epoch 19/20\n",
      " - 5s - loss: 2.8727 - acc: 0.2837 - val_loss: 1.6005 - val_acc: 0.2938\n",
      "Epoch 20/20\n",
      " - 5s - loss: 2.8243 - acc: 0.2844 - val_loss: 1.5904 - val_acc: 0.2934\n",
      "[1.8013314151633988, 1.7886089333396518, 1.778217965640554, 1.766245360595329, 1.7551940500898646, 1.743654440469248, 1.7312749546295292, 1.720176926750578, 1.7074477065161724, 1.6972600601674426, 1.686548461706177, 1.6742073151331183, 1.6629846128520913, 1.6516747013424657, 1.6424836667422054, 1.6319283685502304, 1.6204360385681693, 1.6096221348245396, 1.600497164258515, 1.5904110709068235]\n",
      "args {'lr': 2.130105161767157e-06}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.3366 - acc: 0.3595 - val_loss: 1.1745 - val_acc: 0.3585\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.2643 - acc: 0.3855 - val_loss: 1.1789 - val_acc: 0.3558\n",
      "Epoch 3/20\n",
      " - 5s - loss: 1.2044 - acc: 0.4086 - val_loss: 1.1729 - val_acc: 0.3585\n",
      "Epoch 4/20\n",
      " - 5s - loss: 1.1742 - acc: 0.4139 - val_loss: 1.1769 - val_acc: 0.3615\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.1380 - acc: 0.4289 - val_loss: 1.1853 - val_acc: 0.3551\n",
      "Epoch 6/20\n",
      " - 5s - loss: 1.1227 - acc: 0.4374 - val_loss: 1.1823 - val_acc: 0.3568\n",
      "Epoch 7/20\n",
      " - 5s - loss: 1.1101 - acc: 0.4435 - val_loss: 1.1960 - val_acc: 0.3464\n",
      "Epoch 8/20\n",
      " - 5s - loss: 1.0818 - acc: 0.4558 - val_loss: 1.1906 - val_acc: 0.3493\n",
      "Epoch 9/20\n",
      " - 5s - loss: 1.0758 - acc: 0.4614 - val_loss: 1.1881 - val_acc: 0.3522\n",
      "Epoch 10/20\n",
      " - 5s - loss: 1.0582 - acc: 0.4712 - val_loss: 1.1908 - val_acc: 0.3466\n",
      "Epoch 11/20\n",
      " - 5s - loss: 1.0455 - acc: 0.4750 - val_loss: 1.1924 - val_acc: 0.3406\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.0318 - acc: 0.4824 - val_loss: 1.1879 - val_acc: 0.3459\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.0256 - acc: 0.4905 - val_loss: 1.1929 - val_acc: 0.3413\n",
      "Epoch 14/20\n",
      " - 4s - loss: 1.0112 - acc: 0.4907 - val_loss: 1.1968 - val_acc: 0.3406\n",
      "Epoch 15/20\n",
      " - 5s - loss: 1.0062 - acc: 0.4987 - val_loss: 1.1952 - val_acc: 0.3382\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.9990 - acc: 0.5025 - val_loss: 1.1965 - val_acc: 0.3358\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/20\n",
      " - 5s - loss: 0.9798 - acc: 0.5154 - val_loss: 1.1934 - val_acc: 0.3408\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.9780 - acc: 0.5180 - val_loss: 1.1920 - val_acc: 0.3449\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.9761 - acc: 0.5157 - val_loss: 1.2020 - val_acc: 0.3345\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.9657 - acc: 0.5262 - val_loss: 1.2031 - val_acc: 0.3348\n",
      "[1.1745286410121243, 1.178851966961853, 1.1729166026985938, 1.1769384762896504, 1.185311657531385, 1.1822760975653208, 1.1960441578961198, 1.1906381689560186, 1.1880987138774155, 1.190768401044591, 1.1923522033223664, 1.1879119671657885, 1.192897498770046, 1.1968321033654485, 1.1951931062121481, 1.1964511458815281, 1.1933552728361914, 1.1920378724625715, 1.201976781969824, 1.2031058261439975]\n",
      "args {'lr': 2.8465540585127514e-05}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.1554 - acc: 0.4234 - val_loss: 1.2041 - val_acc: 0.3365\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.9913 - acc: 0.4959 - val_loss: 1.1734 - val_acc: 0.3690\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.9177 - acc: 0.5416 - val_loss: 1.2085 - val_acc: 0.3464\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.8662 - acc: 0.5763 - val_loss: 1.2132 - val_acc: 0.3225\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.8222 - acc: 0.6001 - val_loss: 1.2497 - val_acc: 0.3355\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.7731 - acc: 0.6288 - val_loss: 1.2715 - val_acc: 0.3386\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.7381 - acc: 0.6518 - val_loss: 1.2604 - val_acc: 0.3544\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.7086 - acc: 0.6724 - val_loss: 1.2781 - val_acc: 0.3541\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.6719 - acc: 0.6885 - val_loss: 1.3049 - val_acc: 0.3530\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.6451 - acc: 0.7002 - val_loss: 1.3202 - val_acc: 0.3563\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.6198 - acc: 0.7184 - val_loss: 1.3219 - val_acc: 0.3663\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.5891 - acc: 0.7334 - val_loss: 1.3634 - val_acc: 0.3474\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.5673 - acc: 0.7394 - val_loss: 1.3638 - val_acc: 0.3474\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.5432 - acc: 0.7558 - val_loss: 1.3627 - val_acc: 0.3753\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.5187 - acc: 0.7680 - val_loss: 1.3536 - val_acc: 0.3793\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.5054 - acc: 0.7771 - val_loss: 1.3902 - val_acc: 0.3750\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.4809 - acc: 0.7854 - val_loss: 1.4017 - val_acc: 0.3684\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.4677 - acc: 0.7943 - val_loss: 1.4097 - val_acc: 0.3667\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.4458 - acc: 0.8042 - val_loss: 1.4485 - val_acc: 0.3685\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.4349 - acc: 0.8109 - val_loss: 1.4168 - val_acc: 0.3908\n",
      "[1.2040694081490957, 1.1733780482159648, 1.2085212394392133, 1.2131606912093202, 1.2497196187765136, 1.2715115397762538, 1.2604298565628094, 1.278069292167227, 1.3048974369787065, 1.3201656757323554, 1.3218586230472908, 1.3633847340576006, 1.363827054442112, 1.3626510483042746, 1.3535751604579125, 1.3902250937609972, 1.401692932892885, 1.4097299173027682, 1.448451219527533, 1.4167875226901727]\n",
      "args {'lr': 4.503235654959055e-06}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.5336 - acc: 0.3407 - val_loss: 1.1643 - val_acc: 0.3619\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.2226 - acc: 0.3919 - val_loss: 1.1891 - val_acc: 0.3418\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.1565 - acc: 0.4087 - val_loss: 1.1712 - val_acc: 0.3483\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.1136 - acc: 0.4275 - val_loss: 1.1632 - val_acc: 0.3522\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.0801 - acc: 0.4445 - val_loss: 1.1676 - val_acc: 0.3520\n",
      "Epoch 6/20\n",
      " - 5s - loss: 1.0558 - acc: 0.4656 - val_loss: 1.1699 - val_acc: 0.3506\n",
      "Epoch 7/20\n",
      " - 4s - loss: 1.0337 - acc: 0.4713 - val_loss: 1.1799 - val_acc: 0.3432\n",
      "Epoch 8/20\n",
      " - 5s - loss: 1.0143 - acc: 0.4851 - val_loss: 1.1828 - val_acc: 0.3449\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.9977 - acc: 0.4990 - val_loss: 1.1844 - val_acc: 0.3391\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.9859 - acc: 0.5011 - val_loss: 1.1770 - val_acc: 0.3443\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.9695 - acc: 0.5110 - val_loss: 1.1801 - val_acc: 0.3500\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.9557 - acc: 0.5222 - val_loss: 1.1868 - val_acc: 0.3331\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.9436 - acc: 0.5280 - val_loss: 1.1856 - val_acc: 0.3432\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.9433 - acc: 0.5304 - val_loss: 1.1923 - val_acc: 0.3379\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.9209 - acc: 0.5457 - val_loss: 1.1857 - val_acc: 0.3442\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.9175 - acc: 0.5493 - val_loss: 1.1917 - val_acc: 0.3409\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.9033 - acc: 0.5596 - val_loss: 1.1930 - val_acc: 0.3408\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.8908 - acc: 0.5699 - val_loss: 1.1842 - val_acc: 0.3493\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.8797 - acc: 0.5745 - val_loss: 1.1981 - val_acc: 0.3396\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.8720 - acc: 0.5772 - val_loss: 1.2021 - val_acc: 0.3403\n",
      "[1.1642506434417226, 1.1891181790536367, 1.1711789424802692, 1.16323481658499, 1.1676421009552251, 1.1699429614017705, 1.179877123001161, 1.1827848584515521, 1.1843861974877297, 1.1769635586387779, 1.1801167395199352, 1.1867621009940996, 1.185573443080164, 1.192332408083882, 1.1857114981565553, 1.1917392083669553, 1.1929602603496583, 1.1842231256760434, 1.1981488524730588, 1.2021069490942058]\n",
      "args {'lr': 9.080336280704832e-07}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.4527 - acc: 0.3413 - val_loss: 1.2182 - val_acc: 0.3297\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.3439 - acc: 0.3413 - val_loss: 1.2185 - val_acc: 0.3297\n",
      "Epoch 3/20\n",
      " - 5s - loss: 1.3094 - acc: 0.3554 - val_loss: 1.2183 - val_acc: 0.3306\n",
      "Epoch 4/20\n",
      " - 4s - loss: 1.2758 - acc: 0.3669 - val_loss: 1.2174 - val_acc: 0.3309\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.2492 - acc: 0.3786 - val_loss: 1.2151 - val_acc: 0.3334\n",
      "Epoch 6/20\n",
      " - 5s - loss: 1.2344 - acc: 0.3796 - val_loss: 1.2101 - val_acc: 0.3346\n",
      "Epoch 7/20\n",
      " - 5s - loss: 1.2153 - acc: 0.3865 - val_loss: 1.2093 - val_acc: 0.3348\n",
      "Epoch 8/20\n",
      " - 4s - loss: 1.1930 - acc: 0.4011 - val_loss: 1.2127 - val_acc: 0.3329\n",
      "Epoch 9/20\n",
      " - 5s - loss: 1.1845 - acc: 0.4016 - val_loss: 1.2074 - val_acc: 0.3357\n",
      "Epoch 10/20\n",
      " - 5s - loss: 1.1663 - acc: 0.4099 - val_loss: 1.2045 - val_acc: 0.3348\n",
      "Epoch 11/20\n",
      " - 4s - loss: 1.1446 - acc: 0.4221 - val_loss: 1.2038 - val_acc: 0.3348\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.1401 - acc: 0.4244 - val_loss: 1.2008 - val_acc: 0.3380\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.1326 - acc: 0.4285 - val_loss: 1.2031 - val_acc: 0.3367\n",
      "Epoch 14/20\n",
      " - 5s - loss: 1.1133 - acc: 0.4342 - val_loss: 1.2037 - val_acc: 0.3336\n",
      "Epoch 15/20\n",
      " - 5s - loss: 1.1106 - acc: 0.4397 - val_loss: 1.2013 - val_acc: 0.3367\n",
      "Epoch 16/20\n",
      " - 5s - loss: 1.1130 - acc: 0.4373 - val_loss: 1.2053 - val_acc: 0.3317\n",
      "Epoch 17/20\n",
      " - 4s - loss: 1.0969 - acc: 0.4467 - val_loss: 1.2026 - val_acc: 0.3329\n",
      "Epoch 18/20\n",
      " - 5s - loss: 1.0880 - acc: 0.4480 - val_loss: 1.2022 - val_acc: 0.3334\n",
      "Epoch 19/20\n",
      " - 5s - loss: 1.0791 - acc: 0.4544 - val_loss: 1.2027 - val_acc: 0.3329\n",
      "Epoch 20/20\n",
      " - 5s - loss: 1.0693 - acc: 0.4593 - val_loss: 1.2004 - val_acc: 0.3346\n",
      "[1.2182202936842916, 1.2185025299602374, 1.218338413199547, 1.2173969869067949, 1.2150596737536812, 1.2100611005881827, 1.2093277640173805, 1.212708510559976, 1.2073630805886084, 1.2045003256940712, 1.203766421661065, 1.2008180238245618, 1.2030993316738743, 1.2036734514080536, 1.2013066955093468, 1.2052568018598842, 1.2025955129384345, 1.2022446553128943, 1.2027397740439434, 1.2004333081622214]\n",
      "args {'lr': 8.49938658657799e-06}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.2769 - acc: 0.3635 - val_loss: 1.1310 - val_acc: 0.3762\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.1074 - acc: 0.4177 - val_loss: 1.1362 - val_acc: 0.3714\n",
      "Epoch 3/20\n",
      " - 5s - loss: 1.0503 - acc: 0.4517 - val_loss: 1.1513 - val_acc: 0.3593\n",
      "Epoch 4/20\n",
      " - 5s - loss: 1.0127 - acc: 0.4732 - val_loss: 1.1647 - val_acc: 0.3564\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.9783 - acc: 0.4979 - val_loss: 1.1686 - val_acc: 0.3518\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.9496 - acc: 0.5195 - val_loss: 1.1891 - val_acc: 0.3367\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.9266 - acc: 0.5289 - val_loss: 1.1974 - val_acc: 0.3338\n",
      "Epoch 8/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 5s - loss: 0.9117 - acc: 0.5446 - val_loss: 1.1900 - val_acc: 0.3363\n",
      "Epoch 9/20\n",
      " - 4s - loss: 0.8893 - acc: 0.5565 - val_loss: 1.2001 - val_acc: 0.3454\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.8776 - acc: 0.5657 - val_loss: 1.2158 - val_acc: 0.3309\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.8580 - acc: 0.5745 - val_loss: 1.2164 - val_acc: 0.3369\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.8343 - acc: 0.5885 - val_loss: 1.2161 - val_acc: 0.3459\n",
      "Epoch 13/20\n",
      " - 4s - loss: 0.8283 - acc: 0.5978 - val_loss: 1.2181 - val_acc: 0.3403\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.8129 - acc: 0.6041 - val_loss: 1.2236 - val_acc: 0.3518\n",
      "Epoch 15/20\n",
      " - 4s - loss: 0.7978 - acc: 0.6128 - val_loss: 1.2199 - val_acc: 0.3600\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.7852 - acc: 0.6245 - val_loss: 1.2506 - val_acc: 0.3416\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.7691 - acc: 0.6369 - val_loss: 1.2482 - val_acc: 0.3505\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.7548 - acc: 0.6396 - val_loss: 1.2520 - val_acc: 0.3539\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.7422 - acc: 0.6439 - val_loss: 1.2440 - val_acc: 0.3641\n",
      "Epoch 20/20\n",
      " - 4s - loss: 0.7350 - acc: 0.6518 - val_loss: 1.2632 - val_acc: 0.3500\n",
      "[1.131013315769892, 1.1362342253043152, 1.1513075263363788, 1.1647226816951741, 1.168586991463435, 1.1890802562074376, 1.1974012159846459, 1.1899647673729006, 1.2001313572033874, 1.2158351366786282, 1.216383496162352, 1.2160793240778454, 1.21807387966551, 1.2235645552746932, 1.2199324028368541, 1.2505544349348188, 1.2481606298961172, 1.251980090985831, 1.2440233555411773, 1.2631845890013984]\n",
      "args {'lr': 1.6460295875816825e-07}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.4494 - acc: 0.3813 - val_loss: 1.1596 - val_acc: 0.4150\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.4164 - acc: 0.3565 - val_loss: 1.1652 - val_acc: 0.3891\n",
      "Epoch 3/20\n",
      " - 5s - loss: 1.3847 - acc: 0.3463 - val_loss: 1.1677 - val_acc: 0.3789\n",
      "Epoch 4/20\n",
      " - 5s - loss: 1.3579 - acc: 0.3458 - val_loss: 1.1682 - val_acc: 0.3680\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.3585 - acc: 0.3384 - val_loss: 1.1667 - val_acc: 0.3651\n",
      "Epoch 6/20\n",
      " - 5s - loss: 1.3509 - acc: 0.3380 - val_loss: 1.1653 - val_acc: 0.3622\n",
      "Epoch 7/20\n",
      " - 4s - loss: 1.3324 - acc: 0.3378 - val_loss: 1.1632 - val_acc: 0.3593\n",
      "Epoch 8/20\n",
      " - 4s - loss: 1.3462 - acc: 0.3312 - val_loss: 1.1619 - val_acc: 0.3580\n",
      "Epoch 9/20\n",
      " - 5s - loss: 1.3197 - acc: 0.3411 - val_loss: 1.1598 - val_acc: 0.3588\n",
      "Epoch 10/20\n",
      " - 4s - loss: 1.3147 - acc: 0.3387 - val_loss: 1.1560 - val_acc: 0.3624\n",
      "Epoch 11/20\n",
      " - 5s - loss: 1.3140 - acc: 0.3406 - val_loss: 1.1543 - val_acc: 0.3644\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.2936 - acc: 0.3492 - val_loss: 1.1530 - val_acc: 0.3639\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.2989 - acc: 0.3470 - val_loss: 1.1514 - val_acc: 0.3651\n",
      "Epoch 14/20\n",
      " - 4s - loss: 1.2881 - acc: 0.3500 - val_loss: 1.1505 - val_acc: 0.3646\n",
      "Epoch 15/20\n",
      " - 4s - loss: 1.2787 - acc: 0.3501 - val_loss: 1.1482 - val_acc: 0.3667\n",
      "Epoch 16/20\n",
      " - 5s - loss: 1.2801 - acc: 0.3571 - val_loss: 1.1473 - val_acc: 0.3685\n",
      "Epoch 17/20\n",
      " - 5s - loss: 1.2741 - acc: 0.3638 - val_loss: 1.1464 - val_acc: 0.3690\n",
      "Epoch 18/20\n",
      " - 4s - loss: 1.2676 - acc: 0.3619 - val_loss: 1.1462 - val_acc: 0.3680\n",
      "Epoch 19/20\n",
      " - 5s - loss: 1.2611 - acc: 0.3587 - val_loss: 1.1462 - val_acc: 0.3684\n",
      "Epoch 20/20\n",
      " - 5s - loss: 1.2518 - acc: 0.3619 - val_loss: 1.1453 - val_acc: 0.3692\n",
      "[1.1595966273497496, 1.1651861810554276, 1.1677232519482397, 1.1682029874838016, 1.1667021883281115, 1.1652954102212143, 1.1632156882039209, 1.1618562482033503, 1.1598408615231839, 1.156003578157451, 1.154314992538265, 1.1530270498520023, 1.151431959396487, 1.1505440629470576, 1.1482027830804726, 1.1473190966354079, 1.1463503360098648, 1.1462422658052367, 1.1461634954249826, 1.1452983419641811]\n",
      "args {'lr': 2.1447029543518073e-05}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.1764 - acc: 0.4182 - val_loss: 1.1890 - val_acc: 0.3391\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.0145 - acc: 0.4895 - val_loss: 1.1837 - val_acc: 0.3449\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.9456 - acc: 0.5232 - val_loss: 1.1940 - val_acc: 0.3382\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.8921 - acc: 0.5668 - val_loss: 1.2152 - val_acc: 0.3389\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.8572 - acc: 0.5906 - val_loss: 1.2387 - val_acc: 0.3374\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.8184 - acc: 0.6144 - val_loss: 1.2407 - val_acc: 0.3382\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.7877 - acc: 0.6309 - val_loss: 1.2228 - val_acc: 0.3719\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.7521 - acc: 0.6465 - val_loss: 1.2555 - val_acc: 0.3503\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.7304 - acc: 0.6636 - val_loss: 1.3219 - val_acc: 0.3365\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.7033 - acc: 0.6719 - val_loss: 1.2902 - val_acc: 0.3529\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.6775 - acc: 0.6918 - val_loss: 1.2594 - val_acc: 0.3719\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.6585 - acc: 0.7022 - val_loss: 1.3099 - val_acc: 0.3537\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.6340 - acc: 0.7109 - val_loss: 1.3169 - val_acc: 0.3619\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.6045 - acc: 0.7321 - val_loss: 1.3109 - val_acc: 0.3774\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.5946 - acc: 0.7354 - val_loss: 1.3424 - val_acc: 0.3556\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.5759 - acc: 0.7443 - val_loss: 1.3128 - val_acc: 0.3890\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.5499 - acc: 0.7576 - val_loss: 1.3330 - val_acc: 0.3833\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.5339 - acc: 0.7665 - val_loss: 1.3696 - val_acc: 0.3723\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.5166 - acc: 0.7741 - val_loss: 1.3425 - val_acc: 0.3910\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.5017 - acc: 0.7837 - val_loss: 1.4351 - val_acc: 0.3643\n",
      "[1.1889802568290149, 1.1837382803820784, 1.1940250318771488, 1.2151862811652452, 1.2386742531441213, 1.2407268350715532, 1.22279358852137, 1.2555468238342036, 1.3218536841447086, 1.2902131428185861, 1.2594323447354807, 1.3099265338939283, 1.3168507492834605, 1.3108990900523005, 1.3424150914522217, 1.312836471955198, 1.332977281604216, 1.3695819420125894, 1.342465358144256, 1.4351411869480435]\n",
      "args {'lr': 2.6495385119975706e-08}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.8149 - acc: 0.1952 - val_loss: 1.4513 - val_acc: 0.2285\n",
      "Epoch 2/20\n",
      " - 4s - loss: 1.7776 - acc: 0.1967 - val_loss: 1.4326 - val_acc: 0.2338\n",
      "Epoch 3/20\n",
      " - 5s - loss: 1.7472 - acc: 0.2020 - val_loss: 1.4159 - val_acc: 0.2406\n",
      "Epoch 4/20\n",
      " - 5s - loss: 1.7219 - acc: 0.2053 - val_loss: 1.3988 - val_acc: 0.2456\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.6996 - acc: 0.2100 - val_loss: 1.3832 - val_acc: 0.2509\n",
      "Epoch 6/20\n",
      " - 5s - loss: 1.6706 - acc: 0.2145 - val_loss: 1.3683 - val_acc: 0.2549\n",
      "Epoch 7/20\n",
      " - 5s - loss: 1.6571 - acc: 0.2186 - val_loss: 1.3545 - val_acc: 0.2594\n",
      "Epoch 8/20\n",
      " - 5s - loss: 1.6328 - acc: 0.2213 - val_loss: 1.3415 - val_acc: 0.2660\n",
      "Epoch 9/20\n",
      " - 5s - loss: 1.6159 - acc: 0.2232 - val_loss: 1.3286 - val_acc: 0.2677\n",
      "Epoch 10/20\n",
      " - 4s - loss: 1.5863 - acc: 0.2342 - val_loss: 1.3169 - val_acc: 0.2725\n",
      "Epoch 11/20\n",
      " - 5s - loss: 1.5906 - acc: 0.2321 - val_loss: 1.3057 - val_acc: 0.2790\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.5633 - acc: 0.2328 - val_loss: 1.2949 - val_acc: 0.2832\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.5586 - acc: 0.2354 - val_loss: 1.2852 - val_acc: 0.2900\n",
      "Epoch 14/20\n",
      " - 4s - loss: 1.5428 - acc: 0.2434 - val_loss: 1.2751 - val_acc: 0.2939\n",
      "Epoch 15/20\n",
      " - 4s - loss: 1.5296 - acc: 0.2458 - val_loss: 1.2666 - val_acc: 0.2960\n",
      "Epoch 16/20\n",
      " - 5s - loss: 1.5223 - acc: 0.2537 - val_loss: 1.2583 - val_acc: 0.3011\n",
      "Epoch 17/20\n",
      " - 4s - loss: 1.5113 - acc: 0.2542 - val_loss: 1.2503 - val_acc: 0.3050\n",
      "Epoch 18/20\n",
      " - 5s - loss: 1.4982 - acc: 0.2614 - val_loss: 1.2425 - val_acc: 0.3096\n",
      "Epoch 19/20\n",
      " - 5s - loss: 1.4921 - acc: 0.2629 - val_loss: 1.2350 - val_acc: 0.3134\n",
      "Epoch 20/20\n",
      " - 5s - loss: 1.4819 - acc: 0.2644 - val_loss: 1.2279 - val_acc: 0.3174\n",
      "[1.451321825994133, 1.4326360238670328, 1.415944717885363, 1.3988145787969273, 1.383156609470253, 1.3683209724582184, 1.3545236126278661, 1.3415251739668261, 1.3286431719236869, 1.316907579957302, 1.3057385549883103, 1.2948897086307203, 1.2851552505259294, 1.2750674794740182, 1.2665800544806332, 1.2583313553469708, 1.2502537754640917, 1.2425027166465323, 1.2350313361399181, 1.2279388664204027]\n",
      "args {'lr': 4.877013490255428e-05}\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.1253 - acc: 0.4415 - val_loss: 1.1765 - val_acc: 0.3271\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.9372 - acc: 0.5302 - val_loss: 1.1858 - val_acc: 0.3369\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.8584 - acc: 0.5775 - val_loss: 1.2204 - val_acc: 0.3387\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.7952 - acc: 0.6194 - val_loss: 1.2284 - val_acc: 0.3358\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.7471 - acc: 0.6494 - val_loss: 1.2511 - val_acc: 0.3467\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.6815 - acc: 0.6874 - val_loss: 1.2823 - val_acc: 0.3508\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.6377 - acc: 0.7089 - val_loss: 1.2750 - val_acc: 0.3590\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.6008 - acc: 0.7293 - val_loss: 1.3352 - val_acc: 0.3466\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.5565 - acc: 0.7545 - val_loss: 1.3363 - val_acc: 0.3665\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.5263 - acc: 0.7679 - val_loss: 1.3335 - val_acc: 0.3661\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.4920 - acc: 0.7849 - val_loss: 1.3934 - val_acc: 0.3701\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.4736 - acc: 0.7950 - val_loss: 1.3958 - val_acc: 0.3741\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.4404 - acc: 0.8097 - val_loss: 1.4372 - val_acc: 0.3755\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.4183 - acc: 0.8250 - val_loss: 1.4181 - val_acc: 0.4074\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.3947 - acc: 0.8347 - val_loss: 1.4404 - val_acc: 0.3879\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.3828 - acc: 0.8403 - val_loss: 1.4463 - val_acc: 0.4016\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.3588 - acc: 0.8518 - val_loss: 1.4723 - val_acc: 0.3799\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.3402 - acc: 0.8593 - val_loss: 1.4847 - val_acc: 0.3944\n",
      "Epoch 19/20\n",
      " - 4s - loss: 0.3256 - acc: 0.8673 - val_loss: 1.5163 - val_acc: 0.3755\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.3064 - acc: 0.8754 - val_loss: 1.5843 - val_acc: 0.3673\n",
      "[1.1764668586793323, 1.1858181729303718, 1.2204202936520694, 1.2284349472711131, 1.2511093567762452, 1.2822668471193444, 1.2749776531630057, 1.3351602248989594, 1.336280613569213, 1.333537638349819, 1.3933682396236493, 1.3958206066318688, 1.4371711740052018, 1.4181402525395075, 1.4403780266764379, 1.4463209443261253, 1.4723033911525716, 1.484657686152965, 1.5162631581849557, 1.5843012027584564]\n",
      "args {'lr': 0.000217757720776661}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.1304 - acc: 0.4575 - val_loss: 1.2013 - val_acc: 0.3389\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.8676 - acc: 0.5857 - val_loss: 1.1919 - val_acc: 0.3684\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.7407 - acc: 0.6598 - val_loss: 1.2351 - val_acc: 0.3733\n",
      "Epoch 4/20\n",
      " - 4s - loss: 0.6417 - acc: 0.7096 - val_loss: 1.2790 - val_acc: 0.4065\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.5610 - acc: 0.7491 - val_loss: 1.3296 - val_acc: 0.3878\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.4936 - acc: 0.7878 - val_loss: 1.3945 - val_acc: 0.3723\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.4279 - acc: 0.8120 - val_loss: 1.4128 - val_acc: 0.4084\n",
      "Epoch 8/20\n",
      " - 4s - loss: 0.3767 - acc: 0.8382 - val_loss: 1.4502 - val_acc: 0.3932\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.3318 - acc: 0.8590 - val_loss: 1.5242 - val_acc: 0.4215\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.2961 - acc: 0.8785 - val_loss: 1.6248 - val_acc: 0.3675\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.2598 - acc: 0.8920 - val_loss: 1.5899 - val_acc: 0.4121\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.2287 - acc: 0.9068 - val_loss: 1.6826 - val_acc: 0.4085\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.2227 - acc: 0.9098 - val_loss: 1.7413 - val_acc: 0.3900\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.1809 - acc: 0.9293 - val_loss: 1.7646 - val_acc: 0.4125\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.1604 - acc: 0.9370 - val_loss: 1.8751 - val_acc: 0.4341\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.1498 - acc: 0.9434 - val_loss: 1.8313 - val_acc: 0.4067\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.1303 - acc: 0.9495 - val_loss: 1.8881 - val_acc: 0.4409\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.1247 - acc: 0.9525 - val_loss: 1.9611 - val_acc: 0.4457\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.1157 - acc: 0.9561 - val_loss: 1.9807 - val_acc: 0.4068\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.1055 - acc: 0.9614 - val_loss: 2.0644 - val_acc: 0.4501\n",
      "[1.2012614421038927, 1.1918668727458985, 1.2351063847216988, 1.2790432401833807, 1.3296193303464219, 1.3945092076501664, 1.412750333466387, 1.450238476657088, 1.5241606287475502, 1.6248161903194251, 1.5899132142599661, 1.6825524682245072, 1.741321530264145, 1.7646321961275564, 1.8751243612746777, 1.8313084376280575, 1.8880765025557225, 1.9610917571454998, 1.980663679925882, 2.0644201277387237]\n",
      "args {'lr': 9.537921836509225e-05}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.0703 - acc: 0.4669 - val_loss: 1.2325 - val_acc: 0.2674\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.8809 - acc: 0.5663 - val_loss: 1.1793 - val_acc: 0.3689\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.7828 - acc: 0.6290 - val_loss: 1.2332 - val_acc: 0.3583\n",
      "Epoch 4/20\n",
      " - 4s - loss: 0.7071 - acc: 0.6660 - val_loss: 1.2949 - val_acc: 0.3689\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.6372 - acc: 0.7062 - val_loss: 1.2790 - val_acc: 0.3845\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.5683 - acc: 0.7413 - val_loss: 1.3983 - val_acc: 0.3890\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.5326 - acc: 0.7657 - val_loss: 1.3259 - val_acc: 0.3835\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.4774 - acc: 0.7880 - val_loss: 1.4049 - val_acc: 0.3895\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.4353 - acc: 0.8096 - val_loss: 1.4184 - val_acc: 0.3733\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.4001 - acc: 0.8256 - val_loss: 1.4545 - val_acc: 0.3833\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.3619 - acc: 0.8449 - val_loss: 1.4845 - val_acc: 0.3907\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.3364 - acc: 0.8565 - val_loss: 1.5295 - val_acc: 0.3883\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.3177 - acc: 0.8627 - val_loss: 1.4929 - val_acc: 0.4109\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.2849 - acc: 0.8827 - val_loss: 1.5779 - val_acc: 0.3949\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.2715 - acc: 0.8843 - val_loss: 1.6082 - val_acc: 0.3987\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.2384 - acc: 0.9035 - val_loss: 1.6365 - val_acc: 0.4395\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.2270 - acc: 0.9103 - val_loss: 1.6475 - val_acc: 0.3927\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.2198 - acc: 0.9127 - val_loss: 1.7355 - val_acc: 0.4193\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.1975 - acc: 0.9215 - val_loss: 1.7046 - val_acc: 0.4189\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.1783 - acc: 0.9300 - val_loss: 1.7375 - val_acc: 0.4191\n",
      "[1.2324515275799286, 1.1793446849412423, 1.2331746248198465, 1.294889465664648, 1.2790233838785572, 1.3983364553477524, 1.3258799441179072, 1.4048670864884796, 1.4184181469337818, 1.4544551229606857, 1.484466183737773, 1.5295060112950587, 1.4929181139215786, 1.5779249863013909, 1.6082419991818047, 1.6364607148339378, 1.6474866230416363, 1.7354722568709453, 1.704631708623278, 1.7374990077369545]\n",
      "args {'lr': 5.87666297233721e-07}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.6079 - acc: 0.4445 - val_loss: 1.2247 - val_acc: 0.3416\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.3758 - acc: 0.3786 - val_loss: 1.2538 - val_acc: 0.2515\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.3319 - acc: 0.3387 - val_loss: 1.2617 - val_acc: 0.2294\n",
      "Epoch 4/20\n",
      " - 5s - loss: 1.2917 - acc: 0.3404 - val_loss: 1.2568 - val_acc: 0.2308\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.2735 - acc: 0.3436 - val_loss: 1.2455 - val_acc: 0.2391\n",
      "Epoch 6/20\n",
      " - 5s - loss: 1.2599 - acc: 0.3437 - val_loss: 1.2357 - val_acc: 0.2488\n",
      "Epoch 7/20\n",
      " - 5s - loss: 1.2424 - acc: 0.3609 - val_loss: 1.2265 - val_acc: 0.2582\n",
      "Epoch 8/20\n",
      " - 4s - loss: 1.2301 - acc: 0.3629 - val_loss: 1.2205 - val_acc: 0.2667\n",
      "Epoch 9/20\n",
      " - 5s - loss: 1.2026 - acc: 0.3783 - val_loss: 1.2178 - val_acc: 0.2752\n",
      "Epoch 10/20\n",
      " - 4s - loss: 1.2035 - acc: 0.3812 - val_loss: 1.2121 - val_acc: 0.2784\n",
      "Epoch 11/20\n",
      " - 5s - loss: 1.1918 - acc: 0.3838 - val_loss: 1.2081 - val_acc: 0.2851\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.1856 - acc: 0.3910 - val_loss: 1.2037 - val_acc: 0.2951\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.1690 - acc: 0.3976 - val_loss: 1.2010 - val_acc: 0.3011\n",
      "Epoch 14/20\n",
      " - 5s - loss: 1.1717 - acc: 0.3982 - val_loss: 1.2019 - val_acc: 0.3002\n",
      "Epoch 15/20\n",
      " - 5s - loss: 1.1646 - acc: 0.3978 - val_loss: 1.1967 - val_acc: 0.3082\n",
      "Epoch 16/20\n",
      " - 5s - loss: 1.1515 - acc: 0.4108 - val_loss: 1.1949 - val_acc: 0.3122\n",
      "Epoch 17/20\n",
      " - 5s - loss: 1.1437 - acc: 0.4084 - val_loss: 1.1933 - val_acc: 0.3176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      " - 5s - loss: 1.1307 - acc: 0.4197 - val_loss: 1.1956 - val_acc: 0.3190\n",
      "Epoch 19/20\n",
      " - 5s - loss: 1.1238 - acc: 0.4214 - val_loss: 1.1937 - val_acc: 0.3224\n",
      "Epoch 20/20\n",
      " - 5s - loss: 1.1219 - acc: 0.4242 - val_loss: 1.1905 - val_acc: 0.3290\n",
      "[1.2247131609786759, 1.2537870868350245, 1.2617318607481038, 1.256811260527421, 1.2454949958447865, 1.2357368183395843, 1.2265093570184318, 1.2204886947730582, 1.2177958290323574, 1.2120870111423876, 1.2081413476928378, 1.2037356276603095, 1.2009798450755813, 1.2018698057621637, 1.196656298897247, 1.194870641510883, 1.1933097202706402, 1.195630143708689, 1.1937392381621317, 1.1904934313381725]\n",
      "args {'lr': 6.480347265480266e-05}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.0751 - acc: 0.4579 - val_loss: 1.2026 - val_acc: 0.2830\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.9000 - acc: 0.5564 - val_loss: 1.2417 - val_acc: 0.3370\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.8008 - acc: 0.6192 - val_loss: 1.3051 - val_acc: 0.3161\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.7307 - acc: 0.6576 - val_loss: 1.3293 - val_acc: 0.3360\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.6714 - acc: 0.6897 - val_loss: 1.3223 - val_acc: 0.3724\n",
      "Epoch 6/20\n",
      " - 4s - loss: 0.6242 - acc: 0.7146 - val_loss: 1.3534 - val_acc: 0.3549\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.5708 - acc: 0.7454 - val_loss: 1.3764 - val_acc: 0.3547\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.5323 - acc: 0.7648 - val_loss: 1.3554 - val_acc: 0.3808\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.4933 - acc: 0.7766 - val_loss: 1.4568 - val_acc: 0.3680\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.4623 - acc: 0.7981 - val_loss: 1.4322 - val_acc: 0.3658\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.4284 - acc: 0.8122 - val_loss: 1.4132 - val_acc: 0.3903\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.4051 - acc: 0.8276 - val_loss: 1.4513 - val_acc: 0.3701\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.3685 - acc: 0.8458 - val_loss: 1.5041 - val_acc: 0.3803\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.3548 - acc: 0.8502 - val_loss: 1.4837 - val_acc: 0.3794\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.3323 - acc: 0.8601 - val_loss: 1.4931 - val_acc: 0.3959\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.3089 - acc: 0.8720 - val_loss: 1.5923 - val_acc: 0.3781\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.2898 - acc: 0.8798 - val_loss: 1.5987 - val_acc: 0.3849\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.2766 - acc: 0.8900 - val_loss: 1.5722 - val_acc: 0.3900\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.2636 - acc: 0.8924 - val_loss: 1.6974 - val_acc: 0.3512\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.2476 - acc: 0.8978 - val_loss: 1.6685 - val_acc: 0.3878\n",
      "[1.2026252928481764, 1.2417149517776531, 1.3050973655742262, 1.3292982383385017, 1.3223254391542898, 1.353441069821246, 1.3763602393849343, 1.3553664226298112, 1.4567523012369141, 1.4321952990030398, 1.4131809703660596, 1.4513165138722766, 1.504122105866102, 1.4836978168513535, 1.493129875744396, 1.5923330439533785, 1.5986763706649032, 1.5721975831309847, 1.6974317273911728, 1.668462639933386]\n",
      "args {'lr': 0.0002223336124860315}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.0792 - acc: 0.4632 - val_loss: 1.2237 - val_acc: 0.3573\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.8407 - acc: 0.5869 - val_loss: 1.2970 - val_acc: 0.3285\n",
      "Epoch 3/20\n",
      " - 4s - loss: 0.7198 - acc: 0.6654 - val_loss: 1.3328 - val_acc: 0.3479\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.6213 - acc: 0.7128 - val_loss: 1.3320 - val_acc: 0.3564\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.5383 - acc: 0.7589 - val_loss: 1.3202 - val_acc: 0.3929\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.4840 - acc: 0.7813 - val_loss: 1.3770 - val_acc: 0.3702\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.4208 - acc: 0.8143 - val_loss: 1.4392 - val_acc: 0.4012\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.3654 - acc: 0.8443 - val_loss: 1.5217 - val_acc: 0.3896\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.3296 - acc: 0.8583 - val_loss: 1.5097 - val_acc: 0.3859\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.2780 - acc: 0.8810 - val_loss: 1.6148 - val_acc: 0.3696\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.2539 - acc: 0.8922 - val_loss: 1.6552 - val_acc: 0.3946\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.2224 - acc: 0.9083 - val_loss: 1.6937 - val_acc: 0.3992\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.2046 - acc: 0.9144 - val_loss: 1.6970 - val_acc: 0.4084\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.1740 - acc: 0.9321 - val_loss: 1.8244 - val_acc: 0.4160\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.1685 - acc: 0.9328 - val_loss: 1.8127 - val_acc: 0.4263\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.1533 - acc: 0.9374 - val_loss: 1.8664 - val_acc: 0.4249\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.1248 - acc: 0.9508 - val_loss: 1.9371 - val_acc: 0.4160\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.1233 - acc: 0.9519 - val_loss: 1.9066 - val_acc: 0.4126\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.1140 - acc: 0.9552 - val_loss: 2.0053 - val_acc: 0.4349\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.0967 - acc: 0.9642 - val_loss: 2.1142 - val_acc: 0.4370\n",
      "[1.223745318134734, 1.297010474373924, 1.3327502912006846, 1.3319611257038584, 1.3202425759559757, 1.3769648568831607, 1.4392476962112926, 1.5216916387022679, 1.5097289501159004, 1.6148333861327626, 1.6551528168634109, 1.693699024028934, 1.6970425175061343, 1.8244103618798528, 1.8126569974974651, 1.8664160677782522, 1.9371105968464948, 1.9065606811715732, 2.0052560908917836, 2.1141950937967535]\n",
      "args {'lr': 4.34757399447918e-07}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.9906 - acc: 0.2382 - val_loss: 1.5927 - val_acc: 0.2543\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.6618 - acc: 0.2532 - val_loss: 1.3563 - val_acc: 0.3052\n",
      "Epoch 3/20\n",
      " - 4s - loss: 1.4814 - acc: 0.2890 - val_loss: 1.2282 - val_acc: 0.3759\n",
      "Epoch 4/20\n",
      " - 5s - loss: 1.4049 - acc: 0.3247 - val_loss: 1.1770 - val_acc: 0.4087\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.3745 - acc: 0.3514 - val_loss: 1.1556 - val_acc: 0.4174\n",
      "Epoch 6/20\n",
      " - 5s - loss: 1.3550 - acc: 0.3558 - val_loss: 1.1471 - val_acc: 0.4184\n",
      "Epoch 7/20\n",
      " - 5s - loss: 1.3299 - acc: 0.3578 - val_loss: 1.1396 - val_acc: 0.4189\n",
      "Epoch 8/20\n",
      " - 5s - loss: 1.3127 - acc: 0.3582 - val_loss: 1.1344 - val_acc: 0.4159\n",
      "Epoch 9/20\n",
      " - 5s - loss: 1.2947 - acc: 0.3757 - val_loss: 1.1332 - val_acc: 0.4106\n",
      "Epoch 10/20\n",
      " - 5s - loss: 1.2833 - acc: 0.3721 - val_loss: 1.1314 - val_acc: 0.4080\n",
      "Epoch 11/20\n",
      " - 5s - loss: 1.2612 - acc: 0.3746 - val_loss: 1.1324 - val_acc: 0.4033\n",
      "Epoch 12/20\n",
      " - 5s - loss: 1.2596 - acc: 0.3728 - val_loss: 1.1313 - val_acc: 0.4022\n",
      "Epoch 13/20\n",
      " - 5s - loss: 1.2289 - acc: 0.3901 - val_loss: 1.1285 - val_acc: 0.4021\n",
      "Epoch 14/20\n",
      " - 5s - loss: 1.2220 - acc: 0.3891 - val_loss: 1.1297 - val_acc: 0.3988\n",
      "Epoch 15/20\n",
      " - 5s - loss: 1.2238 - acc: 0.3878 - val_loss: 1.1315 - val_acc: 0.3937\n",
      "Epoch 16/20\n",
      " - 5s - loss: 1.2060 - acc: 0.3886 - val_loss: 1.1303 - val_acc: 0.3931\n",
      "Epoch 17/20\n",
      " - 5s - loss: 1.1932 - acc: 0.4007 - val_loss: 1.1309 - val_acc: 0.3900\n",
      "Epoch 18/20\n",
      " - 5s - loss: 1.1918 - acc: 0.3962 - val_loss: 1.1323 - val_acc: 0.3842\n",
      "Epoch 19/20\n",
      " - 5s - loss: 1.1765 - acc: 0.4063 - val_loss: 1.1324 - val_acc: 0.3837\n",
      "Epoch 20/20\n",
      " - 4s - loss: 1.1772 - acc: 0.4100 - val_loss: 1.1336 - val_acc: 0.3840\n",
      "[1.5926554995596571, 1.3562605946200421, 1.2281937764840816, 1.1769772781013468, 1.1555932526367563, 1.1470552174531796, 1.1395665813206977, 1.1343597102230187, 1.1332278261392579, 1.1314298746046643, 1.1324276570078462, 1.131342285660372, 1.1285104322823256, 1.1297061381612876, 1.131465783560958, 1.1303164026717725, 1.1308704877744253, 1.132275794442408, 1.1323513367520366, 1.1336089541541783]\n",
      "args {'lr': 4.757584855110403e-06}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.2993 - acc: 0.3776 - val_loss: 1.1896 - val_acc: 0.3287\n",
      "Epoch 2/20\n",
      " - 5s - loss: 1.1827 - acc: 0.4197 - val_loss: 1.1755 - val_acc: 0.3496\n",
      "Epoch 3/20\n",
      " - 5s - loss: 1.1239 - acc: 0.4368 - val_loss: 1.1909 - val_acc: 0.3418\n",
      "Epoch 4/20\n",
      " - 5s - loss: 1.0889 - acc: 0.4541 - val_loss: 1.1866 - val_acc: 0.3486\n",
      "Epoch 5/20\n",
      " - 5s - loss: 1.0623 - acc: 0.4679 - val_loss: 1.1932 - val_acc: 0.3379\n",
      "Epoch 6/20\n",
      " - 4s - loss: 1.0340 - acc: 0.4814 - val_loss: 1.1936 - val_acc: 0.3445\n",
      "Epoch 7/20\n",
      " - 5s - loss: 1.0137 - acc: 0.4963 - val_loss: 1.2052 - val_acc: 0.3353\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.9856 - acc: 0.5109 - val_loss: 1.2012 - val_acc: 0.3340\n",
      "Epoch 9/20\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - 4s - loss: 0.9744 - acc: 0.5188 - val_loss: 1.2021 - val_acc: 0.3353\n",
      "Epoch 10/20\n",
      " - 5s - loss: 0.9594 - acc: 0.5278 - val_loss: 1.2148 - val_acc: 0.3323\n",
      "Epoch 11/20\n",
      " - 5s - loss: 0.9378 - acc: 0.5447 - val_loss: 1.2110 - val_acc: 0.3365\n",
      "Epoch 12/20\n",
      " - 5s - loss: 0.9295 - acc: 0.5493 - val_loss: 1.2208 - val_acc: 0.3403\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.9176 - acc: 0.5575 - val_loss: 1.2344 - val_acc: 0.3294\n",
      "Epoch 14/20\n",
      " - 5s - loss: 0.9058 - acc: 0.5600 - val_loss: 1.2426 - val_acc: 0.3232\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.8907 - acc: 0.5677 - val_loss: 1.2307 - val_acc: 0.3345\n",
      "Epoch 16/20\n",
      " - 5s - loss: 0.8860 - acc: 0.5746 - val_loss: 1.2251 - val_acc: 0.3433\n",
      "Epoch 17/20\n",
      " - 5s - loss: 0.8738 - acc: 0.5795 - val_loss: 1.2253 - val_acc: 0.3413\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.8614 - acc: 0.5880 - val_loss: 1.2493 - val_acc: 0.3287\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.8476 - acc: 0.5959 - val_loss: 1.2453 - val_acc: 0.3403\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.8425 - acc: 0.5947 - val_loss: 1.2440 - val_acc: 0.3426\n",
      "[1.189614942677989, 1.1755102557772188, 1.1908845917730306, 1.1866493394004551, 1.193152951934357, 1.1936111619102208, 1.2051703345223408, 1.2012352212573267, 1.2021041929884242, 1.2148449632062575, 1.2109546963460438, 1.2207650443188827, 1.2343641087534643, 1.242620115059273, 1.2306932649430526, 1.2251466723813673, 1.225260983046134, 1.2493288491012615, 1.2452964717750654, 1.2439538415836053]\n",
      "args {'lr': 0.0007276850379905144}\n",
      "Class weights {0: 1.9705474705474706, 1: 0.6056443024494143, 2: 1.1885057471264369}\n",
      "Train on 17061 samples, validate on 5872 samples\n",
      "Epoch 1/20\n",
      " - 5s - loss: 1.1537 - acc: 0.4681 - val_loss: 1.2254 - val_acc: 0.3542\n",
      "Epoch 2/20\n",
      " - 5s - loss: 0.8636 - acc: 0.5779 - val_loss: 1.2838 - val_acc: 0.3346\n",
      "Epoch 3/20\n",
      " - 5s - loss: 0.7870 - acc: 0.6324 - val_loss: 1.3115 - val_acc: 0.3854\n",
      "Epoch 4/20\n",
      " - 5s - loss: 0.6727 - acc: 0.6930 - val_loss: 1.4769 - val_acc: 0.3336\n",
      "Epoch 5/20\n",
      " - 5s - loss: 0.5764 - acc: 0.7420 - val_loss: 1.4807 - val_acc: 0.3983\n",
      "Epoch 6/20\n",
      " - 5s - loss: 0.4964 - acc: 0.7831 - val_loss: 1.5519 - val_acc: 0.3816\n",
      "Epoch 7/20\n",
      " - 5s - loss: 0.4448 - acc: 0.8088 - val_loss: 1.6054 - val_acc: 0.3665\n",
      "Epoch 8/20\n",
      " - 5s - loss: 0.3640 - acc: 0.8433 - val_loss: 1.6230 - val_acc: 0.3931\n",
      "Epoch 9/20\n",
      " - 5s - loss: 0.3137 - acc: 0.8699 - val_loss: 1.7370 - val_acc: 0.3604\n",
      "Epoch 10/20\n",
      " - 4s - loss: 0.2852 - acc: 0.8784 - val_loss: 1.8191 - val_acc: 0.3915\n",
      "Epoch 11/20\n",
      " - 4s - loss: 0.2513 - acc: 0.8962 - val_loss: 1.9484 - val_acc: 0.3641\n",
      "Epoch 12/20\n",
      " - 4s - loss: 0.2241 - acc: 0.9038 - val_loss: 1.8203 - val_acc: 0.4230\n",
      "Epoch 13/20\n",
      " - 5s - loss: 0.1900 - acc: 0.9216 - val_loss: 1.9952 - val_acc: 0.4128\n",
      "Epoch 14/20\n",
      " - 4s - loss: 0.1770 - acc: 0.9269 - val_loss: 2.1905 - val_acc: 0.4229\n",
      "Epoch 15/20\n",
      " - 5s - loss: 0.1417 - acc: 0.9434 - val_loss: 2.1734 - val_acc: 0.4268\n",
      "Epoch 16/20\n",
      " - 4s - loss: 0.1345 - acc: 0.9468 - val_loss: 2.2015 - val_acc: 0.4200\n",
      "Epoch 17/20\n",
      " - 4s - loss: 0.1227 - acc: 0.9507 - val_loss: 2.1474 - val_acc: 0.4200\n",
      "Epoch 18/20\n",
      " - 5s - loss: 0.1128 - acc: 0.9546 - val_loss: 2.3493 - val_acc: 0.4273\n",
      "Epoch 19/20\n",
      " - 5s - loss: 0.1128 - acc: 0.9554 - val_loss: 2.4790 - val_acc: 0.4184\n",
      "Epoch 20/20\n",
      " - 5s - loss: 0.0961 - acc: 0.9602 - val_loss: 2.4234 - val_acc: 0.4315\n",
      "[1.2253659586815484, 1.2837506711320592, 1.3115144295653465, 1.4768685466262235, 1.4806737865674073, 1.5518680541326955, 1.6054138110833858, 1.6230406481823414, 1.7369707147172102, 1.8191043723181743, 1.9484419683019862, 1.8203470222956477, 1.9951791938708978, 2.1905086946747283, 2.173421087966628, 2.2014581052743774, 2.1473594471934057, 2.3492806237140207, 2.4790224415080098, 2.423393063064492]\n",
      "best: {'lr': -6.361753017693156}\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "best = fmin(fn=objective,\n",
    "            space=space,\n",
    "            algo=tpe.suggest,\n",
    "            trials=trials,\n",
    "            max_evals=20)\n",
    "print('best:', best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "it=0\n",
    "loss = np.zeros(len(trials))\n",
    "params = np.zeros((len(trials),3))\n",
    "for objects in trials.trials:\n",
    "                  loss[it] = objects['result']['loss'] \n",
    "                  params[it,0] = 10 ** objects['misc']['vals']['lr'][0]\n",
    "#                   params[it,1] = objects['misc']['vals']['num_dense1'][0]\n",
    "#                   params[it,2] = objects['misc']['vals']['num_dense2'][0]\n",
    "                  it+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAlsAAAJTCAYAAAA/ltMcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYQsAoCHDFgBAQ4YtAICGDFsAAA39f3ALnCqHPL2OAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8631a178d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.stem(params[:,0],loss[:])\n",
    "# plt.scatter(params[:,0][mask]+200,params[:,2][mask]+20,c=loss[:][mask],s=loss[:][mask]*200)\n",
    "# plt.yscale('log')\n",
    "# plt.ylim([1,2])\n",
    "plt.xscale('log',nonposy='clip')\n",
    "plt.xlim([10**-8,10**-3])\n",
    "# plt.colorbar()\n",
    "plt.grid()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = loss>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[2.22893388e-06, 0.00000000e+00, 0.00000000e+00],\n",
       "       [7.81573129e-07, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.43763440e-04, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.49010105e-05, 0.00000000e+00, 0.00000000e+00],\n",
       "       [1.37217731e-04, 0.00000000e+00, 0.00000000e+00]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
